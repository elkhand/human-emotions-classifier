{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis in torchtext of OASIS datasets captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "device: cuda:0\n",
      "Python version: 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 18:10:19) \n",
      "[GCC 7.2.0]\n",
      "Pandas version: 0.22.0\n",
      "Pytorch version: 0.4.0\n",
      "Torch Text version: 0.2.3\n",
      "Spacy version: 2.0.11\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "%matplotlib inline\n",
    "import os, sys\n",
    "import re\n",
    "import string\n",
    "import pathlib\n",
    "import random\n",
    "from collections import Counter, OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "tqdm.pandas(desc='Progress')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import vocab\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'\n",
    "\n",
    "import warnings\n",
    "from utils.scoring_utils import *\n",
    "from utils.data_utils import *\n",
    "from utils.plotting_utils import *\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('device:',device)\n",
    "print('Python version:',sys.version)\n",
    "print('Pandas version:',pd.__version__)\n",
    "print('Pytorch version:', torch.__version__)\n",
    "print('Torch Text version:', torchtext.__version__)\n",
    "print('Spacy version:', spacy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_title_human</th>\n",
       "      <th>caption_human</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I109</td>\n",
       "      <td>Camping 6.jpg</td>\n",
       "      <td>A man wearing a blue jacket and a headlamp lig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id image_title_human                                      caption_human\n",
       "0  I109     Camping 6.jpg  A man wearing a blue jacket and a headlamp lig..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(900, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_title_auto</th>\n",
       "      <th>caption_auto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I672</td>\n",
       "      <td>Rocks 5.jpg</td>\n",
       "      <td>a bunch of carrots are sitting on the ground.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id image_title_auto                                   caption_auto\n",
       "0  I672      Rocks 5.jpg  a bunch of carrots are sitting on the ground."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(900, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>theme</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "      <th>valence_mean</th>\n",
       "      <th>valence_std</th>\n",
       "      <th>valence_n</th>\n",
       "      <th>arousal_mean</th>\n",
       "      <th>arousal_std</th>\n",
       "      <th>arousal_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I1</td>\n",
       "      <td>Acorns 1</td>\n",
       "      <td>Object</td>\n",
       "      <td>Pixabay</td>\n",
       "      <td>4.686275</td>\n",
       "      <td>0.954203</td>\n",
       "      <td>102</td>\n",
       "      <td>2.346535</td>\n",
       "      <td>1.60272</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     theme category   source  valence_mean  valence_std  valence_n  \\\n",
       "0  I1  Acorns 1   Object  Pixabay      4.686275     0.954203        102   \n",
       "\n",
       "   arousal_mean  arousal_std  arousal_n  \n",
       "0      2.346535      1.60272        101  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(900, 7)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_title_human</th>\n",
       "      <th>caption_human</th>\n",
       "      <th>image_title_auto</th>\n",
       "      <th>caption_auto</th>\n",
       "      <th>theme</th>\n",
       "      <th>valence_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I109</td>\n",
       "      <td>Camping 6.jpg</td>\n",
       "      <td>A man wearing a blue jacket and a headlamp lig...</td>\n",
       "      <td>Camping 7.jpg</td>\n",
       "      <td>a group of people on a small boat in the water.</td>\n",
       "      <td>Camping 7</td>\n",
       "      <td>5.215686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I56</td>\n",
       "      <td>Bark 5.jpg</td>\n",
       "      <td>The trunk of an old tree with a rough bark cov...</td>\n",
       "      <td>BDSM 1.jpg</td>\n",
       "      <td>a group of people standing next to each other.</td>\n",
       "      <td>BDSM 1</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I61</td>\n",
       "      <td>Beach 3.jpg</td>\n",
       "      <td>A person walking along a sandy seashore at dawn.</td>\n",
       "      <td>Beach 3.jpg</td>\n",
       "      <td>a person on a beach with a surfboard.</td>\n",
       "      <td>Beach 3</td>\n",
       "      <td>5.514851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id image_title_human                                      caption_human  \\\n",
       "0  I109     Camping 6.jpg  A man wearing a blue jacket and a headlamp lig...   \n",
       "1   I56        Bark 5.jpg  The trunk of an old tree with a rough bark cov...   \n",
       "2   I61       Beach 3.jpg   A person walking along a sandy seashore at dawn.   \n",
       "\n",
       "  image_title_auto                                     caption_auto  \\\n",
       "0    Camping 7.jpg  a group of people on a small boat in the water.   \n",
       "1       BDSM 1.jpg   a group of people standing next to each other.   \n",
       "2      Beach 3.jpg            a person on a beach with a surfboard.   \n",
       "\n",
       "       theme  valence_mean  \n",
       "0  Camping 7      5.215686  \n",
       "1     BDSM 1      4.333333  \n",
       "2    Beach 3      5.514851  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(900, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_title</th>\n",
       "      <th>caption</th>\n",
       "      <th>valence_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I109</td>\n",
       "      <td>Camping 6.jpg</td>\n",
       "      <td>A man wearing a blue jacket and a headlamp lig...</td>\n",
       "      <td>5.215686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id    image_title                                            caption  \\\n",
       "0  I109  Camping 6.jpg  A man wearing a blue jacket and a headlamp lig...   \n",
       "\n",
       "   valence_mean  \n",
       "0      5.215686  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(900, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_title</th>\n",
       "      <th>caption</th>\n",
       "      <th>valence_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I109</td>\n",
       "      <td>Camping 7.jpg</td>\n",
       "      <td>a group of people on a small boat in the water.</td>\n",
       "      <td>5.215686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id    image_title                                          caption  \\\n",
       "0  I109  Camping 7.jpg  a group of people on a small boat in the water.   \n",
       "\n",
       "   valence_mean  \n",
       "0      5.215686  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_root = \"/home/elkhand/git-repos/human-emotions-classifier/dataset/metadata\"\n",
    "oasis_csv_path = \"dataset/metadata/OASIS.csv\"\n",
    "captions_root_path = pathlib.Path(captions_root)\n",
    "dfHuman = read_caption_csv_into_dataframe(captions_root_path/'captions.csv')\n",
    "#pd.read_csv(data_root/'captions.csv', error_bad_lines=False)\n",
    "dfHuman[\"id\"] = dfHuman[\"id\"].apply(lambda x: \"I\"+str(x))\n",
    "dfHuman.columns = ['id', 'image_title_human', 'caption_human']\n",
    "dfHuman.shape\n",
    "dfHuman.head(1)\n",
    "\n",
    "dfAuto = read_caption_csv_into_dataframe(data_root/'auto_generated_captions.csv', delimeter='|')\n",
    "#pd.read_csv(data_root/'auto_generated_captions.csv', sep = \"|\", error_bad_lines=False)\n",
    "dfAuto.columns = ['id', 'image_title_auto', 'caption_auto']\n",
    "dfAuto.shape\n",
    "dfAuto.head(1)\n",
    "\n",
    "\n",
    "dfOasis = read_oasis_csv_into_dataframe(oasis_csv_path)\n",
    "dfOasis.shape\n",
    "dfOasis.head(1)\n",
    "\n",
    "# frames = [dfHuman, dfAuto, dfOasis]\n",
    "df = pd.merge(dfHuman,dfAuto, on= 'id')\n",
    "df = pd.merge(df,dfOasis, on= 'id')\n",
    "## Select the ones you want\n",
    "df = df[['id','image_title_human','caption_human','image_title_auto','caption_auto','theme','valence_mean']]\n",
    "df.shape\n",
    "df.head(3)\n",
    "\n",
    "dfHuman = df[['id','image_title_human','caption_human','valence_mean']]\n",
    "dfHuman.columns = ['id', 'image_title', 'caption', 'valence_mean']\n",
    "dfHuman.shape\n",
    "dfHuman.head(1)\n",
    "\n",
    "dfAuto = df[['id','image_title_auto','caption_auto','valence_mean']]\n",
    "dfAuto.columns = ['id', 'image_title', 'caption','valence_mean']\n",
    "dfAuto.shape\n",
    "dfAuto.head(1)\n",
    "\n",
    "\n",
    "humanCaptionWithScorePath = captions_root_path/'humanCaptionWithScoredf.csv'\n",
    "autoCaptionWithScorePath = captions_root_path/'autoCaptionWithScoredf.csv'\n",
    "\n",
    "dfHuman.to_csv(humanCaptionWithScorePath, index=False)\n",
    "dfAuto.to_csv(autoCaptionWithScorePath, index=False)\n",
    "\n",
    "# dfDiff = df[df[\"image_title_human\"] != df[\"image_title_auto\"]]\n",
    "# dfDiff.shape\n",
    "# dfDiff.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define how to process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.dataset.TabularDataset'>\n",
      "900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torchtext.data.example.Example"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_items([('id', None), ('image_title', None), ('caption', <torchtext.data.field.Field object at 0x7f8c1f15dfd0>), ('valence_mean', <torchtext.data.field.Field object at 0x7f8c1f15de80>)])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'5.2156862745098005'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'man',\n",
       " 'wearing',\n",
       " 'blue',\n",
       " 'jacket',\n",
       " 'headlamp',\n",
       " 'lighting',\n",
       " 'fire',\n",
       " 'pile',\n",
       " 'wood',\n",
       " 'kindling',\n",
       " 'front']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en',disable=['parser', 'tagger', 'ner'])\n",
    "def tokenizer(s): return [w.text.lower() for w in nlp(caption_clean(s))]\n",
    "def caption_clean(caption):\n",
    "    caption = re.sub(r'[^A-Za-z0-9]+', ' ', caption) # remove non alphanumeric character\n",
    "    caption = remove_stop_words(caption) # remove links\n",
    "    return caption\n",
    "\n",
    "def remove_stop_words(caption):\n",
    "    cleanedCaption = \"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(caption)\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            cleanedCaption += word + \" \"\n",
    "    return cleanedCaption.strip()\n",
    "\n",
    "\n",
    "txt_field = data.Field(sequential=True, tokenize=tokenizer, include_lengths=True, use_vocab=True)\n",
    "label_field = data.Field(sequential=False, use_vocab=False, pad_token=None, unk_token=None)\n",
    "\n",
    "test_fields = [\n",
    "    ('id', None),\n",
    "    ('image_title', None),\n",
    "     ('caption', txt_field),\n",
    "    ('valence_mean', label_field)   \n",
    "]\n",
    "\n",
    "\n",
    "# trainds, valds = data.TabularDataset.splits(path=datasets_root, format='csv', train='traindf.csv', validation='valdf.csv', fields=train_val_fields, skip_header=True)\n",
    "# %%time\n",
    "testHumanCaption = data.TabularDataset(\n",
    "        path=humanCaptionWithScorePath, format='csv', \n",
    "        skip_header=True,\n",
    "        fields=test_fields)\n",
    "\n",
    "testAutoCaption = data.TabularDataset(\n",
    "        path=autoCaptionWithScorePath, format='csv', \n",
    "        skip_header=True,\n",
    "        fields=test_fields)\n",
    "\n",
    "print(type(testHumanCaption))\n",
    "print(len(testHumanCaption))\n",
    "ex = testHumanCaption[0]\n",
    "type(ex)\n",
    "testHumanCaption.fields.items()\n",
    "ex.valence_mean\n",
    "ex.caption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained word vectors and building vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 471 ms, sys: 144 ms, total: 616 ms\n",
      "Wall time: 592 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "glove_dataset_root = \"/home/elkhand/datasets/glove-vectors\"\n",
    "vec = vocab.Vectors('glove.twitter.27B.100d.txt', glove_dataset_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2367, 100])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5078, -1.0274,  0.4814, -0.0942,  0.4484, -0.5229,  0.5150,\n",
       "        -0.0389,  0.3587, -0.0660, -0.8288,  0.7618, -3.8030, -0.0106,\n",
       "         0.2165,  0.5971,  0.3742, -0.0226, -0.0103, -0.3397,  0.0943,\n",
       "         0.2625, -0.4016, -0.0080,  1.0206, -0.3579, -0.5650,  0.5882,\n",
       "        -0.8185,  0.3029,  0.4720, -0.0974, -0.6123, -0.1780, -0.1162,\n",
       "         0.3259,  0.1150, -0.1903,  0.0116,  0.4648, -0.1681,  0.2197,\n",
       "        -0.2594, -0.0135,  0.7071,  0.7811,  0.7992,  1.0389,  0.5279,\n",
       "        -0.1116, -0.6227,  0.0307,  0.3385, -0.5309, -0.0997,  0.2160,\n",
       "         0.6052,  1.2356, -0.0035, -0.0975, -0.2494,  0.2154,  0.4464,\n",
       "         0.0954, -0.2737, -0.2854, -0.4089,  0.4822,  0.3032,  0.1944,\n",
       "         0.8324, -0.5038,  0.3009, -0.4979,  0.5030,  0.0327, -0.5179,\n",
       "        -0.2354,  0.2296, -0.6359,  1.6270,  0.6283, -0.7485,  0.6007,\n",
       "        -0.0112, -0.3211,  0.1434, -0.0608,  0.0882,  0.6594, -0.4613,\n",
       "        -0.3764, -0.1133,  0.1587,  0.3912,  0.6766, -0.0712,  0.1746,\n",
       "        -0.0334,  0.7315])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_field.build_vocab(testHumanCaption, testAutoCaption, max_size=100000, vectors=vec)\n",
    "label_field.build_vocab(testHumanCaption)\n",
    "txt_field.vocab.vectors.shape\n",
    "txt_field.vocab.vectors[txt_field.vocab.stoi['dog']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ConcatPoolingGRUAdaptive:\n\tWhile copying the parameter named \"emb.weight\", whose dimensions in the model are torch.Size([2367, 100]) and whose dimensions in the checkpoint are torch.Size([100002, 100]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-948239494c01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatPoolingGRUAdaptive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestHumanCaption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'caption'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/elkhand/git-repos/sentiment-analysis-torchtext/model/twitter-%i.pth'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-948239494c01>\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(checkpoint_path, model, optimizer)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loaded from %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231n/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 721\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ConcatPoolingGRUAdaptive:\n\tWhile copying the parameter named \"emb.weight\", whose dimensions in the model are torch.Size([2367, 100]) and whose dimensions in the checkpoint are torch.Size([100002, 100])."
     ]
    }
   ],
   "source": [
    "vocab_size = len(txt_field.vocab)\n",
    "embedding_dim = 100\n",
    "n_hidden = 64\n",
    "n_out = 2\n",
    "\n",
    "class ConcatPoolingGRUAdaptive(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_hidden, n_out, pretrained_vec, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.emb = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.emb.weight.data.copy_(pretrained_vec)\n",
    "        self.emb.weight.requires_grad = False\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.n_hidden, bidirectional=bidirectional)\n",
    "        if bidirectional:\n",
    "            self.out = nn.Linear(self.n_hidden*2*2, self.n_out)\n",
    "        else:\n",
    "            self.out = nn.Linear(self.n_hidden*2, self.n_out)\n",
    "        \n",
    "    def forward(self, seq, lengths):\n",
    "        bs = seq.size(1)\n",
    "        self.h = self.init_hidden(bs)\n",
    "        seq = seq.transpose(0,1)\n",
    "        embs = self.emb(seq)\n",
    "        embs = embs.transpose(0,1)\n",
    "        embs = pack_padded_sequence(embs, lengths)\n",
    "        gru_out, self.h = self.gru(embs, self.h)\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out)        \n",
    "        \n",
    "        avg_pool = F.adaptive_avg_pool1d(gru_out.permute(1,2,0),1).view(bs,-1)\n",
    "        max_pool = F.adaptive_max_pool1d(gru_out.permute(1,2,0),1).view(bs,-1)        \n",
    "        outp = self.out(torch.cat([avg_pool,max_pool],dim=1))\n",
    "        return F.log_softmax(outp)\n",
    "    \n",
    "    def init_hidden(self, batch_size): \n",
    "        if self.bidirectional:\n",
    "            return torch.zeros((2,batch_size,self.n_hidden)).to(device)\n",
    "        else:\n",
    "            return torch.zeros((1,batch_size,self.n_hidden)).cuda().to(device)\n",
    "\n",
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = {'state_dict': model.state_dict(),\n",
    "             'optimizer' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from %s' % checkpoint_path)\n",
    "    \n",
    "# Load model\n",
    "m = ConcatPoolingGRUAdaptive(vocab_size, embedding_dim, n_hidden, n_out, testHumanCaption.fields['caption'].vocab.vectors).to(device)\n",
    "opt = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), 1e-3)\n",
    "load_checkpoint('/home/elkhand/git-repos/sentiment-analysis-torchtext/model/twitter-%i.pth' % 5, m, opt)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
