{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is exact same as `Final Caption Keras-Bidrectional-GRU-based sentiment analysis of OASIS dataset captions` notebook\n",
    "\n",
    "Only without class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, io,re, string, pathlib, random\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import hecutils.data_utils as dt\n",
    "import hecutils.scoring_utils as sc\n",
    "import hecutils.plotting_utils as pt\n",
    "import hecutils.caption_utils as caput\n",
    "import hecutils.image_utils as imut\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, GRU, Bidirectional, LSTM\n",
    "from keras.layers.core import Dropout, Flatten, Masking, ActivityRegularization\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import text\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "num_cores = 8\n",
    "GPU=True\n",
    "CPU = not GPU\n",
    "\n",
    "if GPU:\n",
    "    num_GPU = 1\n",
    "    num_CPU = 8\n",
    "if CPU:\n",
    "    num_CPU = 8\n",
    "    num_GPU = 0\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : num_CPU, 'GPU' : num_GPU})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "\n",
    "oasis_csv_path = \"dataset/metadata/OASIS.csv\"\n",
    "captions_root = \"/home/elkhand/git-repos/human-emotions-classifier/dataset/metadata\"\n",
    "captions_root_path = pathlib.Path(captions_root)\n",
    "human_output_caption_to_label_csv_path = captions_root_path/'humanCaptionWithLabeldf2.csv'\n",
    "human_caption_csv_path = captions_root_path/'captions.csv'\n",
    "#fasttext_embedding_path = 'embedding/wiki-news-300d-1M.vec'\n",
    "fasttext_embedding_path = '/home/elkhand/datasets/glove-vectors/glove.twitter.27B.200d.txt'\n",
    "model_results_root_dir = \"model2/\"\n",
    "inputDataset_csv_path = captions_root_path/\"inputDataset2.csv\"\n",
    "testDataset_csv_path = captions_root_path/\"testDataset2.csv\"\n",
    "\n",
    "neutralLow = 3.0 \n",
    "neutralHigh = 5.0\n",
    "\n",
    "auto_output_caption_to_label_csv_path = captions_root_path/'autoCaptionWithLabeldf2.csv'\n",
    "auto_caption_csv_path = captions_root_path/'auto_generated_captions.csv'\n",
    "\n",
    "\n",
    "dataset_path = human_output_caption_to_label_csv_path\n",
    "# dataset_path = auto_output_caption_to_label_csv_path\n",
    "\n",
    "kfold_splits = 10 \n",
    "test_size = 0.1\n",
    "\n",
    "embedding_dimension = 200 # 300\n",
    "batch_size = 16 \n",
    "nb_epochs = 100\n",
    "dropout = 0.3 \n",
    "recurrent_dropout=  0.5 \n",
    "patience = 10\n",
    "verbose = 1\n",
    "\n",
    "useF1Score = True # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original: separating data into test and input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt.create_caption_to_label(oasis_csv_path,human_caption_csv_path, human_output_caption_to_label_csv_path,neutralLow, neutralHigh)\n",
    "# dt.create_caption_to_label(oasis_csv_path,auto_caption_csv_path, auto_output_caption_to_label_csv_path,neutralLow, neutralHigh)\n",
    "\n",
    "# df = pd.read_csv(dataset_path, header=0, sep=\"|\")\n",
    "# df[\"caption\"] = df[\"caption\"].apply(lambda x: \" \".join(caput.get_words_withoutstopwords(x.lower().split())))\n",
    "# df[\"label\"] = df[\"label\"].apply(lambda x: caput.change_label_str_to_int(x))\n",
    "\n",
    "\n",
    "\n",
    "# input_x, test_x, input_y,  test_y = train_test_split(df[\"caption\"],\n",
    "#                                                      df[\"label\"],\n",
    "#                                                      test_size=test_size,\n",
    "#                                                      random_state=seed,\n",
    "#                                                      stratify=df[\"label\"])\n",
    "\n",
    "# inputDataset = pd.concat([input_x, input_y], axis=1)\n",
    "# testDataset = pd.concat([test_x, test_y], axis=1)\n",
    "\n",
    "# inputDataset = inputDataset.dropna()\n",
    "# testDataset = testDataset.dropna()\n",
    "# inputDataset = inputDataset.reset_index()\n",
    "# testDataset = testDataset.reset_index()\n",
    "\n",
    "\n",
    "# inputDataset.to_csv(inputDataset_csv_path, index=False, sep=\"|\")\n",
    "# testDataset.to_csv(testDataset_csv_path, index=False, sep=\"|\")\n",
    "\n",
    "# print(\"df.head()\\n\", df.head())\n",
    "# print(\"\\n\")\n",
    "# print(\"df.tail()\\n\", df.tail())\n",
    "# print(\"\\n\")\n",
    "# print(\"inputDataset.head()\\n\", inputDataset.head())\n",
    "# print(\"testDataset.head()\\n\", testDataset.head())\n",
    "# print(\"\\n\")\n",
    "# print(\"Label distribution in inputDataset\", inputDataset.groupby('label').label.count())\n",
    "# print(\"Label distribution in testDataset\", testDataset.groupby('label').label.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common way of separating data into input and test\n",
    "\n",
    "### Divide data into train/val/test datasets\n",
    "\n",
    "Read dataframe to have:\n",
    "\n",
    "<imageName, caption, label>\n",
    "\n",
    "1. Read into df <imageId, label>\n",
    "2. Then separate data into input and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label distribution in inputDataset label\n",
      "-1    147\n",
      " 0    378\n",
      " 1    285\n",
      "Name: label, dtype: int64\n",
      "Label distribution in testDataset label\n",
      "-1    16\n",
      " 0    42\n",
      " 1    32\n",
      "Name: label, dtype: int64\n",
      "Input data size 810\n",
      "Test data size 90\n",
      "head:\n",
      "\n",
      "   index    id                                            caption  label  \\\n",
      "0      1   I10  bar several bottles wine partially-filled wine...      0   \n",
      "1      5  I103  smiling woman wearing orange top blue shorts, ...      1   \n",
      "2      8  I106  three men two women dressed medieval costumes ...      1   \n",
      "3     13  I110  three boys playing refugee camp tents behind t...      0   \n",
      "4     14  I111  person wearing hat coat sunburned faced lookin...      0   \n",
      "5     19  I116  blue car hood smashed side road people looking...     -1   \n",
      "6     60  I153       group male workers, mostly children factory.      0   \n",
      "7     79  I170  cup coffee heart shape made milk foam, saucer ...      1   \n",
      "8     86  I177  leafless tree, covered snow. ground tree also ...      1   \n",
      "9     96  I186  man woman embracing water's edge beach. woman ...      1   \n",
      "\n",
      "             image_name  \n",
      "0         Alcohol 7.jpg  \n",
      "1  Bungee jumping 3.jpg  \n",
      "2         Camping 3.jpg  \n",
      "3         Camping 8.jpg  \n",
      "4         Camping 9.jpg  \n",
      "5    Car accident 1.jpg  \n",
      "6     Child labor 1.jpg  \n",
      "7          Coffee 1.jpg  \n",
      "8            Cold 7.jpg  \n",
      "9          Couple 4.jpg  \n",
      "tail\n",
      "\n",
      "    index    id                                            caption  label  \\\n",
      "80    780  I801  white, purple, red, green, blue, orange shippi...      0   \n",
      "81    799  I819  operating room patient lying covered table sur...      0   \n",
      "82    804  I823  swimmer pool lane markers turning head take br...      1   \n",
      "83    810  I829  purple lightning purple sky, causing lens flar...      0   \n",
      "84    834  I850  tornado distance. house green roof tree foregr...     -1   \n",
      "85    851  I866  black white photo man camouflage uniform holdi...      0   \n",
      "86    863  I877  three-tiered cake, pink yellow frosting it, pu...      1   \n",
      "87    864  I878  black white photo man's hand underneath woman'...      1   \n",
      "88    872  I885  row chairs tables set meal red napkins inverte...      0   \n",
      "89    895   I95             square section stones laid brick wall.      0   \n",
      "\n",
      "            image_name  \n",
      "80       Storage 2.jpg  \n",
      "81       Surgery 4.jpg  \n",
      "82      Swimming 1.jpg  \n",
      "83  Thunderstorm 5.jpg  \n",
      "84       Tornado 3.jpg  \n",
      "85           War 3.jpg  \n",
      "86       Wedding 4.jpg  \n",
      "87       Wedding 5.jpg  \n",
      "88      Wedding 12.jpg  \n",
      "89        Bricks 1.jpg  \n"
     ]
    }
   ],
   "source": [
    "dt.create_caption_to_label(oasis_csv_path,human_caption_csv_path, human_output_caption_to_label_csv_path,neutralLow, neutralHigh)\n",
    "dt.create_caption_to_label(oasis_csv_path,auto_caption_csv_path, auto_output_caption_to_label_csv_path,neutralLow, neutralHigh)\n",
    "\n",
    "dfImageIdCaptionLabel = pd.read_csv(dataset_path, header=0, sep=\"|\")\n",
    "dfImageIdCaptionLabel.columns = [\"id\",\"caption\", \"label\"]\n",
    "dfImageIdCaptionLabel[\"caption\"] = dfImageIdCaptionLabel[\"caption\"].apply(lambda x: \" \".join(caput.get_words_withoutstopwords(x.lower().split())))\n",
    "#dfImageIdCaptionLabel[\"label\"] = dfImageIdCaptionLabel[\"label\"].apply(lambda x: caput.change_label_str_to_int(x))\n",
    "\n",
    "\n",
    "dfImageIdImageName = dt.get_image_id_to_image_title_as_df(oasis_csv_path)\n",
    "dfImageIdImageName.columns = ['id', 'image_name']\n",
    "dfImageIdImageName['image_name'] = dfImageIdImageName['image_name'].apply(lambda x: x + \".jpg\") \n",
    "printCnt = 5\n",
    "# has [id, caption, label]\n",
    "df = pd.merge(dfImageIdCaptionLabel, dfImageIdImageName, on=\"id\")\n",
    "df[\"label\"] = df[\"label\"].apply(lambda x: caput.change_label_str_to_int(x))\n",
    "#print(df.head(printCnt))\n",
    "\n",
    "\n",
    "\n",
    "input_x, test_x, input_y,  test_y = train_test_split(df[\"id\"],\n",
    "                                                     df[\"label\"],\n",
    "                                                     test_size=test_size,\n",
    "                                                     random_state=seed,\n",
    "                                                     stratify=df[\"label\"])\n",
    "\n",
    "inputDataset = pd.concat([input_x, input_y], axis=1)\n",
    "testDataset = pd.concat([test_x, test_y], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# print(\"inputDataset\\n\", inputDataset.head(10))\n",
    "# print(\"testDataset\\n\", testDataset.head(10))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Label distribution in inputDataset\", inputDataset.groupby('label').label.count())\n",
    "print(\"Label distribution in testDataset\", testDataset.groupby('label').label.count())\n",
    "\n",
    "\n",
    "inputDataset = df.loc[df['id'].isin(inputDataset.id)]\n",
    "testDataset = df.loc[df['id'].isin(testDataset.id)]\n",
    "\n",
    "\n",
    "inputDataset = inputDataset.dropna()\n",
    "testDataset = testDataset.dropna()\n",
    "inputDataset = inputDataset.reset_index()\n",
    "testDataset = testDataset.reset_index()\n",
    "\n",
    "# print(\"inputData\\n\", inputData.head())\n",
    "# print(\"testData\\n\", testData.head())\n",
    "\n",
    "inputIds = set(inputDataset['id'].values)\n",
    "testIds = set(testDataset['id'].values)\n",
    "\n",
    "print(\"Input data size\", len(inputIds))\n",
    "print(\"Test data size\", len(testIds))\n",
    "\n",
    "for inputId in inputIds:\n",
    "    if inputId in testIds:\n",
    "        raise inputId + \" inputId exists both in test and input dataset\"\n",
    "        \n",
    "for testId in testIds:\n",
    "    if testId in inputIds:\n",
    "        raise testId + \" testId exists both in test and input dataset\"        \n",
    "\n",
    "#inputDataset.head()\n",
    "print(\"head:\\n\")\n",
    "print(testDataset.head(10))\n",
    "print(\"tail\\n\")\n",
    "print(testDataset.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size : 1193514\n",
      "embedding dimension : (200,)\n"
     ]
    }
   ],
   "source": [
    "def load_embedding(path):\n",
    "    word2vec = {}\n",
    "    with io.open(path, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            entries = line.rstrip().split(\" \")\n",
    "            word, entries = entries[0], entries[1:]\n",
    "            word2vec[word] = np.array(entries).astype(np.float) # Convert String type to float\n",
    "    print('embedding size : %d' % len(word2vec))\n",
    "    print('embedding dimension : %s' % (word2vec['apple'].shape,))\n",
    "    return word2vec\n",
    "    \n",
    "wordToVec = {}\n",
    "wordToVec = load_embedding(fasttext_embedding_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(max_seq_len, num_of_classes, config): \n",
    "    # Cross-validation results: 0.61% (+/- 0.13%)\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=(None, config['embedding_dimension'])))\n",
    "    model.add(LSTM(max_seq_len, return_sequences=True, dropout=config['dropout'], recurrent_dropout=config['recurrent_dropout'])) \n",
    "    model.add(LSTM(max_seq_len, dropout=config['dropout'], recurrent_dropout=config['recurrent_dropout'])) \n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "    \n",
    "    if config['useF1Score']:\n",
    "        metrics = ['accuracy', sc.f1, sc.recall, sc.precision]\n",
    "    else:\n",
    "        metrics = ['accuracy']\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "                      metrics=metrics)\n",
    "    #print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evalaute_on_test_data(model, testDataset, inputDataset, wordToVec, config):\n",
    "    print(\"filenames: \", testDataset['image_name'].values)\n",
    "    max_seq_len = int(testDataset['caption'].map(lambda x: caput.get_non_stop_word_count(x.split())).max())\n",
    "    print(\"max_seq_len\", max_seq_len)\n",
    "    num_of_classes, class_to_index, index_to_class = caput.get_label_map_from_train_set(inputDataset, wordToVec, max_seq_len, config)\n",
    "    X_test, y_test_index, _, _, _  = caput.load_dataset_StratifiedKFold(testDataset,wordToVec,max_seq_len,class_to_index, index_to_class, config)\n",
    "    y_test = caput.convert_index_to_one_hot(y_test_index, num_of_classes) \n",
    "    print(model.summary())\n",
    "    results = model.evaluate(X_test, y_test, verbose=1) # batch_size=1,\n",
    "    print(model.metrics_names, results)\n",
    "        \n",
    "    predictions = model.predict(X_test, verbose=1)    \n",
    "    print(\"predictions:\\n\",predictions)\n",
    "    print(\"\\n\")\n",
    "    print(\"class_to_index:\", class_to_index)\n",
    "    print(\"index_to_class:\", index_to_class)\n",
    "    predictionClasses = imut.conver_predictions_to_classes(predictions, class_to_index)\n",
    "    y_test_classes = [index_to_class[k] for k in y_test_index]\n",
    "    y_true = y_test_classes\n",
    "    print(\"y_true:\\n\", y_true)\n",
    "    print(\"\\n\")\n",
    "    y_pred = predictionClasses\n",
    "    print(\"y_pred:\\n\", y_pred)\n",
    "    \n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    print(\"cnf_matrix\", cnf_matrix)\n",
    "    titleOfConfusionMatrix = \"Confusion Matrix based on GRU based Seq2seq model on captions\"\n",
    "    pt.plot_confusion_matrix_from_labels(y_true, y_pred, titleOfConfusionMatrix)\n",
    "    misLabeledCount = 0\n",
    "    for index, row in testDataset.iterrows():\n",
    "        caption = row['caption']\n",
    "        label = row['label']\n",
    "        if label != y_true[index]:\n",
    "            print(caption)\n",
    "            raise \"Unexpected result, truth labels should have matched, seems the order is messed up\"\n",
    "        if label != y_pred[index]:\n",
    "            print(caption,\"TL\", label,\"PL\", y_pred[index])\n",
    "            misLabeledCount += 1 \n",
    "    print(\"\\n\")\n",
    "    print(\"Mislabeled count: \", misLabeledCount)\n",
    "\n",
    "\n",
    "def train_StratifiedKFold(inputDataset, testDataset, wordToVec, config):\n",
    "    \"\"\"StratifiedKFold cross-validation\"\"\"\n",
    "    # Shuffle dataset\n",
    "    df = shuffle(inputDataset)\n",
    "    X = df[\"caption\"]\n",
    "    y = df[\"label\"]\n",
    "    print(\"Label distribution: \",df.groupby('label').label.count())\n",
    "    max_seq_len = int(df['caption'].map(lambda x: caput.get_non_stop_word_count(x.split())).max())\n",
    "    print(\"max_seq_len\", max_seq_len)\n",
    "    \n",
    "    # Instantiate the cross validator\n",
    "    skf = StratifiedKFold(n_splits=kfold_splits, shuffle=True)\n",
    "    cv_accuracies = []\n",
    "    cv_f1s = []\n",
    "    \n",
    "    best_model = None\n",
    "    best_model_best_acc = -1\n",
    "    \n",
    "    # Loop through the indices the split() method returns\n",
    "    for index, (train_indices, val_indices) in enumerate(skf.split(X, y)):\n",
    "        print(\"train_indices[:5]\", train_indices[:5],\"train_indices[-5:]\",train_indices[-5:])\n",
    "        print(\"val_indices[:5]\", val_indices[:5],\"val_indices[-5:]\",val_indices[-5:])\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        start = time.time()        \n",
    "        class_to_index = {}\n",
    "        index_to_class = {}\n",
    "        \n",
    "        X_train_caption, X_val_caption = X[train_indices], X[val_indices]\n",
    "        y_train_index, y_val_index = y[train_indices], y[val_indices]\n",
    "        \n",
    "        dfTrain = pd.concat([X_train_caption, y_train_index], axis=1)\n",
    "        dfTrain.columns = ['caption', 'label']\n",
    "        \n",
    "        print(dfTrain.head())\n",
    "        \n",
    "        X_train, y_train_index, num_of_classes, class_to_index, index_to_class = \\\n",
    "            caput.load_dataset_StratifiedKFold(\n",
    "                            dfTrain,\n",
    "                            wordToVec, \n",
    "                            max_seq_len, \n",
    "                            class_to_index, \n",
    "                            index_to_class,\n",
    "                            config)\n",
    "        y_train = caput.convert_index_to_one_hot(y_train_index, num_of_classes) \n",
    "        \n",
    "#         y_ints = [y.argmax() for y in y_train]\n",
    "#         class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  np.unique(y_ints),\n",
    "#                                                  y_ints)\n",
    "#         print(\"class_weights\", class_weights)\n",
    "        print(\"class_to_index\", class_to_index)\n",
    "        print(\"index_to_class\", index_to_class)\n",
    "        \n",
    "        dfVal= pd.concat([X_val_caption, y_val_index], axis=1)\n",
    "        dfVal.columns = ['caption', 'label']\n",
    "        X_val, y_val_index, _, _, _ = caput.load_dataset_StratifiedKFold(\n",
    "                            dfVal,\n",
    "                            wordToVec,\n",
    "                            max_seq_len, \n",
    "                            class_to_index, \n",
    "                            index_to_class,\n",
    "                            config)\n",
    "        y_val = caput.convert_index_to_one_hot(y_val_index, num_of_classes) \n",
    "        \n",
    "        \n",
    "        print(\"\\nTRAIN size:\", len(train_indices), \"\\t VAL size:\", len(val_indices))\n",
    "        print(\"Train label distribution: \",dfTrain.groupby('label').label.count())\n",
    "        print(\"Val label distribution: \",dfVal.groupby('label').label.count())\n",
    "\n",
    "        \n",
    "        model = build_model(max_seq_len,num_of_classes, config)\n",
    "        \n",
    "        plot_model(model, to_file = model_results_root_dir + '/model.png', show_shapes=True, show_layer_names=True)#\n",
    "        \n",
    "        \n",
    "        # Log to tensorboard\n",
    "        tensorBoardCallback = TensorBoard(log_dir=model_results_root_dir + '/logs', write_graph=True)\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                  factor=0.5, \n",
    "                                  patience=2, \n",
    "                                  min_lr=1e-7,\n",
    "                                  cooldown=1,\n",
    "                                  verbose=1)\n",
    "        \n",
    "        history = {}\n",
    "        filename = \"\"\n",
    "        # checkpoint\n",
    "        filepath= model_results_root_dir + \"/weights.best.h5\"\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "        \n",
    "        callbacks_list = [checkpoint,  reduce_lr, early_stopping, tensorBoardCallback]  # \n",
    "        \n",
    "        history = model.fit(x=X_train,\n",
    "                      y=y_train, \n",
    "                      batch_size=config['batch_size'],\n",
    "                      epochs=config['nb_epochs'], \n",
    "                      verbose=config['verbose'], \n",
    "                      validation_data = (X_val, y_val),\n",
    "                      shuffle=True,\n",
    "                      callbacks=callbacks_list)        # \n",
    "        val_acc_list = history.history['val_acc']\n",
    "        best_val_acc =  max(val_acc_list)\n",
    "        cv_accuracies.append(best_val_acc)\n",
    "        print(\"best_val_acc: \", best_val_acc)\n",
    "        \n",
    "        if config['useF1Score']:\n",
    "            val_f1_list = history.history['val_f1']\n",
    "            best_f1 =  max(val_f1_list)\n",
    "            print(\"best_f1: \", best_f1)\n",
    "            cv_f1s.append(best_f1)\n",
    "        \n",
    "        filename = \"caption\" \n",
    "        filename = model_results_root_dir + caput.generate_model_name(filename, best_val_acc) + \".h5\"\n",
    "        os.rename(filepath, filename)\n",
    "        \n",
    "        pt.plot_model_accuracy(history,model_results_root_dir, config['useF1Score'])\n",
    "        \n",
    "        end = time.time()\n",
    "        print(\"Time passed for training\", (end-start))\n",
    "        \n",
    "        if best_val_acc > best_model_best_acc:\n",
    "            best_model_best_acc = best_val_acc\n",
    "            best_model = model\n",
    "    \n",
    "    print(\"=========================================\")\n",
    "    print(\"Cross-validation val accuracy results: \" , cv_accuracies)\n",
    "    print(\"Cross-validation val accuracy results: %.2f%% (+/- %.2f%%)\" % (np.mean(cv_accuracies), np.std(cv_accuracies)))\n",
    "    \n",
    "    print(\"\\n\",\"Cross-validation val f1 results: \" , cv_f1s)\n",
    "    print(\"Cross-validation val f1 results: %.2f%% (+/- %.2f%%)\" % (np.mean(cv_f1s), np.std(cv_f1s)))\n",
    "    \n",
    "    best_model.save(model_results_root_dir + \"/bestmodel-\" + str(best_model_best_acc) + \".h5\")\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def get_config():\n",
    "    conf = {}\n",
    "    conf[\"kfold_splits\"] = kfold_splits\n",
    "    conf[\"batch_size\"] = batch_size\n",
    "    conf['embedding_dimension'] = embedding_dimension\n",
    "    conf['recurrent_dropout'] = recurrent_dropout\n",
    "    conf['dropout'] = dropout\n",
    "    conf[\"nb_epochs\"] = nb_epochs\n",
    "    conf['useF1Score'] = useF1Score\n",
    "    conf['verbose'] = verbose\n",
    "    conf['useF1Score'] = useF1Score\n",
    "    conf['seed'] = seed\n",
    "    return conf    \n",
    "    \n",
    "best_model = None\n",
    "def main():\n",
    "    global wordToVec, best_model\n",
    "    config = get_config()\n",
    "    print(\"config:\\n\", config)\n",
    "    if wordToVec is None:\n",
    "        wordToVec = load_embedding(fasttext_embedding_path)\n",
    "    print(\"# words: \", len(wordToVec.keys()),\" word vector dimension\", len(wordToVec[list(wordToVec.keys())[1]]))\n",
    "    best_model = train_StratifiedKFold(inputDataset, testDataset, wordToVec, config)\n",
    "    # Evaluate Test data set\n",
    "    evalaute_on_test_data(best_model, testDataset, inputDataset, wordToVec, config)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # execute only if run as a script\n",
    "    #main()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_56 (Masking)         (None, None, 200)         0         \n",
      "_________________________________________________________________\n",
      "lstm_111 (LSTM)              (None, None, 38)          36328     \n",
      "_________________________________________________________________\n",
      "lstm_112 (LSTM)              (None, 38)                11704     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 3)                 117       \n",
      "=================================================================\n",
      "Total params: 48,149\n",
      "Trainable params: 48,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "best_model_path = model_results_root_dir + \"bestmodel-0.7682926829268293.h5\" \n",
    "custom_objects={'f1': sc.f1, 'recall': sc.recall, 'precision': sc.precision}\n",
    "model = load_model(best_model_path, custom_objects)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filenames:  ['Alcohol 7.jpg' 'Bungee jumping 3.jpg' 'Camping 3.jpg' 'Camping 8.jpg'\n",
      " 'Camping 9.jpg' 'Car accident 1.jpg' 'Child labor 1.jpg' 'Coffee 1.jpg'\n",
      " 'Cold 7.jpg' 'Couple 4.jpg' 'Couple 8.jpg' 'Crosswalk 1.jpg' 'Cups 1.jpg'\n",
      " 'Cups 4.jpg' 'Dancing 7.jpg' 'Dead bodies 3.jpg' 'Depressed pose 3.jpg'\n",
      " 'Dessert 3.jpg' 'Doctor 3.jpg' 'Dog 3.jpg' 'Dog 6.jpg' 'Dog 11.jpg'\n",
      " 'Dog 19.jpg' 'Dog 20.jpg' 'Dog 31.jpg' 'Fire hydrant 1.jpg'\n",
      " 'Flowers 7.jpg' 'Flowers 10.jpg' 'Food 1.jpg' 'Food 5.jpg'\n",
      " 'Frustrated pose 1.jpg' 'Frustrated pose 2.jpg' 'Funeral 1.jpg'\n",
      " 'Gazing 6.jpg' 'Graveyard 1.jpg' 'Gun 9.jpg' 'Hangover 1.jpg'\n",
      " 'House 1.jpg' 'KKK rally 2.jpg' 'Lightning 2.jpg' 'Meerkat 1.jpg'\n",
      " 'Memorial 3.jpg' 'Miserable pose 5.jpg' 'Monkey 1.jpg' 'Mother 3.jpg'\n",
      " 'Mother 6.jpg' 'Nude couple 12.jpg' 'Nude man 8.jpg' 'Nude woman 5.jpg'\n",
      " 'Nude woman 14.jpg' 'BDSM 3.jpg' 'Nude woman 19.jpg' 'Paperclips 3.jpg'\n",
      " 'Paperclips 4.jpg' 'Penguins 2.jpg' 'Picnic 1.jpg' 'Pigeon 2.jpg'\n",
      " 'Police 3.jpg' 'Present 1.jpg' 'Rafting 2.jpg' 'Rafting 6.jpg'\n",
      " 'Rocks 4.jpg' 'Rocks 5.jpg' 'Roofing 1.jpg' 'Sad pose 3.jpg'\n",
      " 'Sad pose 5.jpg' 'Scared cat 1.jpg' 'School 5.jpg' 'Shark 10.jpg'\n",
      " 'Shot 4.jpg' 'Shot 5.jpg' 'Sidewalk 6.jpg' 'Bird 2.jpg' 'Bird 3.jpg'\n",
      " 'Smiling face 1.jpg' 'Bird 5.jpg' 'Soldiers 2.jpg' 'Soldiers 7.jpg'\n",
      " 'Statue 1.jpg' 'Stingray 1.jpg' 'Storage 2.jpg' 'Surgery 4.jpg'\n",
      " 'Swimming 1.jpg' 'Thunderstorm 5.jpg' 'Tornado 3.jpg' 'War 3.jpg'\n",
      " 'Wedding 4.jpg' 'Wedding 5.jpg' 'Wedding 12.jpg' 'Bricks 1.jpg']\n",
      "max_seq_len 38\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_56 (Masking)         (None, None, 200)         0         \n",
      "_________________________________________________________________\n",
      "lstm_111 (LSTM)              (None, None, 38)          36328     \n",
      "_________________________________________________________________\n",
      "lstm_112 (LSTM)              (None, 38)                11704     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 3)                 117       \n",
      "=================================================================\n",
      "Total params: 48,149\n",
      "Trainable params: 48,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "class_to_index {0: 0, 1: 1, -1: 2}\n",
      "index_to_class {0: 0, 1: 1, 2: -1}\n",
      "90/90 [==============================] - 0s 1ms/step\n",
      "['loss', 'acc', 'f1', 'recall', 'precision'] [0.641032542122735, 0.7222222261958652, 0.7120750824610392, 0.6666666719648573, 0.76653141313129]\n",
      "\n",
      "\n",
      "class_to_index: {0: 0, 1: 1, -1: 2}\n",
      "index_to_class: {0: 0, 1: 1, 2: -1}\n",
      "y_true:\n",
      " [0, 1, 1, 0, 0, -1, 0, 1, 1, 1, 1, 0, 0, 0, 1, -1, -1, 1, 0, 1, 1, 1, 1, 1, -1, 0, 1, 1, 0, 1, -1, -1, -1, 1, 0, -1, -1, 0, -1, 0, 0, 0, -1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, -1, 0, -1, 1, 1, 1, 0, 0, -1, 1, 0, 0, 0, 1, 0, -1, 0, 1, 1, 0, 0]\n",
      "\n",
      "\n",
      "y_pred:\n",
      " [0, 1, 0, 1, 0, -1, 1, 1, 0, 1, 1, 0, 0, 0, 0, -1, 1, 1, 0, 1, 1, 1, -1, 0, 0, 0, 1, 1, -1, 0, 1, 0, 0, 1, 1, -1, 0, 0, -1, 0, -1, 0, -1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, -1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, -1, 0, 1, 1, 0, 0]\n",
      "cnf_matrix [[ 7  6  3]\n",
      " [ 3 33  6]\n",
      " [ 1  6 25]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three men two women dressed medieval costumes sit benches wooden table. table horn, furred hat, apple it. shield nearby. TL 1 PL 0\n",
      "three boys playing refugee camp tents behind them. TL 0 PL 1\n",
      "group male workers, mostly children factory. TL 0 PL 1\n",
      "leafless tree, covered snow. ground tree also covered snow, tracks seen right tree. TL 1 PL 0\n",
      "three girls ring holding hands. outdoors. brown skin straight black hair. TL 1 PL 0\n",
      "black white photo woman sitting ground one hand face top head. TL -1 PL 1\n",
      "dog leash mouth open, looking alertly towards camera. TL 1 PL -1\n",
      "white dog running across grass ears flying. TL 1 PL 0\n",
      "brown dog paws nose fence looking it. TL -1 PL 0\n",
      "pasta salad olives tomatoes TL 0 PL -1\n",
      "several containers raspberries. TL 1 PL 0\n",
      "dirty damaged photograph woman messy hair holding head hands. TL -1 PL 1\n",
      "man holding head hands. TL -1 PL 0\n",
      "man walks amidst crosses marking graves cemetery. TL -1 PL 0\n",
      "sunset small cemetery. TL 0 PL 1\n",
      "bald man head wooden table. grasps empty liquor bottle right hand. shot glass seen behind left arm. TL -1 PL 0\n",
      "weasel sitting upright like human being. TL 0 PL -1\n",
      "two women dressed leather, one bright red hair, black, sitting backs kneeling men. red-haired woman sits man full blue leather bondage attire, hands chained behind back. woman sits man dressed black leather bondage attire hands tied front him. TL 0 PL 1\n",
      "pigeon ground seeds scattered around it. TL 0 PL -1\n",
      "man sitting armchair hand covering eyes. TL -1 PL 0\n",
      "gray black striped cat stares much larger dog white muzzle brown black fur. TL 0 PL 1\n",
      "small white blue stones soil. TL -1 PL 1\n",
      "view soldier behind. wearing green beret bayonet visible muzzle rifle. TL -1 PL 0\n",
      "ray resting seabed small striped fish swimming it. TL 0 PL 1\n",
      "swimmer pool lane markers turning head take breath swimming. TL 1 PL 0\n",
      "\n",
      "\n",
      "Mislabeled count:  25\n",
      "\n",
      "\n",
      "imgToPrediction= {'Alcohol 7.jpg': array([0.97, 0.01, 0.02], dtype=float32), 'Bungee jumping 3.jpg': array([0.19, 0.81, 0.  ], dtype=float32), 'Camping 3.jpg': array([0.55, 0.45, 0.  ], dtype=float32), 'Camping 8.jpg': array([0.12, 0.88, 0.  ], dtype=float32), 'Camping 9.jpg': array([0.98, 0.01, 0.02], dtype=float32), 'Car accident 1.jpg': array([0.4 , 0.01, 0.58], dtype=float32), 'Child labor 1.jpg': array([0.29, 0.66, 0.05], dtype=float32), 'Coffee 1.jpg': array([0.04, 0.96, 0.  ], dtype=float32), 'Cold 7.jpg': array([0.89, 0.02, 0.09], dtype=float32), 'Couple 4.jpg': array([6.59e-02, 9.33e-01, 9.31e-04], dtype=float32), 'Couple 8.jpg': array([0.13, 0.86, 0.01], dtype=float32), 'Crosswalk 1.jpg': array([0.45, 0.19, 0.36], dtype=float32), 'Cups 1.jpg': array([0.57, 0.39, 0.03], dtype=float32), 'Cups 4.jpg': array([0.88, 0.09, 0.03], dtype=float32), 'Dancing 7.jpg': array([0.52, 0.48, 0.01], dtype=float32), 'Dead bodies 3.jpg': array([0.16, 0.04, 0.8 ], dtype=float32), 'Depressed pose 3.jpg': array([0.47, 0.49, 0.03], dtype=float32), 'Dessert 3.jpg': array([1.17e-02, 9.88e-01, 4.38e-04], dtype=float32), 'Doctor 3.jpg': array([0.95, 0.04, 0.01], dtype=float32), 'Dog 3.jpg': array([0.25, 0.67, 0.08], dtype=float32), 'Dog 6.jpg': array([0.04, 0.96, 0.  ], dtype=float32), 'Dog 11.jpg': array([0.24, 0.75, 0.  ], dtype=float32), 'Dog 19.jpg': array([0.32, 0.3 , 0.38], dtype=float32), 'Dog 20.jpg': array([0.49, 0.29, 0.23], dtype=float32), 'Dog 31.jpg': array([0.56, 0.28, 0.16], dtype=float32), 'Fire hydrant 1.jpg': array([0.74, 0.08, 0.18], dtype=float32), 'Flowers 7.jpg': array([2.14e-02, 9.78e-01, 8.44e-04], dtype=float32), 'Flowers 10.jpg': array([0.14, 0.85, 0.  ], dtype=float32), 'Food 1.jpg': array([0.24, 0.29, 0.47], dtype=float32), 'Food 5.jpg': array([0.55, 0.13, 0.32], dtype=float32), 'Frustrated pose 1.jpg': array([0.29, 0.44, 0.28], dtype=float32), 'Frustrated pose 2.jpg': array([0.44, 0.21, 0.35], dtype=float32), 'Funeral 1.jpg': array([0.6 , 0.13, 0.27], dtype=float32), 'Gazing 6.jpg': array([0.17, 0.83, 0.  ], dtype=float32), 'Graveyard 1.jpg': array([0.2 , 0.76, 0.05], dtype=float32), 'Gun 9.jpg': array([0.15, 0.  , 0.84], dtype=float32), 'Hangover 1.jpg': array([0.75, 0.  , 0.24], dtype=float32), 'House 1.jpg': array([0.98, 0.01, 0.01], dtype=float32), 'KKK rally 2.jpg': array([0.16, 0.01, 0.83], dtype=float32), 'Lightning 2.jpg': array([0.99, 0.  , 0.01], dtype=float32), 'Meerkat 1.jpg': array([0.1 , 0.02, 0.88], dtype=float32), 'Memorial 3.jpg': array([0.65, 0.02, 0.33], dtype=float32), 'Miserable pose 5.jpg': array([0.25, 0.13, 0.62], dtype=float32), 'Monkey 1.jpg': array([0.45, 0.15, 0.4 ], dtype=float32), 'Mother 3.jpg': array([0.38, 0.47, 0.15], dtype=float32), 'Mother 6.jpg': array([1.37e-02, 9.85e-01, 8.76e-04], dtype=float32), 'Nude couple 12.jpg': array([0.09, 0.9 , 0.  ], dtype=float32), 'Nude man 8.jpg': array([0.72, 0.28, 0.01], dtype=float32), 'Nude woman 5.jpg': array([0.25, 0.75, 0.01], dtype=float32), 'Nude woman 14.jpg': array([0.23, 0.7 , 0.07], dtype=float32), 'BDSM 3.jpg': array([0.17, 0.83, 0.  ], dtype=float32), 'Nude woman 19.jpg': array([0.94, 0.01, 0.04], dtype=float32), 'Paperclips 3.jpg': array([0.77, 0.06, 0.17], dtype=float32), 'Paperclips 4.jpg': array([0.56, 0.17, 0.26], dtype=float32), 'Penguins 2.jpg': array([0.04, 0.96, 0.  ], dtype=float32), 'Picnic 1.jpg': array([0.04, 0.95, 0.01], dtype=float32), 'Pigeon 2.jpg': array([0.17, 0.04, 0.8 ], dtype=float32), 'Police 3.jpg': array([0.92, 0.08, 0.  ], dtype=float32), 'Present 1.jpg': array([1.05e-02, 9.89e-01, 3.06e-04], dtype=float32), 'Rafting 2.jpg': array([0.73, 0.25, 0.02], dtype=float32), 'Rafting 6.jpg': array([0.54, 0.45, 0.  ], dtype=float32), 'Rocks 4.jpg': array([0.89, 0.05, 0.05], dtype=float32), 'Rocks 5.jpg': array([0.92, 0.07, 0.01], dtype=float32), 'Roofing 1.jpg': array([0.88, 0.02, 0.1 ], dtype=float32), 'Sad pose 3.jpg': array([0.54, 0.19, 0.27], dtype=float32), 'Sad pose 5.jpg': array([0.67, 0.04, 0.29], dtype=float32), 'Scared cat 1.jpg': array([0.3 , 0.7 , 0.01], dtype=float32), 'School 5.jpg': array([0.84, 0.09, 0.07], dtype=float32), 'Shark 10.jpg': array([0.82, 0.06, 0.12], dtype=float32), 'Shot 4.jpg': array([0.25, 0.  , 0.74], dtype=float32), 'Shot 5.jpg': array([0.75, 0.02, 0.22], dtype=float32), 'Sidewalk 6.jpg': array([0.42, 0.47, 0.11], dtype=float32), 'Bird 2.jpg': array([0.35, 0.37, 0.28], dtype=float32), 'Bird 3.jpg': array([0.1 , 0.89, 0.  ], dtype=float32), 'Smiling face 1.jpg': array([0.2, 0.8, 0. ], dtype=float32), 'Bird 5.jpg': array([0.44, 0.2 , 0.35], dtype=float32), 'Soldiers 2.jpg': array([0.94, 0.01, 0.05], dtype=float32), 'Soldiers 7.jpg': array([0.84, 0.03, 0.13], dtype=float32), 'Statue 1.jpg': array([2.70e-02, 9.72e-01, 6.49e-04], dtype=float32), 'Stingray 1.jpg': array([0.11, 0.88, 0.01], dtype=float32), 'Storage 2.jpg': array([0.88, 0.04, 0.08], dtype=float32), 'Surgery 4.jpg': array([0.81, 0.02, 0.17], dtype=float32), 'Swimming 1.jpg': array([0.51, 0.48, 0.01], dtype=float32), 'Thunderstorm 5.jpg': array([0.86, 0.14, 0.  ], dtype=float32), 'Tornado 3.jpg': array([0.15, 0.02, 0.84], dtype=float32), 'War 3.jpg': array([0.72, 0.04, 0.24], dtype=float32), 'Wedding 4.jpg': array([0.09, 0.91, 0.  ], dtype=float32), 'Wedding 5.jpg': array([3.22e-02, 9.67e-01, 5.15e-04], dtype=float32), 'Wedding 12.jpg': array([0.91, 0.08, 0.  ], dtype=float32), 'Bricks 1.jpg': array([0.87, 0.04, 0.08], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "def evalaute_on_test_data(model, testDataset, inputDataset, wordToVec, config):\n",
    "    print(\"filenames: \", testDataset['image_name'].values)\n",
    "    max_seq_len = int(testDataset['caption'].map(lambda x: caput.get_non_stop_word_count(x.split())).max())\n",
    "    print(\"max_seq_len\", max_seq_len)\n",
    "    #num_of_classes, class_to_index, index_to_class = caput.get_label_map_from_train_set(inputDataset, wordToVec, max_seq_len, config)\n",
    "    class_to_index = {}\n",
    "    index_to_class = {}\n",
    "    _, _, num_of_classes, class_to_index, index_to_class,_ = caput.load_dataset_StratifiedKFold(\n",
    "                                                                inputDataset,\n",
    "                                                                wordToVec, \n",
    "                                                                max_seq_len, \n",
    "                                                                class_to_index, \n",
    "                                                                index_to_class,\n",
    "                                                                config)\n",
    "    \n",
    "    X_test, y_test_index, _, _, _,filenames  = caput.load_dataset_StratifiedKFold(testDataset,wordToVec,max_seq_len,class_to_index, index_to_class, config)\n",
    "    y_test = caput.convert_index_to_one_hot(y_test_index, num_of_classes) \n",
    "    print(model.summary())\n",
    "    \n",
    "    print(\"class_to_index\", class_to_index)\n",
    "    print(\"index_to_class\", index_to_class)\n",
    "    \n",
    "    results = model.evaluate(X_test, y_test, verbose=1) # batch_size=1,\n",
    "    print(model.metrics_names, results)\n",
    "    predictions = []\n",
    "    imgToPrediction = {}\n",
    "    for x_test, image_name in zip(X_test, filenames):\n",
    "        prediction = model.predict(np.array([x_test]),batch_size=1, verbose=0)[0]    \n",
    "        #print(image_name,prediction)\n",
    "        predictions.append(prediction)\n",
    "        imgToPrediction[image_name] = prediction\n",
    "        \n",
    "    predictions = np.array(predictions)\n",
    "    #predictions = model.predict(X_test, verbose=1)    \n",
    "    #print(\"predictions:\\n\",predictions)\n",
    "    print(\"\\n\")\n",
    "    print(\"class_to_index:\", class_to_index)\n",
    "    print(\"index_to_class:\", index_to_class)\n",
    "    predictionClasses = imut.conver_predictions_to_classes(predictions, class_to_index)\n",
    "    y_test_classes = [index_to_class[k] for k in y_test_index]\n",
    "    y_true = y_test_classes\n",
    "    print(\"y_true:\\n\", y_true)\n",
    "    print(\"\\n\")\n",
    "    y_pred = predictionClasses\n",
    "    print(\"y_pred:\\n\", y_pred)\n",
    "    \n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    print(\"cnf_matrix\", cnf_matrix)\n",
    "    titleOfConfusionMatrix = \"Confusion Matrix based on GRU based Seq2seq model on captions\"\n",
    "    pt.plot_confusion_matrix_from_labels(y_true, y_pred, titleOfConfusionMatrix)\n",
    "    misLabeledCount = 0\n",
    "    for index, row in testDataset.iterrows():\n",
    "        caption = row['caption']\n",
    "        label = row['label']\n",
    "        if label != y_true[index]:\n",
    "            print(caption)\n",
    "            raise \"Unexpected result, truth labels should have matched, seems the order is messed up\"\n",
    "        if label != y_pred[index]:\n",
    "            print(caption,\"TL\", label,\"PL\", y_pred[index])\n",
    "            misLabeledCount += 1 \n",
    "    print(\"\\n\")\n",
    "    print(\"Mislabeled count: \", misLabeledCount)\n",
    "    print(\"\\n\")\n",
    "    print(\"imgToPrediction=\",imgToPrediction)\n",
    "    \n",
    "evalaute_on_test_data(model, testDataset, inputDataset, wordToVec, get_config())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>caption</th>\n",
       "      <th>label</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I10</td>\n",
       "      <td>bar several bottles wine partially-filled wine...</td>\n",
       "      <td>0</td>\n",
       "      <td>Alcohol 7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I103</td>\n",
       "      <td>smiling woman wearing orange top blue shorts, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bungee jumping 3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>I106</td>\n",
       "      <td>three men two women dressed medieval costumes ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Camping 3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>I110</td>\n",
       "      <td>three boys playing refugee camp tents behind t...</td>\n",
       "      <td>0</td>\n",
       "      <td>Camping 8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>I111</td>\n",
       "      <td>person wearing hat coat sunburned faced lookin...</td>\n",
       "      <td>0</td>\n",
       "      <td>Camping 9.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    id                                            caption  label  \\\n",
       "0      1   I10  bar several bottles wine partially-filled wine...      0   \n",
       "1      5  I103  smiling woman wearing orange top blue shorts, ...      1   \n",
       "2      8  I106  three men two women dressed medieval costumes ...      1   \n",
       "3     13  I110  three boys playing refugee camp tents behind t...      0   \n",
       "4     14  I111  person wearing hat coat sunburned faced lookin...      0   \n",
       "\n",
       "             image_name  \n",
       "0         Alcohol 7.jpg  \n",
       "1  Bungee jumping 3.jpg  \n",
       "2         Camping 3.jpg  \n",
       "3         Camping 8.jpg  \n",
       "4         Camping 9.jpg  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataset.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
