{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import os, sys, re, string, pathlib, random, io, time, glob\n",
    "from collections import Counter, OrderedDict\n",
    "from shutil import copyfile, rmtree\n",
    "\n",
    "#import hecutils.resnet152 as resnet\n",
    "from hecutils.resnet152 import ResNet152\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import hecutils.data_utils as dt\n",
    "import hecutils.scoring_utils as sc\n",
    "import hecutils.plotting_utils as pt\n",
    "import hecutils.common_utils as cm\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "from keras.layers import GRU, Bidirectional, LSTM, MaxPooling1D, Conv1D,Dense, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.layers.core import Dropout, Flatten, Masking, ActivityRegularization\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing import text\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "\n",
    "# from fastText import load_model\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "num_cores = 8\n",
    "GPU=True\n",
    "CPU = not GPU\n",
    "\n",
    "if GPU:\n",
    "    num_GPU = 1\n",
    "    num_CPU = 8\n",
    "if CPU:\n",
    "    num_CPU = 8\n",
    "    num_GPU = 0\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : num_CPU, 'GPU' : num_GPU})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oasis_csv_path = \"dataset/metadata/OASIS.csv\"\n",
    "oasis_images_src = \"dataset/images/\"\n",
    "input_images_src = \"dataset/input2/\"\n",
    "test_images_src = \"dataset/test2/\"\n",
    "model_results_root_dir = \"img_model2/\"\n",
    "\n",
    "input_images_classified = \"dataset/input-classified2/\"\n",
    "test_images_classified = \"dataset/test-classified2/\"\n",
    "\n",
    "# ou can downlaod weights here: https://gist.github.com/flyyufelix/7e2eafb149f72f4d38dd661882c554a6\n",
    "weights_path = \"/home/elkhand/weights/resnet152_weights_tf.h5\"\n",
    "\n",
    "dataset_groups=[\"train\", \"val\"]\n",
    "classes = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "kfold_splits =  5\n",
    "\n",
    "neutralLow = 3.0\n",
    "neutralHigh = 5.0\n",
    "\n",
    "nb_epochs = 100\n",
    "patience = 10 # ReduceLROnPlateau has 5\n",
    "batch_size = 32 # 32  \n",
    "\n",
    "FC_SIZE = 256 # 1024\n",
    "LAYERS_TO_UNFREEZE = 10\n",
    "\n",
    "img_height = 224 # 299\n",
    "img_width = 224  # 299\n",
    "\n",
    "useF1Score = False\n",
    "verbose=1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data (to be used for model learning and validation) label distribution: \n",
      " OrderedDict([('negative', 147), ('neutral', 378), ('positive', 285)])\n",
      "\n",
      "Test data(never used for learning) label distribution: \n",
      " OrderedDict([('negative', 16), ('neutral', 42), ('positive', 32)])\n"
     ]
    }
   ],
   "source": [
    "image_names, image_labels = dt.get_image_name_and_label(oasis_csv_path, neutralLow, neutralHigh)\n",
    "\n",
    "imageNameToLabel = {}\n",
    "\n",
    "for img_name,label in zip(image_names, image_labels):\n",
    "    if img_name not in imageNameToLabel:\n",
    "        imageNameToLabel[img_name] = label\n",
    "    else:\n",
    "        raise \"There should not be images with same name: \" + img_name + label    \n",
    "        \n",
    "image_names = np.array(image_names)\n",
    "image_labels = np.array(image_labels)\n",
    "\n",
    "input_x, test_x, input_y,  test_y = train_test_split(image_names, image_labels,\n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=seed,\n",
    "                                                    stratify=image_labels)\n",
    "\n",
    "print(\"Input data (to be used for model learning and validation) label distribution: \\n\",pt.get_label_count(input_y))\n",
    "print()\n",
    "print(\"Test data(never used for learning) label distribution: \\n\",pt.get_label_count(test_y))\n",
    "\n",
    "\n",
    "# Delete input images dir\n",
    "rmtree(input_images_src, ignore_errors=True)\n",
    "os.makedirs(input_images_src)\n",
    "\n",
    "\n",
    "# Delete test images dir\n",
    "rmtree(test_images_src, ignore_errors=True)\n",
    "os.makedirs(test_images_src)\n",
    "\n",
    "\n",
    "# Copy input images into input dir, and test images into test dir\n",
    "cm.copy_imgs_into(oasis_images_src, input_x, input_images_src)\n",
    "cm.copy_imgs_into(oasis_images_src, test_x, test_images_src)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config:\n",
      " {'img_height': 224, 'img_width': 224, 'kfold_splits': 5, 'batch_size': 32, 'nb_epochs': 100, 'useF1Score': False, 'verbose': 1}\n",
      "Train size:  647\n",
      "Val size:  163\n",
      "Train label distribution:  OrderedDict([('negative', 117), ('neutral', 302), ('positive', 228)])\n",
      "Val label distribution:  OrderedDict([('negative', 30), ('neutral', 76), ('positive', 57)])\n",
      "Found 647 images belonging to 3 classes.\n",
      "Found 163 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elkhand/anaconda3/envs/cs231n/lib/python3.6/site-packages/ipykernel_launcher.py:54: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "62/62 [==============================] - 29s 471ms/step - loss: 1.7056 - acc: 0.4489 - val_loss: 0.8868 - val_acc: 0.5750\n",
      "Epoch 2/3\n",
      "62/62 [==============================] - 26s 422ms/step - loss: 1.1212 - acc: 0.5097 - val_loss: 0.8376 - val_acc: 0.6250\n",
      "Epoch 3/3\n",
      "62/62 [==============================] - 26s 424ms/step - loss: 0.9924 - acc: 0.5420 - val_loss: 0.8208 - val_acc: 0.6375\n",
      "Starting fune-tuning\n",
      "LAYERS_TO_UNFREEZE: 10 last layer id to freeze 716 total layers,  726\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 29s 465ms/step - loss: 0.9684 - acc: 0.5652 - val_loss: 0.8082 - val_acc: 0.6375\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 26s 417ms/step - loss: 0.8899 - acc: 0.5768 - val_loss: 0.8081 - val_acc: 0.5938\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 26s 416ms/step - loss: 0.8506 - acc: 0.5946 - val_loss: 0.7854 - val_acc: 0.6438\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 24s 393ms/step - loss: 0.8167 - acc: 0.6218 - val_loss: 0.8032 - val_acc: 0.6125\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 25s 398ms/step - loss: 0.7724 - acc: 0.6476 - val_loss: 0.7782 - val_acc: 0.6500\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 25s 403ms/step - loss: 0.7487 - acc: 0.6598 - val_loss: 0.7988 - val_acc: 0.6062\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 24s 384ms/step - loss: 0.7644 - acc: 0.6328 - val_loss: 0.7705 - val_acc: 0.6312\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 24s 390ms/step - loss: 0.7317 - acc: 0.6757 - val_loss: 0.7560 - val_acc: 0.6500\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 24s 393ms/step - loss: 0.7195 - acc: 0.6730 - val_loss: 0.7815 - val_acc: 0.6312\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 24s 392ms/step - loss: 0.7174 - acc: 0.6711 - val_loss: 0.8040 - val_acc: 0.6062\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 23s 374ms/step - loss: 0.6949 - acc: 0.6933 - val_loss: 0.7909 - val_acc: 0.6125\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 25s 396ms/step - loss: 0.6989 - acc: 0.6730 - val_loss: 0.7578 - val_acc: 0.6562\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 25s 408ms/step - loss: 0.6661 - acc: 0.7072 - val_loss: 0.7597 - val_acc: 0.6500\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 24s 383ms/step - loss: 0.6349 - acc: 0.7259 - val_loss: 0.7425 - val_acc: 0.6500\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 25s 396ms/step - loss: 0.6666 - acc: 0.7095 - val_loss: 0.7524 - val_acc: 0.6500\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 24s 390ms/step - loss: 0.6434 - acc: 0.7197 - val_loss: 0.7347 - val_acc: 0.6813\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 25s 405ms/step - loss: 0.6120 - acc: 0.7297 - val_loss: 0.7429 - val_acc: 0.6625\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 24s 387ms/step - loss: 0.6421 - acc: 0.7218 - val_loss: 0.7425 - val_acc: 0.6813\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 25s 408ms/step - loss: 0.6377 - acc: 0.7253 - val_loss: 0.7414 - val_acc: 0.6875\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 25s 401ms/step - loss: 0.6040 - acc: 0.7326 - val_loss: 0.7315 - val_acc: 0.6875\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 25s 405ms/step - loss: 0.6139 - acc: 0.7278 - val_loss: 0.7464 - val_acc: 0.6625\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 25s 404ms/step - loss: 0.5995 - acc: 0.7374 - val_loss: 0.7486 - val_acc: 0.6750\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 26s 415ms/step - loss: 0.5960 - acc: 0.7476 - val_loss: 0.7587 - val_acc: 0.6687\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 26s 418ms/step - loss: 0.6255 - acc: 0.7200 - val_loss: 0.7647 - val_acc: 0.6750\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "Epoch 25/100\n",
      "46/62 [=====================>........] - ETA: 6s - loss: 0.5920 - acc: 0.7321"
     ]
    }
   ],
   "source": [
    "# Instantiate the cross validator\n",
    "skf = StratifiedKFold(n_splits=kfold_splits, shuffle=True)\n",
    "cv_accuracies = []\n",
    "cv_f1s = []\n",
    "    \n",
    "X = input_x\n",
    "y = input_y\n",
    "    \n",
    "# Shuffe input data\n",
    "X, y = shuffle(X,y)\n",
    "\n",
    "def setup_to_finetune(model, useF1Score):\n",
    "    \"\"\"Freeze the bottom LAYERS_TO_FREEZE and retrain the remaining top layers.\n",
    "  note: LAYERS_TO_FREEZE corresponds to the top 2 inception blocks in the inceptionv3 arch\n",
    "  Args:\n",
    "    model: keras model\n",
    "    \"\"\"    \n",
    "    totalLayers = len(model.layers)\n",
    "    lastFreezeLayer = totalLayers - LAYERS_TO_UNFREEZE\n",
    "    print(\"LAYERS_TO_UNFREEZE:\", LAYERS_TO_UNFREEZE, \"last layer id to freeze\", lastFreezeLayer, \"total layers, \",totalLayers)\n",
    "    for layer in model.layers[:lastFreezeLayer]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[lastFreezeLayer:]:\n",
    "        layer.trainable = True\n",
    "    #optimizers.SGD(lr=0.0001, momentum=0.9)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy',\\\n",
    "                  metrics=cm.get_metrics(useF1Score))\n",
    "\n",
    "def setup_to_transfer_learn(model, base_model, useF1Score):\n",
    "    \"\"\"Freeze all layers and compile the model\"\"\"    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "       \n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', \\\n",
    "                  metrics=cm.get_metrics(useF1Score))\n",
    "    print()\n",
    "\n",
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    \"\"\"Add last layer to the convnet\n",
    "      Args:\n",
    "        base_model: keras model excluding top\n",
    "        nb_classes: # of classes\n",
    "      Returns:\n",
    "        new keras model with last layer\n",
    "    \"\"\"\n",
    "    # 62,65,67% w/o reducing lr\n",
    "    x = base_model.output\n",
    "    x = Dropout(0.5)(x)\n",
    "    # convert MxNxC into 1xC\n",
    "    #x = GlobalAveragePooling2D()(x)\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(FC_SIZE, activation='relu')(x) #new FC layer, random init\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(nb_classes, activation='softmax')(x) #new softmax layer\n",
    "    model = Model(input=base_model.input, output=output_layer)\n",
    "    #print(model.summary())\n",
    "    \n",
    "#     x = base_model.output\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     output_layer = Dense(nb_classes, activation='softmax', name='softmax')(x)\n",
    "#     model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(trainDir, valDir, config): \n",
    "    \"\"\"Use transfer learning and fine-tuning to train a network on a new dataset\"\"\"     \n",
    "    \n",
    "    nb_classes = len(glob.glob(trainDir + \"/*\"))\n",
    "    \n",
    "    # this is a generator that will read pictures found in\n",
    "    # subfolers of 'data/train', and indefinitely generate\n",
    "    # batches of augmented image data\n",
    "    isForTrain = True\n",
    "    train_batches = cm.get_data_generator(trainDir, config, isForTrain)  \n",
    "    \n",
    "\n",
    "    # this is a similar generator, for validation data\n",
    "    isForTrain = False\n",
    "    validation_batches = cm.get_data_generator(valDir, config, isForTrain)  \n",
    "        \n",
    "    # setup model\n",
    "    base_model = ResNet152(include_top=False, weights='imagenet')\n",
    "    model = add_new_last_layer(base_model, nb_classes)\n",
    "\n",
    "    # transfer learning\n",
    "    setup_to_transfer_learn(model, base_model, config['useF1Score'])\n",
    "    \n",
    "    # monitor='val_loss', patience = 5 default\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                  factor=0.7, \n",
    "                                  patience=2,\n",
    "                                  min_delta=0.0001,\n",
    "                                  cooldown=1,\n",
    "                                  min_lr=10e-7,\n",
    "                                  verbose=verbose)\n",
    "    # monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0\n",
    "    \n",
    "    filepath = model_results_root_dir + \"image.weights.best.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience)    \n",
    "    callbacks_list = [ early_stopping, reduce_lr]  # , checkpoint\n",
    "\n",
    "    # train the model on the new data for a few epochs\n",
    "    history = model.fit_generator(\n",
    "            train_batches,\n",
    "            steps_per_epoch= 2000 // config['batch_size'], # train_batches.samples\n",
    "            epochs=3,\n",
    "            validation_data=validation_batches,\n",
    "            validation_steps= validation_batches.samples // config['batch_size'], \n",
    "            shuffle=True,\n",
    "            verbose=config['verbose'],\n",
    "            #callbacks=callbacks_list,\n",
    "            class_weight='auto')\n",
    "    \n",
    "    # fine-tuning\n",
    "    print(\"Starting fune-tuning\")\n",
    "    setup_to_finetune(model, config['useF1Score'])\n",
    "    \n",
    "    # Add checkpointing to save best model\n",
    "    #callbacks_list.append(checkpoint)\n",
    "    history = model.fit_generator(\n",
    "            train_batches,\n",
    "            steps_per_epoch= 2000 // config['batch_size'], # train_batches.samples\n",
    "            epochs=config['nb_epochs'],\n",
    "            validation_data=validation_batches,\n",
    "            validation_steps= validation_batches.samples // config['batch_size'],\n",
    "            shuffle=True,\n",
    "            verbose=config['verbose'],\n",
    "            callbacks=callbacks_list,\n",
    "            class_weight='auto')\n",
    "    return history, model\n",
    "\n",
    "\n",
    "def conver_predictions_to_classes(predictions, label_map_from_train_gen):\n",
    "    predictions = np.argmax(predictions, axis=-1) #multiple categories\n",
    "    label_map_from_train_gen = dict((v,k) for k,v in label_map_from_train_gen.items()) #flip k,v\n",
    "    predictions = [label_map_from_train_gen[k] for k in predictions]\n",
    "    return predictions\n",
    "\n",
    "def get_label_map_from_train_generator(config):\n",
    "    trainDir = input_images_classified + \"/\" + \"train\" + \"/\"\n",
    "    isForTrain = True\n",
    "    config['batch_size'] = batch_size\n",
    "    train_batches = cm.get_data_generator(trainDir, config, isForTrain)  \n",
    "    return train_batches.class_indices\n",
    "\n",
    "def get_trutch_labels_test_data(test_filenames):\n",
    "    y_true = []\n",
    "    for test_file_name in test_filenames:\n",
    "        # 'negative/Ambulance 1.jpg'\n",
    "        label, test_file_name = test_file_name.split(\"/\")\n",
    "        assert label == imageNameToLabel[test_file_name], \\\n",
    "                \"test_file_name did not match: \" + test_file_name + \\\n",
    "                \"\\t imageNameToLabel:\" + imageNameToLabel[test_file_name]                                                    \n",
    "        y_true.append(imageNameToLabel[test_file_name])\n",
    "    return y_true\n",
    "\n",
    "def evalaute_on_test_data(model, config):\n",
    "    testDir = test_images_src\n",
    "    print(\"testDir\", testDir)\n",
    "    isForTrain = False\n",
    "    config['batch_size'] = 1\n",
    "    \n",
    "    # Divide input images into train and dev set, and each one into {negative, neutral, positive}\n",
    "    isForTest = True\n",
    "    dt.create_dataset(\"test\", testDir, test_images_classified, test_x, test_y, isForTest)\n",
    "    test_batches = cm.get_data_generator_for_test(test_images_classified, config) \n",
    "\n",
    "    results = model.evaluate_generator(test_batches, steps=test_batches.samples // config['batch_size'], verbose=1)\n",
    "    print(model.metrics_names, results)\n",
    "    \n",
    "    predictions = model.predict_generator(test_batches, steps=test_batches.samples // config['batch_size'], verbose=1)\n",
    "    \n",
    "    label_map_from_train_gen = (get_label_map_from_train_generator(config))\n",
    "    predictions = conver_predictions_to_classes(predictions, label_map_from_train_gen)\n",
    "    \n",
    "    test_filenames = test_batches.filenames\n",
    "    y_true = get_trutch_labels_test_data(test_filenames)\n",
    "    y_pred = predictions\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    print(\"cnf_matrix\", cnf_matrix)\n",
    "    titleOfConfusionMatrix = \"Confusion Matrix based on InceptionResNetV2\"\n",
    "    pt.plot_confusion_matrix_from_labels(y_true, y_pred, titleOfConfusionMatrix)\n",
    "    \n",
    "\n",
    "def prepare_and_train(config):\n",
    "    bestModel = None\n",
    "    final_model_val_acc = -1\n",
    "    for index, (train_indices, val_indices) in enumerate(skf.split(X, y)):\n",
    "        print(\"Train size: \", len(train_indices))\n",
    "        print(\"Val size: \", len(val_indices))\n",
    "\n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y_train, y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "        print(\"Train label distribution: \", pt.get_label_count(y_train))\n",
    "        print(\"Val label distribution: \", pt.get_label_count(y_val))\n",
    "\n",
    "        # Divide input images into train and dev set, and each one into {negative, neutral, positive}\n",
    "        isForTest = False\n",
    "        dt.create_dataset(\"train\", input_images_src, input_images_classified, X_train, y_train, isForTest)\n",
    "        dt.create_dataset(\"val\", input_images_src, input_images_classified, X_val, y_val, isForTest)\n",
    "\n",
    "        trainDir = input_images_classified + \"/\" + \"train\" + \"/\"\n",
    "        valDir = input_images_classified + \"/\" + \"val\" + \"/\"\n",
    "\n",
    "        history, model = train(trainDir, valDir, config)\n",
    "        \n",
    "        pt.plot_model_accuracy(history, model_results_root_dir, useF1Score)\n",
    "        best_val_acc = max(history.history['val_acc'])\n",
    "        \n",
    "        if best_val_acc > final_model_val_acc:\n",
    "            bestModel = model\n",
    "            final_model_val_acc = best_val_acc\n",
    "        \n",
    "        cv_accuracies.append(best_val_acc)\n",
    "        print(\"best_val_acc\", best_val_acc)\n",
    "        if useF1Score:\n",
    "            best_val_f1 = max(history.history['val_f1'])\n",
    "            cv_f1s.append(best_val_f1)\n",
    "\n",
    "    print(\"=========================================\")\n",
    "    print(\"Cross-validation val accuracy results: \" , cv_accuracies)\n",
    "    print(\"Cross-validation val accuracy results: %.2f%% (+/- %.2f%%)\" % (np.mean(cv_accuracies), np.std(cv_accuracies)))\n",
    "\n",
    "    if useF1Score:\n",
    "        print(\"\\n\",\"Cross-validation val f1 results: \" , cv_f1s)\n",
    "        print(\"Cross-validation val f1 results: %.2f%% (+/- %.2f%%)\" % (np.mean(cv_f1s), np.std(cv_f1s)))   \n",
    "    \n",
    "    # Evaluate Test data set\n",
    "    evalaute_on_test_data(model, config)\n",
    "    \n",
    "    bestModel.save(model_results_root_dir + \"/bestmodel-\" + str(final_model_val_acc) + \".h5\")\n",
    "\n",
    "\n",
    "def get_config():\n",
    "    conf = {}\n",
    "    conf[\"img_height\"] = img_height\n",
    "    conf[\"img_width\"] = img_width\n",
    "    conf[\"kfold_splits\"] = kfold_splits\n",
    "    conf[\"batch_size\"] = batch_size\n",
    "    conf[\"nb_epochs\"] = nb_epochs\n",
    "    conf['useF1Score'] = useF1Score\n",
    "    conf['verbose'] = verbose\n",
    "    return conf    \n",
    "    \n",
    "def main():\n",
    "    config = get_config()\n",
    "    print(\"config:\\n\", config)\n",
    "    prepare_and_train(config)\n",
    "    # predict()\n",
    "    # text_pre_processing(\"hello&nbsp;hi\")\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # execute only if run as a script\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
