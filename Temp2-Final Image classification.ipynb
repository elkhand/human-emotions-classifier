{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elkhand/anaconda3/envs/cs231n/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, re, string, pathlib, random, io, time, glob\n",
    "from collections import Counter, OrderedDict\n",
    "from shutil import copyfile, rmtree\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import hecutils.data_utils as dt\n",
    "import hecutils.scoring_utils as sc\n",
    "import hecutils.plotting_utils as pt\n",
    "import hecutils.common_utils as cm\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "from keras.layers import GRU, Bidirectional, LSTM, MaxPooling1D, Conv1D,Dense, GlobalAveragePooling2D\n",
    "from keras.layers.core import Dropout, Flatten, Masking, ActivityRegularization\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing import text\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "\n",
    "# from fastText import load_model\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "num_cores = 8\n",
    "GPU=True\n",
    "CPU = not GPU\n",
    "\n",
    "if GPU:\n",
    "    num_GPU = 1\n",
    "    num_CPU = 8\n",
    "if CPU:\n",
    "    num_CPU = 8\n",
    "    num_GPU = 0\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : num_CPU, 'GPU' : num_GPU})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oasis_csv_path = \"dataset/metadata/OASIS.csv\"\n",
    "oasis_images_src = \"dataset/images/\"\n",
    "input_images_src = \"dataset/input2/\"\n",
    "test_images_src = \"dataset/test2/\"\n",
    "model_results_root_dir = \"img_model2/\"\n",
    "\n",
    "input_images_classified = \"dataset/input-classified2/\"\n",
    "test_images_classified = \"dataset/test-classified2/\"\n",
    "\n",
    "dataset_groups=[\"train\", \"val\"]\n",
    "classes = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "kfold_splits = 10 #10\n",
    "\n",
    "neutralLow = 3.0\n",
    "neutralHigh = 5.0\n",
    "\n",
    "nb_epochs = 100 # 3\n",
    "patience = 10 # ReduceLROnPlateau has 5\n",
    "batch_size = 32 # 32  \n",
    "FC_SIZE = 1024\n",
    "LAYERS_TO_FREEZE = -10 #249\n",
    "img_height = 299\n",
    "img_width = 299\n",
    "\n",
    "useF1Score = False\n",
    "verbose=1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data (to be used for model learning and validation) label distribution: \n",
      " OrderedDict([('negative', 147), ('neutral', 378), ('positive', 285)])\n",
      "\n",
      "Test data(never used for learning) label distribution: \n",
      " OrderedDict([('negative', 16), ('neutral', 42), ('positive', 32)])\n"
     ]
    }
   ],
   "source": [
    "image_names, image_labels = dt.get_image_name_and_label(oasis_csv_path, neutralLow, neutralHigh)\n",
    "\n",
    "imageNameToLabel = {}\n",
    "\n",
    "for img_name,label in zip(image_names, image_labels):\n",
    "    if img_name not in imageNameToLabel:\n",
    "        imageNameToLabel[img_name] = label\n",
    "    else:\n",
    "        raise \"There should not be images with same name: \" + img_name + label    \n",
    "        \n",
    "image_names = np.array(image_names)\n",
    "image_labels = np.array(image_labels)\n",
    "\n",
    "input_x, test_x, input_y,  test_y = train_test_split(image_names, image_labels,\n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=seed,\n",
    "                                                    stratify=image_labels)\n",
    "\n",
    "print(\"Input data (to be used for model learning and validation) label distribution: \\n\",pt.get_label_count(input_y))\n",
    "print()\n",
    "print(\"Test data(never used for learning) label distribution: \\n\",pt.get_label_count(test_y))\n",
    "\n",
    "\n",
    "# Delete input images dir\n",
    "rmtree(input_images_src, ignore_errors=True)\n",
    "os.makedirs(input_images_src)\n",
    "\n",
    "\n",
    "# Delete test images dir\n",
    "rmtree(test_images_src, ignore_errors=True)\n",
    "os.makedirs(test_images_src)\n",
    "\n",
    "\n",
    "# Copy input images into input dir, and test images into test dir\n",
    "cm.copy_imgs_into(oasis_images_src, input_x, input_images_src)\n",
    "cm.copy_imgs_into(oasis_images_src, test_x, test_images_src)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config:\n",
      " {'img_height': 299, 'img_width': 299, 'kfold_splits': 10, 'batch_size': 32, 'nb_epochs': 50, 'useF1Score': False, 'verbose': 1}\n",
      "Train size:  728\n",
      "Val size:  82\n",
      "Train label distribution:  OrderedDict([('negative', 132), ('neutral', 340), ('positive', 256)])\n",
      "Val label distribution:  OrderedDict([('negative', 15), ('neutral', 38), ('positive', 29)])\n",
      "Found 728 images belonging to 3 classes.\n",
      "Found 82 images belonging to 3 classes.\n",
      "Epoch 1/50\n",
      "22/22 [==============================] - 29s 1s/step - loss: 1.3571 - acc: 0.3712 - val_loss: 1.1733 - val_acc: 0.3906\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 1.2152 - acc: 0.4256 - val_loss: 1.1861 - val_acc: 0.3750\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 1.1765 - acc: 0.4541 - val_loss: 1.0680 - val_acc: 0.4062\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 1.1028 - acc: 0.4914 - val_loss: 1.1451 - val_acc: 0.4062\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 1.0603 - acc: 0.4967 - val_loss: 1.0240 - val_acc: 0.4375\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 27s 1s/step - loss: 1.0376 - acc: 0.5280 - val_loss: 1.0113 - val_acc: 0.5312\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 0.9496 - acc: 0.5682 - val_loss: 1.0197 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 0.9702 - acc: 0.5610 - val_loss: 0.9675 - val_acc: 0.5469\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 27s 1s/step - loss: 0.9379 - acc: 0.5696 - val_loss: 0.9824 - val_acc: 0.5625\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 27s 1s/step - loss: 0.9088 - acc: 0.5966 - val_loss: 0.9460 - val_acc: 0.5781\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 0.8858 - acc: 0.6194 - val_loss: 0.9686 - val_acc: 0.5312\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 27s 1s/step - loss: 0.8457 - acc: 0.6023 - val_loss: 0.9031 - val_acc: 0.5781\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 0.8601 - acc: 0.6165 - val_loss: 0.9124 - val_acc: 0.6094\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 29s 1s/step - loss: 0.8629 - acc: 0.5946 - val_loss: 0.9326 - val_acc: 0.5938\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 27s 1s/step - loss: 0.7582 - acc: 0.6790 - val_loss: 0.9942 - val_acc: 0.5625\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 27s 1s/step - loss: 0.7724 - acc: 0.6473 - val_loss: 0.8891 - val_acc: 0.6406\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 27s 1s/step - loss: 0.8086 - acc: 0.6307 - val_loss: 0.9159 - val_acc: 0.5938\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 28s 1s/step - loss: 0.7518 - acc: 0.6629 - val_loss: 0.8439 - val_acc: 0.6406\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 28s 1s/step - loss: 0.7662 - acc: 0.6662 - val_loss: 0.9244 - val_acc: 0.5781\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 0.7416 - acc: 0.6672 - val_loss: 0.9548 - val_acc: 0.6094\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 0.7407 - acc: 0.6795 - val_loss: 0.8392 - val_acc: 0.6406\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 0.7150 - acc: 0.7003 - val_loss: 0.8411 - val_acc: 0.6250\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 0.7409 - acc: 0.6865 - val_loss: 0.8976 - val_acc: 0.6250\n",
      "Epoch 24/50\n",
      "11/22 [==============>...............] - ETA: 10s - loss: 0.7496 - acc: 0.6799"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9f29c0e9ec1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;31m# execute only if run as a script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9f29c0e9ec1b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"config:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0mprepare_and_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;31m# predict()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;31m# text_pre_processing(\"hello&nbsp;hi\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9f29c0e9ec1b>\u001b[0m in \u001b[0;36mprepare_and_train\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mvalDir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_images_classified\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"val\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_results_root_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museF1Score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9f29c0e9ec1b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trainDir, valDir, config)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verbose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             class_weight='auto')\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m#     # fine-tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231n/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231n/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2192\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2193\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231n/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231n/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231n/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231n/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231n/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate the cross validator\n",
    "skf = StratifiedKFold(n_splits=kfold_splits, shuffle=True)\n",
    "cv_accuracies = []\n",
    "cv_f1s = []\n",
    "    \n",
    "X = input_x\n",
    "y = input_y\n",
    "    \n",
    "# Shuffe input data\n",
    "X, y = shuffle(X,y)\n",
    "\n",
    "def get_adam_optimizer():\n",
    "    return optimizers.Adam(lr=1e-5)\n",
    "\n",
    "def setup_to_finetune(model, useF1Score):\n",
    "    \"\"\"Freeze the bottom LAYERS_TO_FREEZE and retrain the remaining top layers.\n",
    "  note: LAYERS_TO_FREEZE corresponds to the top 2 inception blocks in the inceptionv3 arch\n",
    "  Args:\n",
    "    model: keras model\n",
    "    \"\"\"    \n",
    "    print(\"LAYERS_TO_FREEZE:\", LAYERS_TO_FREEZE)\n",
    "    for layer in model.layers[:LAYERS_TO_FREEZE]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[LAYERS_TO_FREEZE:]:\n",
    "        layer.trainable = True\n",
    "    model.compile(optimizer=get_adam_optimizer(), loss='categorical_crossentropy',\\\n",
    "                  metrics=cm.get_metrics(useF1Score))\n",
    "\n",
    "def setup_to_transfer_learn(model, base_model, useF1Score):\n",
    "    \"\"\"Freeze all layers and compile the model\"\"\"    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    for layer in base_model.layers[LAYERS_TO_FREEZE:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    model.compile(optimizer=get_adam_optimizer(), loss='categorical_crossentropy', metrics=cm.get_metrics(useF1Score))\n",
    "\n",
    "\n",
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    \"\"\"Add last layer to the convnet\n",
    "      Args:\n",
    "        base_model: keras model excluding top\n",
    "        nb_classes: # of classes\n",
    "      Returns:\n",
    "        new keras model with last layer\n",
    "    \"\"\"\n",
    "    # 62,65,67% w/o reducing lr\n",
    "#     x = base_model.output\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "#     x = Dense(FC_SIZE, activation='relu')(x) #new FC layer, random init\n",
    "#     output_layer = Dense(nb_classes, activation='softmax')(x) #new softmax layer\n",
    "#     model = Model(input=base_model.input, output=output_layer)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output_layer = Dense(nb_classes, activation='softmax', name='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(trainDir, valDir, config): \n",
    "    \"\"\"Use transfer learning and fine-tuning to train a network on a new dataset\"\"\"     \n",
    "    \n",
    "    nb_classes = len(glob.glob(trainDir + \"/*\"))\n",
    "    \n",
    "    # this is a generator that will read pictures found in\n",
    "    # subfolers of 'data/train', and indefinitely generate\n",
    "    # batches of augmented image data\n",
    "    isForTrain = True\n",
    "    train_batches = cm.get_data_generator(trainDir, config, isForTrain)  \n",
    "    \n",
    "\n",
    "    # this is a similar generator, for validation data\n",
    "    isForTrain = False\n",
    "    validation_batches = cm.get_data_generator(valDir, config, isForTrain)  \n",
    "        \n",
    "    # setup model\n",
    "    #base_model = InceptionV3(weights='imagenet', include_top=False) #include_top=False excludes final FC layer\n",
    "    base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(config['img_height'],config['img_width'],3))\n",
    "    model = add_new_last_layer(base_model, nb_classes)\n",
    "\n",
    "    # transfer learning\n",
    "    setup_to_transfer_learn(model, base_model, config['useF1Score'])\n",
    "    \n",
    "    # monitor='val_loss', patience = 5 default\n",
    "    reduce_lr = ReduceLROnPlateau()\n",
    "    \n",
    "    filepath = model_results_root_dir + \"image.weights.best.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience)    \n",
    "    callbacks_list = [ early_stopping, reduce_lr]  # , checkpoint\n",
    "\n",
    "    # train the model on the new data for a few epochs\n",
    "    history = model.fit_generator(\n",
    "            train_batches,\n",
    "            steps_per_epoch= train_batches.samples // config['batch_size'],\n",
    "            epochs=config['nb_epochs'],\n",
    "            validation_data=validation_batches,\n",
    "            validation_steps= validation_batches.samples // config['batch_size'],\n",
    "            shuffle=True,\n",
    "            verbose=config['verbose'],\n",
    "            callbacks=callbacks_list,\n",
    "            class_weight='auto')\n",
    "    \n",
    "#     # fine-tuning\n",
    "#     print(\"Starting fune-tuning\")\n",
    "#     setup_to_finetune(model, config['useF1Score'])\n",
    "    \n",
    "#     callbacks_list.append(checkpoint)\n",
    "#     history = model.fit_generator(\n",
    "#             train_generator,\n",
    "#             steps_per_epoch= 2000 // config['batch_size'],\n",
    "#             epochs=config['nb_epochs'] * 3,\n",
    "#             validation_data=validation_generator,\n",
    "#             validation_steps= 800 // config['batch_size'],\n",
    "#             shuffle=True,\n",
    "#             verbose=config['verbose'],\n",
    "#             callbacks=callbacks_list,\n",
    "#             class_weight='auto')\n",
    "    return history, model\n",
    "\n",
    "\n",
    "def conver_predictions_to_classes(predictions, label_map_from_train_gen):\n",
    "    predictions = np.argmax(predictions, axis=-1) #multiple categories\n",
    "    label_map_from_train_gen = dict((v,k) for k,v in label_map_from_train_gen.items()) #flip k,v\n",
    "    predictions = [label_map_from_train_gen[k] for k in predictions]\n",
    "    return predictions\n",
    "\n",
    "def get_label_map_from_train_generator(config):\n",
    "    trainDir = input_images_classified + \"/\" + \"train\" + \"/\"\n",
    "    isForTrain = True\n",
    "    config['batch_size'] = batch_size\n",
    "    train_batches = cm.get_data_generator(trainDir, config, isForTrain)  \n",
    "    return train_batches.class_indices\n",
    "\n",
    "def get_trutch_labels_test_data(test_filenames):\n",
    "    y_true = []\n",
    "    for test_file_name in test_filenames:\n",
    "        # 'negative/Ambulance 1.jpg'\n",
    "        label, test_file_name = test_file_name.split(\"/\")\n",
    "        assert label == imageNameToLabel[test_file_name], \\\n",
    "                \"test_file_name did not match: \" + test_file_name + \\\n",
    "                \"\\t imageNameToLabel:\" + imageNameToLabel[test_file_name]                                                    \n",
    "        y_true.append(imageNameToLabel[test_file_name])\n",
    "    return y_true\n",
    "\n",
    "def evalaute_on_test_data(model, config):\n",
    "    testDir = test_images_src\n",
    "    print(\"testDir\", testDir)\n",
    "    isForTrain = False\n",
    "    config['batch_size'] = 1\n",
    "    \n",
    "    # Divide input images into train and dev set, and each one into {negative, neutral, positive}\n",
    "    isForTest = True\n",
    "    dt.create_dataset(\"test\", testDir, test_images_classified, test_x, test_y, isForTest)\n",
    "    test_batches = cm.get_data_generator_for_test(test_images_classified, config) \n",
    "\n",
    "    results = model.evaluate_generator(test_batches, steps=test_batches.samples // config['batch_size'], verbose=1)\n",
    "    print(model.metrics_names, results)\n",
    "    \n",
    "    predictions = model.predict_generator(test_batches, steps=test_batches.samples // config['batch_size'], verbose=1)\n",
    "    \n",
    "    label_map_from_train_gen = (get_label_map_from_train_generator(config))\n",
    "    predictions = conver_predictions_to_classes(predictions, label_map_from_train_gen)\n",
    "    \n",
    "    test_filenames = test_batches.filenames\n",
    "    y_true = get_trutch_labels_test_data(test_filenames)\n",
    "    y_pred = predictions\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    print(\"cnf_matrix\", cnf_matrix)\n",
    "    titleOfConfusionMatrix = \"Confusion Matrix based on InceptionResNetV2\"\n",
    "    pt.plot_confusion_matrix_from_labels(y_true, y_pred, titleOfConfusionMatrix)\n",
    "    \n",
    "\n",
    "def prepare_and_train(config):\n",
    "    bestModel = None\n",
    "    final_model_val_acc = -1\n",
    "    for index, (train_indices, val_indices) in enumerate(skf.split(X, y)):\n",
    "        print(\"Train size: \", len(train_indices))\n",
    "        print(\"Val size: \", len(val_indices))\n",
    "\n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y_train, y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "        print(\"Train label distribution: \", pt.get_label_count(y_train))\n",
    "        print(\"Val label distribution: \", pt.get_label_count(y_val))\n",
    "\n",
    "        # Divide input images into train and dev set, and each one into {negative, neutral, positive}\n",
    "        isForTest = False\n",
    "        dt.create_dataset(\"train\", input_images_src, input_images_classified, X_train, y_train, isForTest)\n",
    "        dt.create_dataset(\"val\", input_images_src, input_images_classified, X_val, y_val, isForTest)\n",
    "\n",
    "        trainDir = input_images_classified + \"/\" + \"train\" + \"/\"\n",
    "        valDir = input_images_classified + \"/\" + \"val\" + \"/\"\n",
    "\n",
    "        history, model = train(trainDir, valDir, config)\n",
    "        \n",
    "        pt.plot_model_accuracy(history, model_results_root_dir, useF1Score)\n",
    "        best_val_acc = max(history.history['val_acc'])\n",
    "        \n",
    "        if best_val_acc > final_model_val_acc:\n",
    "            bestModel = model\n",
    "            final_model_val_acc = best_val_acc\n",
    "        \n",
    "        cv_accuracies.append(best_val_acc)\n",
    "        print(\"best_val_acc\", best_val_acc)\n",
    "        if useF1Score:\n",
    "            best_val_f1 = max(history.history['val_f1'])\n",
    "            cv_f1s.append(best_val_f1)\n",
    "\n",
    "    print(\"=========================================\")\n",
    "    print(\"Cross-validation val accuracy results: \" , cv_accuracies)\n",
    "    print(\"Cross-validation val accuracy results: %.2f%% (+/- %.2f%%)\" % (np.mean(cv_accuracies), np.std(cv_accuracies)))\n",
    "\n",
    "    if useF1Score:\n",
    "        print(\"\\n\",\"Cross-validation val f1 results: \" , cv_f1s)\n",
    "        print(\"Cross-validation val f1 results: %.2f%% (+/- %.2f%%)\" % (np.mean(cv_f1s), np.std(cv_f1s)))   \n",
    "    \n",
    "    # Evaluate Test data set\n",
    "    evalaute_on_test_data(model, config)\n",
    "    \n",
    "    bestModel.save(model_results_root_dir + \"/bestmodel-\" + str(final_model_val_acc) + \".h5\")\n",
    "\n",
    "\n",
    "def get_config():\n",
    "    conf = {}\n",
    "    conf[\"img_height\"] = img_height\n",
    "    conf[\"img_width\"] = img_width\n",
    "    conf[\"kfold_splits\"] = kfold_splits\n",
    "    conf[\"batch_size\"] = batch_size\n",
    "    conf[\"nb_epochs\"] = nb_epochs\n",
    "    conf['useF1Score'] = useF1Score\n",
    "    conf['verbose'] = verbose\n",
    "    return conf    \n",
    "    \n",
    "def main():\n",
    "    config = get_config()\n",
    "    print(\"config:\\n\", config)\n",
    "    prepare_and_train(config)\n",
    "    # predict()\n",
    "    # text_pre_processing(\"hello&nbsp;hi\")\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # execute only if run as a script\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
