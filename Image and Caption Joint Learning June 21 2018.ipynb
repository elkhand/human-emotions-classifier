{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Image & Caption joint training\n",
    "\n",
    "https://gist.github.com/elkhand/412f9dc4cd1a72c4571354e81c93d695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports for Caption model\n",
    "\n",
    "import os, sys, io,re, string, pathlib, random\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import hecutils.data_utils as dt\n",
    "import hecutils.scoring_utils as sc\n",
    "import hecutils.plotting_utils as pt\n",
    "import hecutils.caption_utils as caput\n",
    "import hecutils.image_utils as imut\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, GRU, Bidirectional, LSTM\n",
    "from keras.layers.core import Dropout, Flatten, Masking, ActivityRegularization\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import text\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "################################################################################################################\n",
    "# Imports for Image model\n",
    "\n",
    "import os, sys, re, string, pathlib, random, io, time, glob\n",
    "from collections import Counter, OrderedDict\n",
    "from shutil import copyfile, rmtree\n",
    "\n",
    "#import hecutils.resnet152 as resnet\n",
    "from hecutils.resnet152 import ResNet152\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import hecutils.data_utils as dt\n",
    "import hecutils.scoring_utils as sc\n",
    "import hecutils.plotting_utils as pt\n",
    "import hecutils.image_utils as imut\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "from keras.layers import Concatenate, MaxPooling2D, Conv2D, ZeroPadding2D, merge, Input, GRU, Bidirectional, LSTM, MaxPooling1D, Conv1D,Dense, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.layers.core import Dropout, Flatten, Masking, ActivityRegularization\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.applications.inception_v3 import InceptionV3#, preprocess_input\n",
    "#from imagenet_utils import preprocess_input\n",
    "from keras_applications import imagenet_utils\n",
    "preprocess_input = imagenet_utils.preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.preprocessing import text\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# from fastText import load_model\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Keras to use Tensorflow GPU in the backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "num_cores = 8\n",
    "GPU=True\n",
    "CPU = not GPU\n",
    "\n",
    "if GPU:\n",
    "    num_GPU = 1\n",
    "    num_CPU = 8\n",
    "if CPU:\n",
    "    num_CPU = 8\n",
    "    num_GPU = 0\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : num_CPU, 'GPU' : num_GPU})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caption model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "\n",
    "oasis_csv_path = \"dataset/metadata/OASIS.csv\"\n",
    "captions_root = \"/home/elkhand/git-repos/human-emotions-classifier/dataset/metadata\"\n",
    "captions_root_path = pathlib.Path(captions_root)\n",
    "human_output_caption_to_label_csv_path = captions_root_path/'humanCaptionWithLabeldf.csv'\n",
    "human_caption_csv_path = captions_root_path/'captions.csv'\n",
    "#fasttext_embedding_path = 'embedding/wiki-news-300d-1M.vec'\n",
    "fasttext_embedding_path = '/home/elkhand/datasets/glove-vectors/glove.twitter.27B.100d.txt'\n",
    "#model_results_root_dir = \"model/\"\n",
    "inputDataset_csv_path = captions_root_path/\"inputDataset.csv\"\n",
    "testDataset_csv_path = captions_root_path/\"testDataset.csv\"\n",
    "\n",
    "neutralLow = 3.0 \n",
    "neutralHigh = 5.0\n",
    "\n",
    "auto_output_caption_to_label_csv_path = captions_root_path/'autoCaptionWithLabeldf.csv'\n",
    "auto_caption_csv_path = captions_root_path/'auto_generated_captions.csv'\n",
    "\n",
    "\n",
    "dataset_path = human_output_caption_to_label_csv_path\n",
    "# dataset_path = auto_output_caption_to_label_csv_path\n",
    "\n",
    "kfold_splits = 7 # 10 # 7 # 5 # 10 # 7 \n",
    "test_size = 0.1\n",
    "\n",
    "embedding_dimension = 100 #200 # 300\n",
    "hidden_layer_dim = 32\n",
    "batch_size = 16 # 64\n",
    "nb_epochs = 100\n",
    "dropout = 0.3\n",
    "recurrent_dropout=  0.6\n",
    "patience = 10\n",
    "verbose = 1\n",
    "\n",
    "useF1Score = False # True\n",
    "\n",
    "################################################################################################################\n",
    "# Image model\n",
    "\n",
    "oasis_csv_path = \"dataset/metadata/OASIS.csv\"\n",
    "oasis_images_src = \"dataset/images/\"\n",
    "input_images_src = \"dataset/input-joint/\"\n",
    "test_images_src = \"dataset/test-joint/\"\n",
    "model_results_root_dir = \"img_model-joint/\"\n",
    "\n",
    "input_images_classified = \"dataset/input-classified-joint/\"\n",
    "test_images_classified = \"dataset/test-classified-joint/\"\n",
    "\n",
    "# ou can downlaod weights here: https://gist.github.com/flyyufelix/7e2eafb149f72f4d38dd661882c554a6\n",
    "weights_path = \"/home/elkhand/weights/resnet152_weights_tf.h5\"\n",
    "\n",
    "dataset_groups=[\"train\", \"val\"]\n",
    "classes = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "kfold_splits =  7 #5\n",
    "\n",
    "neutralLow = 3.0\n",
    "neutralHigh = 5.0\n",
    "\n",
    "nb_epochs = 100\n",
    "patience = 10 # ReduceLROnPlateau has 5\n",
    "batch_size = 32 # 32  \n",
    "\n",
    "FC_SIZE = 128 # 1024\n",
    "LAYERS_TO_UNFREEZE = 10\n",
    "\n",
    "img_height = 224 # 299\n",
    "img_width = 224  # 299\n",
    "\n",
    "useF1Score = False\n",
    "verbose=1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Label distribution in inputDataset label\n",
      "negative    147\n",
      "neutral     378\n",
      "positive    285\n",
      "Name: label, dtype: int64\n",
      "Label distribution in testDataset label\n",
      "negative    16\n",
      "neutral     42\n",
      "positive    32\n",
      "Name: label, dtype: int64\n",
      "Input data size 810\n",
      "Test data size 90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>caption</th>\n",
       "      <th>label</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I1</td>\n",
       "      <td>two acorns lying ground next oak leaves.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Acorns 1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I100</td>\n",
       "      <td>ruined walls church backdrop white clouds blue...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Building 2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I101</td>\n",
       "      <td>man free fall attached blue bungee jumping app...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Bungee jumping 1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I102</td>\n",
       "      <td>falling man attached bungee jumping apparatus....</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Bungee jumping 2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I104</td>\n",
       "      <td>man kneeling front tent two similar-looking gi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Camping 1.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                            caption     label  \\\n",
       "0    I1           two acorns lying ground next oak leaves.   neutral   \n",
       "2  I100  ruined walls church backdrop white clouds blue...   neutral   \n",
       "3  I101  man free fall attached blue bungee jumping app...   neutral   \n",
       "4  I102  falling man attached bungee jumping apparatus....   neutral   \n",
       "6  I104  man kneeling front tent two similar-looking gi...  positive   \n",
       "\n",
       "             image_name  \n",
       "0          Acorns 1.jpg  \n",
       "2        Building 2.jpg  \n",
       "3  Bungee jumping 1.jpg  \n",
       "4  Bungee jumping 2.jpg  \n",
       "6         Camping 1.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create <caption,label> CSV files\n",
    "dt.create_caption_to_label(oasis_csv_path,human_caption_csv_path, human_output_caption_to_label_csv_path,neutralLow, neutralHigh)\n",
    "dt.create_caption_to_label(oasis_csv_path,auto_caption_csv_path, auto_output_caption_to_label_csv_path,neutralLow, neutralHigh)\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# Divide data into train/val/test datasets <imageName, caption, label>\n",
    "# ============================================\n",
    "\n",
    "dfImageIdCaptionLabel = pd.read_csv(dataset_path, header=0, sep=\"|\")\n",
    "dfImageIdCaptionLabel.columns = [\"id\",\"caption\", \"label\"]\n",
    "dfImageIdCaptionLabel[\"caption\"] = dfImageIdCaptionLabel[\"caption\"].apply(lambda x: \" \".join(caput.get_words_withoutstopwords(x.lower().split())))\n",
    "#dfImageIdCaptionLabel[\"label\"] = dfImageIdCaptionLabel[\"label\"].apply(lambda x: caput.change_label_str_to_int(x))\n",
    "\n",
    "\n",
    "dfImageIdImageName = dt.get_image_id_to_image_title_as_df(oasis_csv_path)\n",
    "dfImageIdImageName.columns = ['id', 'image_name']\n",
    "dfImageIdImageName['image_name'] = dfImageIdImageName['image_name'].apply(lambda x: x + \".jpg\") \n",
    "printCnt = 5\n",
    "# has [id, caption, label]\n",
    "df = pd.merge(dfImageIdCaptionLabel, dfImageIdImageName, on=\"id\")\n",
    "#print(df.head(printCnt))\n",
    "\n",
    "\n",
    "\n",
    "input_x, test_x, input_y,  test_y = train_test_split(df[\"id\"],\n",
    "                                                     df[\"label\"],\n",
    "                                                     test_size=test_size,\n",
    "                                                     random_state=seed,\n",
    "                                                     stratify=df[\"label\"])\n",
    "\n",
    "inputDataset = pd.concat([input_x, input_y], axis=1)\n",
    "testDataset = pd.concat([test_x, test_y], axis=1)\n",
    "\n",
    "inputDataset = inputDataset.dropna()\n",
    "testDataset = testDataset.dropna()\n",
    "inputDataset = inputDataset.reset_index()\n",
    "testDataset = testDataset.reset_index()\n",
    "\n",
    "# print(\"inputDataset\\n\", inputDataset.head(10))\n",
    "# print(\"testDataset\\n\", testDataset.head(10))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Label distribution in inputDataset\", inputDataset.groupby('label').label.count())\n",
    "print(\"Label distribution in testDataset\", testDataset.groupby('label').label.count())\n",
    "\n",
    "\n",
    "inputData = df.loc[df['id'].isin(inputDataset.id)]\n",
    "testData = df.loc[df['id'].isin(testDataset.id)]\n",
    "\n",
    "# print(\"inputData\\n\", inputData.head())\n",
    "# print(\"testData\\n\", testData.head())\n",
    "\n",
    "inputIds = set(inputData['id'].values)\n",
    "testIds = set(testData['id'].values)\n",
    "\n",
    "print(\"Input data size\", len(inputIds))\n",
    "print(\"Test data size\", len(testIds))\n",
    "\n",
    "for inputId in inputIds:\n",
    "    if inputId in testIds:\n",
    "        raise inputId + \" inputId exists both in test and input dataset\"\n",
    "        \n",
    "for testId in testIds:\n",
    "    if testId in inputIds:\n",
    "        raise testId + \" testId exists both in test and input dataset\"        \n",
    "\n",
    "inputData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating test and input dataset, and `positive,neutral,negative` under each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete input images dir\n",
    "rmtree(input_images_src, ignore_errors=True)\n",
    "os.makedirs(input_images_src)\n",
    "\n",
    "\n",
    "# Delete test images dir\n",
    "rmtree(test_images_src, ignore_errors=True)\n",
    "os.makedirs(test_images_src)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Copy input images into input dir, and test images into test dir\n",
    "imut.copy_imgs_into(oasis_images_src, inputData['image_name'], input_images_src)\n",
    "imut.copy_imgs_into(oasis_images_src, testData['image_name'], test_images_src)\n",
    "\n",
    "# Divide input images into train and dev set, and each one into {negative, neutral, positive}\n",
    "isForTest = False\n",
    "X_train = inputData['image_name']\n",
    "y_train = inputData['label']\n",
    "dt.create_dataset(\"train\", input_images_src, input_images_classified, X_train, y_train, isForTest)\n",
    "#X_val = inputData['image_name'] # TODO COrrect\n",
    "#y_val = inputData['label']\n",
    "#dt.create_dataset(\"val\", input_images_src, input_images_classified, X_val, y_val, isForTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Fasttext Embeddings\n",
    "\n",
    "You can download fasttext word vectors from here:\n",
    "\n",
    "https://fasttext.cc/docs/en/english-vectors.html\n",
    "\n",
    "https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki-news-300d-1M.vec.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext_embedding_path /home/elkhand/datasets/glove-vectors/glove.twitter.27B.100d.txt\n",
      "embedding size : 1193514\n",
      "embedding dimension : (100,)\n"
     ]
    }
   ],
   "source": [
    "def load_embedding(path):\n",
    "    word2vec = {}\n",
    "    with io.open(path, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            entries = line.rstrip().split(\" \")\n",
    "            word, entries = entries[0], entries[1:]\n",
    "            word2vec[word] = np.array(entries).astype(np.float) # Convert String type to float\n",
    "    print('embedding size : %d' % len(word2vec))\n",
    "    print('embedding dimension : %s' % (word2vec['apple'].shape,))\n",
    "    return word2vec\n",
    "    \n",
    "print(\"fasttext_embedding_path\", fasttext_embedding_path)\n",
    "wordToVec = {}\n",
    "wordToVec = load_embedding(fasttext_embedding_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint model, which will learn both from images and captions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 40)     22560       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 40)           12960       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 802816)       0           block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 802856)       0           lstm_2[0][0]                     \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          205531392   concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            771         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 205,606,403\n",
      "Trainable params: 205,606,403\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model(max_seq_len, num_of_classes, config): \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (3, img_height, img_width)\n",
    "    else:\n",
    "        input_shape = (img_height, img_width, 3)\n",
    "    text_inputs = Input(shape=(None, config['embedding_dimension']))\n",
    "#     masking = Masking(mask_value=0., input_shape=(None, config['embedding_dimension']))(text_inputs) #input_shape=(None, config['embedding_dimension'])\n",
    "    lstm1 = LSTM(max_seq_len, return_sequences=True, dropout=config['dropout'], recurrent_dropout=config['recurrent_dropout'])(text_inputs)\n",
    "    branch_1 = LSTM(max_seq_len, dropout=config['dropout'], recurrent_dropout=config['recurrent_dropout'])(lstm1)    \n",
    "    # Image input branch - a pre-trained Inception module followed by an added fully connected layer\n",
    "    #base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "    #base_model = ResNet152(include_top=False, weights='imagenet')\n",
    "#     base_model = InceptionResNetV2(weights='imagenet', include_top=False)\n",
    "    #base_model = VGG16(include_top=False, weights='imagenet')\n",
    "        \n",
    "    # Freeze Inception's weights - we don't want to train these\n",
    "#     for layer in base_model.layers:\n",
    "#         layer.trainable = False\n",
    "\n",
    "#     # add a fully connected layer after Inception - we do want to train these\n",
    "#     branch_2 = base_model.output\n",
    "    \n",
    "# #     branch_2 = Dropout(0.5)(branch_2) # NEW ADDED\n",
    "    \n",
    "# #     branch_2 = GlobalAveragePooling2D()(branch_2)\n",
    "# #     branch_2 = Dense(1024, activation='relu')(branch_2)\n",
    "    \n",
    "#     #x = Dropout(0.5)(branch_2)\n",
    "#     x = GlobalMaxPooling2D()(branch_2)\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     x = Dense(FC_SIZE, activation='relu')(x) #new FC layer, random init\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     branch_2 = x\n",
    "    \n",
    "    # Block 1\n",
    "    image_input = Input(shape=input_shape)\n",
    "    model = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1' )(image_input)\n",
    "    model = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2') (model)\n",
    "    model = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool') (model)\n",
    "    # Classification block\n",
    "    model = Flatten(name='flatten') (model)\n",
    "    branch_2 = model\n",
    "    # merge the text input branch and the image input branch and add another fully connected layer\n",
    "    #joint = merge([branch_1, branch_2], mode='concat')\n",
    "    joint = layers.concatenate([branch_1, branch_2], axis=-1)\n",
    "    joint = Dense(256, activation='relu')(joint)\n",
    "    joint = Dropout(0.5)(joint)\n",
    "    predictions = Dense(num_of_classes, activation='softmax')(joint)\n",
    "    \n",
    "    \n",
    "    if config['useF1Score']:\n",
    "        metrics = ['accuracy', sc.f1, sc.recall, sc.precision]\n",
    "    else:\n",
    "        metrics = ['accuracy']\n",
    "        \n",
    "#     full_model = Model(inputs=[base_model.input, text_inputs], outputs=[predictions])\n",
    "    full_model = Model(inputs=[image_input, text_inputs], outputs=[predictions])\n",
    "\n",
    "    full_model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer='adam', # 'rmsprop'\n",
    "                   metrics=metrics)\n",
    "    print(full_model.summary())\n",
    "    return full_model\n",
    "\n",
    "def setup_to_finetune(model, useF1Score):\n",
    "    \"\"\"Freeze the bottom LAYERS_TO_FREEZE and retrain the remaining top layers.\n",
    "  note: LAYERS_TO_FREEZE corresponds to the top 2 inception blocks in the inceptionv3 arch\n",
    "  Args:\n",
    "    model: keras model\n",
    "    \"\"\"    \n",
    "    totalLayers = len(model.layers)\n",
    "    lastFreezeLayer = totalLayers - LAYERS_TO_UNFREEZE\n",
    "    print(\"LAYERS_TO_UNFREEZE:\", LAYERS_TO_UNFREEZE, \"last layer id to freeze\", lastFreezeLayer, \"total layers, \",totalLayers)\n",
    "    for layer in model.layers[:lastFreezeLayer]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[lastFreezeLayer:]:\n",
    "        layer.trainable = True\n",
    "    #optimizers.SGD(lr=0.0001, momentum=0.9)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy',\\\n",
    "                  metrics=imut.get_metrics(useF1Score))\n",
    "    \n",
    "def get_config():\n",
    "    conf = {}\n",
    "    conf[\"kfold_splits\"] = kfold_splits\n",
    "    conf[\"batch_size\"] = batch_size\n",
    "    conf['embedding_dimension'] = embedding_dimension\n",
    "    conf['recurrent_dropout'] = recurrent_dropout\n",
    "    conf['dropout'] = dropout\n",
    "    conf[\"nb_epochs\"] = nb_epochs\n",
    "    conf['useF1Score'] = useF1Score\n",
    "    conf['verbose'] = verbose\n",
    "    conf['useF1Score'] = useF1Score\n",
    "    conf['seed'] = seed\n",
    "    conf[\"img_height\"] = img_height\n",
    "    conf[\"img_width\"] = img_width\n",
    "    conf[\"kfold_splits\"] = kfold_splits\n",
    "    conf[\"batch_size\"] = batch_size\n",
    "    conf[\"nb_epochs\"] = nb_epochs\n",
    "    conf['useF1Score'] = useF1Score\n",
    "    conf['verbose'] = verbose\n",
    "    return conf \n",
    "\n",
    "full_model = build_model(40, 3, get_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/input-joint/Acorns 1.jpg\n",
      "dataset/input-joint/Building 2.jpg\n",
      "dataset/input-joint/Bungee jumping 1.jpg\n",
      "dataset/input-joint/Bungee jumping 2.jpg\n",
      "dataset/input-joint/Camping 1.jpg\n",
      "dataset/input-joint/Camping 2.jpg\n",
      "dataset/input-joint/Camping 4.jpg\n",
      "dataset/input-joint/Camping 6.jpg\n",
      "dataset/input-joint/Camping 7.jpg\n",
      "dataset/input-joint/Alcohol 8.jpg\n",
      "dataset/input-joint/Camping 10.jpg\n",
      "dataset/input-joint/Candle 1.jpg\n",
      "dataset/input-joint/Car 1.jpg\n",
      "dataset/input-joint/Car 2.jpg\n",
      "dataset/input-joint/Car accident 2.jpg\n",
      "dataset/input-joint/Car accident 3.jpg\n",
      "dataset/input-joint/Car accident 4.jpg\n",
      "dataset/input-joint/Ambulance 1.jpg\n",
      "dataset/input-joint/Car crash 1.jpg\n",
      "dataset/input-joint/Car crash 2.jpg\n",
      "dataset/input-joint/Car crash 3.jpg\n",
      "dataset/input-joint/Car race 1.jpg\n",
      "dataset/input-joint/Car race 2.jpg\n",
      "dataset/input-joint/Car race 3.jpg\n",
      "dataset/input-joint/Car race 4.jpg\n",
      "dataset/input-joint/Cardboard 1.jpg\n",
      "dataset/input-joint/Cardboard 2.jpg\n",
      "dataset/input-joint/Cardboard 3.jpg\n",
      "dataset/input-joint/Ambulance 2.jpg\n",
      "dataset/input-joint/Cat 1.jpg\n",
      "dataset/input-joint/Cat 2.jpg\n",
      "dataset/input-joint/Cat 3.jpg\n",
      "dataset/input-joint/Cat 4.jpg\n",
      "dataset/input-joint/Cat 5.jpg\n",
      "dataset/input-joint/Cat 6.jpg\n",
      "dataset/input-joint/Cat 7.jpg\n",
      "dataset/input-joint/Cat 8.jpg\n",
      "dataset/input-joint/Cat 9.jpg\n",
      "dataset/input-joint/Cat 10.jpg\n",
      "dataset/input-joint/Ambulance 3.jpg\n",
      "dataset/input-joint/Cat 11.jpg\n",
      "dataset/input-joint/Cat 12.jpg\n",
      "dataset/input-joint/Cat 13.jpg\n",
      "dataset/input-joint/Cat 14.jpg\n",
      "dataset/input-joint/Celebration 1.jpg\n",
      "dataset/input-joint/Celebration 2.jpg\n",
      "dataset/input-joint/Cemetery 1.jpg\n",
      "dataset/input-joint/Cemetery 2.jpg\n",
      "dataset/input-joint/Cemetery 3.jpg\n",
      "dataset/input-joint/Cemetery 4.jpg\n",
      "dataset/input-joint/Angry face 1.jpg\n",
      "dataset/input-joint/Cemetery 5.jpg\n",
      "dataset/input-joint/Cheerleader 1.jpg\n",
      "dataset/input-joint/Cheerleader 2.jpg\n",
      "dataset/input-joint/Child labor 2.jpg\n",
      "dataset/input-joint/Child labor 3.jpg\n",
      "dataset/input-joint/Child labor 4.jpg\n",
      "dataset/input-joint/Children 1.jpg\n",
      "dataset/input-joint/Chipmunk 1.jpg\n",
      "dataset/input-joint/Chipmunk 2.jpg\n",
      "dataset/input-joint/Angry face 2.jpg\n",
      "dataset/input-joint/Chipmunk 3.jpg\n",
      "dataset/input-joint/City 1.jpg\n",
      "dataset/input-joint/Clean 1.jpg\n",
      "dataset/input-joint/Cliff diver 1.jpg\n",
      "dataset/input-joint/Cliff diver 2.jpg\n",
      "dataset/input-joint/Cliff diver 3.jpg\n",
      "dataset/input-joint/Cockroach 1.jpg\n",
      "dataset/input-joint/Cockroach 2.jpg\n",
      "dataset/input-joint/Cockroach 3.jpg\n",
      "dataset/input-joint/Cockroach 4.jpg\n",
      "dataset/input-joint/Angry face 3.jpg\n",
      "dataset/input-joint/Cold 1.jpg\n",
      "dataset/input-joint/Cold 2.jpg\n",
      "dataset/input-joint/Cold 3.jpg\n",
      "dataset/input-joint/Cold 4.jpg\n",
      "dataset/input-joint/Cold 5.jpg\n",
      "dataset/input-joint/Cold 6.jpg\n",
      "dataset/input-joint/Cold 8.jpg\n",
      "dataset/input-joint/Collaboration 1.jpg\n",
      "dataset/input-joint/Angry face 4.jpg\n",
      "dataset/input-joint/Cotton swabs 1.jpg\n",
      "dataset/input-joint/Cotton swabs 2.jpg\n",
      "dataset/input-joint/Cotton swabs 3.jpg\n",
      "dataset/input-joint/Couple 1.jpg\n",
      "dataset/input-joint/Couple 2.jpg\n",
      "dataset/input-joint/Couple 3.jpg\n",
      "dataset/input-joint/Couple 5.jpg\n",
      "dataset/input-joint/Couple 6.jpg\n",
      "dataset/input-joint/Couple 7.jpg\n",
      "dataset/input-joint/Angry face 5.jpg\n",
      "dataset/input-joint/Couple 9.jpg\n",
      "dataset/input-joint/Crow 1.jpg\n",
      "dataset/input-joint/Crow 2.jpg\n",
      "dataset/input-joint/Cups 2.jpg\n",
      "dataset/input-joint/Cups 3.jpg\n",
      "dataset/input-joint/Dancing 1.jpg\n",
      "dataset/input-joint/Acorns 2.jpg\n",
      "dataset/input-joint/Angry pose 1.jpg\n",
      "dataset/input-joint/Dancing 2.jpg\n",
      "dataset/input-joint/Dancing 3.jpg\n",
      "dataset/input-joint/Dancing 4.jpg\n",
      "dataset/input-joint/Dancing 5.jpg\n",
      "dataset/input-joint/Dancing 6.jpg\n",
      "dataset/input-joint/Dancing 8.jpg\n",
      "dataset/input-joint/Dancing 9.jpg\n",
      "dataset/input-joint/Dead bodies 1.jpg\n",
      "dataset/input-joint/Dead bodies 2.jpg\n",
      "dataset/input-joint/Angry pose 2.jpg\n",
      "dataset/input-joint/Depressed face 1.jpg\n",
      "dataset/input-joint/Depressed face 2.jpg\n",
      "dataset/input-joint/Depressed pose 1.jpg\n",
      "dataset/input-joint/Depressed pose 2.jpg\n",
      "dataset/input-joint/Depressed pose 4.jpg\n",
      "dataset/input-joint/Desert 1.jpg\n",
      "dataset/input-joint/Dessert 1.jpg\n",
      "dataset/input-joint/Dessert 2.jpg\n",
      "dataset/input-joint/Animal carcass 1.jpg\n",
      "dataset/input-joint/Dessert 4.jpg\n",
      "dataset/input-joint/Dessert 5.jpg\n",
      "dataset/input-joint/Dessert 6.jpg\n",
      "dataset/input-joint/Dessert 7.jpg\n",
      "dataset/input-joint/Dessert 8.jpg\n",
      "dataset/input-joint/Destruction 1.jpg\n",
      "dataset/input-joint/Destruction 4.jpg\n",
      "dataset/input-joint/Destruction 5.jpg\n",
      "dataset/input-joint/Destruction 6.jpg\n",
      "dataset/input-joint/Animal carcass 2.jpg\n",
      "dataset/input-joint/Destruction 7.jpg\n",
      "dataset/input-joint/Destruction 8.jpg\n",
      "dataset/input-joint/Destruction 9.jpg\n",
      "dataset/input-joint/Destruction 10.jpg\n",
      "dataset/input-joint/Dirt 1.jpg\n",
      "dataset/input-joint/Destruction 2.jpg\n",
      "dataset/input-joint/Destruction 3.jpg\n",
      "dataset/input-joint/Dirt 2.jpg\n",
      "dataset/input-joint/Dirt 3.jpg\n",
      "dataset/input-joint/Dirt 4.jpg\n",
      "dataset/input-joint/Animal carcass 3.jpg\n",
      "dataset/input-joint/Dirt 5.jpg\n",
      "dataset/input-joint/Dock 1.jpg\n",
      "dataset/input-joint/Doctor 1.jpg\n",
      "dataset/input-joint/Doctor 2.jpg\n",
      "dataset/input-joint/Doctor 4.jpg\n",
      "dataset/input-joint/Doctor 5.jpg\n",
      "dataset/input-joint/Doctor 6.jpg\n",
      "dataset/input-joint/Doctor 7.jpg\n",
      "dataset/input-joint/Doctor 8.jpg\n",
      "dataset/input-joint/Animal carcass 4.jpg\n",
      "dataset/input-joint/Doctor 9.jpg\n",
      "dataset/input-joint/Dog 1.jpg\n",
      "dataset/input-joint/Dog 2.jpg\n",
      "dataset/input-joint/Dog 4.jpg\n",
      "dataset/input-joint/Dog 5.jpg\n",
      "dataset/input-joint/Dog 7.jpg\n",
      "dataset/input-joint/Dog 8.jpg\n",
      "dataset/input-joint/Dog 9.jpg\n",
      "dataset/input-joint/Animal carcass 5.jpg\n",
      "dataset/input-joint/Dog 10.jpg\n",
      "dataset/input-joint/Dog 12.jpg\n",
      "dataset/input-joint/Dog 13.jpg\n",
      "dataset/input-joint/Dog 14.jpg\n",
      "dataset/input-joint/Dog 15.jpg\n",
      "dataset/input-joint/Dog 16.jpg\n",
      "dataset/input-joint/Dog 17.jpg\n",
      "dataset/input-joint/Dog 18.jpg\n",
      "dataset/input-joint/Animal carcass 6.jpg\n",
      "dataset/input-joint/Dog 21.jpg\n",
      "dataset/input-joint/Dog 22.jpg\n",
      "dataset/input-joint/Dog 23.jpg\n",
      "dataset/input-joint/Dog 24.jpg\n",
      "dataset/input-joint/Dog 25.jpg\n",
      "dataset/input-joint/Dog 26.jpg\n",
      "dataset/input-joint/Dog 27.jpg\n",
      "dataset/input-joint/Dog 28.jpg\n",
      "dataset/input-joint/Dog 29.jpg\n",
      "dataset/input-joint/Archery 1.jpg\n",
      "dataset/input-joint/Dog 30.jpg\n",
      "dataset/input-joint/Dog attack 1.jpg\n",
      "dataset/input-joint/Dog attack 2.jpg\n",
      "dataset/input-joint/Dog attack 3.jpg\n",
      "dataset/input-joint/Drink 1.jpg\n",
      "dataset/input-joint/Drink 2.jpg\n",
      "dataset/input-joint/Dummy 1.jpg\n",
      "dataset/input-joint/Eating 1.jpg\n",
      "dataset/input-joint/Eating 2.jpg\n",
      "dataset/input-joint/Archery 2.jpg\n",
      "dataset/input-joint/Eating 3.jpg\n",
      "dataset/input-joint/Elephant 1.jpg\n",
      "dataset/input-joint/Excited face 1.jpg\n",
      "dataset/input-joint/Excited face 2.jpg\n",
      "dataset/input-joint/Excited face 3.jpg\n",
      "dataset/input-joint/Excited face 4.jpg\n",
      "dataset/input-joint/Excited face 5.jpg\n",
      "dataset/input-joint/Excited face 6.jpg\n",
      "dataset/input-joint/Excited face 7.jpg\n",
      "dataset/input-joint/Exercise 1.jpg\n",
      "dataset/input-joint/Acorns 3.jpg\n",
      "dataset/input-joint/Astronaut 1.jpg\n",
      "dataset/input-joint/Exercise 2.jpg\n",
      "dataset/input-joint/Exercise 3.jpg\n",
      "dataset/input-joint/Explosion 1.jpg\n",
      "dataset/input-joint/Explosion 2.jpg\n",
      "dataset/input-joint/Explosion 3.jpg\n",
      "dataset/input-joint/Explosion 4.jpg\n",
      "dataset/input-joint/Explosion 5.jpg\n",
      "dataset/input-joint/Explosion 6.jpg\n",
      "dataset/input-joint/Father 1.jpg\n",
      "dataset/input-joint/Feces 1.jpg\n",
      "dataset/input-joint/Astronaut 2.jpg\n",
      "dataset/input-joint/Feces 2.jpg\n",
      "dataset/input-joint/Fence 1.jpg\n",
      "dataset/input-joint/Fence 2.jpg\n",
      "dataset/input-joint/Fence 3.jpg\n",
      "dataset/input-joint/Fence 4.jpg\n",
      "dataset/input-joint/Fence 5.jpg\n",
      "dataset/input-joint/Fence 6.jpg\n",
      "dataset/input-joint/Ferret 1.jpg\n",
      "dataset/input-joint/Fire 1.jpg\n",
      "dataset/input-joint/Fire 2.jpg\n",
      "dataset/input-joint/Baby 1.jpg\n",
      "dataset/input-joint/Fire 3.jpg\n",
      "dataset/input-joint/Fire 4.jpg\n",
      "dataset/input-joint/Fire 5.jpg\n",
      "dataset/input-joint/Fire 6.jpg\n",
      "dataset/input-joint/Fire 7.jpg\n",
      "dataset/input-joint/Fire 8.jpg\n",
      "dataset/input-joint/Fire 9.jpg\n",
      "dataset/input-joint/Fire 10.jpg\n",
      "dataset/input-joint/Fire 11.jpg\n",
      "dataset/input-joint/Baby 2.jpg\n",
      "dataset/input-joint/Fire hydrant 2.jpg\n",
      "dataset/input-joint/Fire hydrant 3.jpg\n",
      "dataset/input-joint/Fire hydrant 4.jpg\n",
      "dataset/input-joint/Fireman 1.jpg\n",
      "dataset/input-joint/Fireworks 1.jpg\n",
      "dataset/input-joint/Fireworks 2.jpg\n",
      "dataset/input-joint/Fireworks 3.jpg\n",
      "dataset/input-joint/Fireworks 4.jpg\n",
      "dataset/input-joint/Fireworks 5.jpg\n",
      "dataset/input-joint/Fireworks 6.jpg\n",
      "dataset/input-joint/Baby 3.jpg\n",
      "dataset/input-joint/Fireworks 7.jpg\n",
      "dataset/input-joint/Flood 1.jpg\n",
      "dataset/input-joint/Flood 2.jpg\n",
      "dataset/input-joint/Flood 3.jpg\n",
      "dataset/input-joint/Flowers 1.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/input-joint/Flowers 2.jpg\n",
      "dataset/input-joint/Flowers 3.jpg\n",
      "dataset/input-joint/Flowers 4.jpg\n",
      "dataset/input-joint/Flowers 5.jpg\n",
      "dataset/input-joint/Flowers 6.jpg\n",
      "dataset/input-joint/Baby 4.jpg\n",
      "dataset/input-joint/Flowers 8.jpg\n",
      "dataset/input-joint/Flowers 9.jpg\n",
      "dataset/input-joint/Food 2.jpg\n",
      "dataset/input-joint/Food 3.jpg\n",
      "dataset/input-joint/Food 4.jpg\n",
      "dataset/input-joint/Food 6.jpg\n",
      "dataset/input-joint/Baby 5.jpg\n",
      "dataset/input-joint/Football player 1.jpg\n",
      "dataset/input-joint/Frisbee 1.jpg\n",
      "dataset/input-joint/Frustrated pose 3.jpg\n",
      "dataset/input-joint/Frustrated pose 4.jpg\n",
      "dataset/input-joint/Frustrated pose 5.jpg\n",
      "dataset/input-joint/Frustrated pose 6.jpg\n",
      "dataset/input-joint/Frustrated pose 7.jpg\n",
      "dataset/input-joint/Frustrated pose 8.jpg\n",
      "dataset/input-joint/Baby 6.jpg\n",
      "dataset/input-joint/Galaxy 1.jpg\n",
      "dataset/input-joint/Galaxy 2.jpg\n",
      "dataset/input-joint/Galaxy 3.jpg\n",
      "dataset/input-joint/Galaxy 4.jpg\n",
      "dataset/input-joint/Galaxy 5.jpg\n",
      "dataset/input-joint/Galaxy 6.jpg\n",
      "dataset/input-joint/Galaxy 7.jpg\n",
      "dataset/input-joint/Galaxy 8.jpg\n",
      "dataset/input-joint/Garbage dump 1.jpg\n",
      "dataset/input-joint/Baby 7.jpg\n",
      "dataset/input-joint/Garbage dump 2.jpg\n",
      "dataset/input-joint/Garbage dump 3.jpg\n",
      "dataset/input-joint/Garbage dump 4.jpg\n",
      "dataset/input-joint/Garbage dump 5.jpg\n",
      "dataset/input-joint/Garbage dump 6.jpg\n",
      "dataset/input-joint/Garbage dump 7.jpg\n",
      "dataset/input-joint/Garbage dump 8.jpg\n",
      "dataset/input-joint/Gargoyle 1.jpg\n",
      "dataset/input-joint/Gargoyle 2.jpg\n",
      "dataset/input-joint/Gazing 1.jpg\n",
      "dataset/input-joint/Baby 8.jpg\n",
      "dataset/input-joint/Gazing 2.jpg\n",
      "dataset/input-joint/Gazing 3.jpg\n",
      "dataset/input-joint/Gazing 4.jpg\n",
      "dataset/input-joint/Gazing 5.jpg\n",
      "dataset/input-joint/Gazing 7.jpg\n",
      "dataset/input-joint/Goat 1.jpg\n",
      "dataset/input-joint/Goat 2.jpg\n",
      "dataset/input-joint/Gorrila 1.jpg\n",
      "dataset/input-joint/Grass 1.jpg\n",
      "dataset/input-joint/Alcohol 1.jpg\n",
      "dataset/input-joint/Baby 9.jpg\n",
      "dataset/input-joint/Grass 2.jpg\n",
      "dataset/input-joint/Grass 3.jpg\n",
      "dataset/input-joint/Grass 4.jpg\n",
      "dataset/input-joint/Grass 5.jpg\n",
      "dataset/input-joint/Grass 6.jpg\n",
      "dataset/input-joint/Grass 7.jpg\n",
      "dataset/input-joint/Graveyard 2.jpg\n",
      "dataset/input-joint/Graveyard 3.jpg\n",
      "dataset/input-joint/Graveyard 4.jpg\n",
      "dataset/input-joint/Baby 10.jpg\n",
      "dataset/input-joint/Guitar 1.jpg\n",
      "dataset/input-joint/Gun 1.jpg\n",
      "dataset/input-joint/Gun 2.jpg\n",
      "dataset/input-joint/Gun 3.jpg\n",
      "dataset/input-joint/Gun 4.jpg\n",
      "dataset/input-joint/Gun 5.jpg\n",
      "dataset/input-joint/Gun 6.jpg\n",
      "dataset/input-joint/Gun 7.jpg\n",
      "dataset/input-joint/Gun 8.jpg\n",
      "dataset/input-joint/Band 1.jpg\n",
      "dataset/input-joint/Gun 10.jpg\n",
      "dataset/input-joint/Hallway 1.jpg\n",
      "dataset/input-joint/Hang gliding 1.jpg\n",
      "dataset/input-joint/Hang gliding 2.jpg\n",
      "dataset/input-joint/Hang gliding 3.jpg\n",
      "dataset/input-joint/Happy face 1.jpg\n",
      "dataset/input-joint/Happy face 2.jpg\n",
      "dataset/input-joint/Happy pose 1.jpg\n",
      "dataset/input-joint/Happy pose 2.jpg\n",
      "dataset/input-joint/Band 2.jpg\n",
      "dataset/input-joint/Happy pose 3.jpg\n",
      "dataset/input-joint/Heart 1.jpg\n",
      "dataset/input-joint/Heart 2.jpg\n",
      "dataset/input-joint/Heart 3.jpg\n",
      "dataset/input-joint/Horse 1.jpg\n",
      "dataset/input-joint/Horse racing 1.jpg\n",
      "dataset/input-joint/Injury 1.jpg\n",
      "dataset/input-joint/Injury 2.jpg\n",
      "dataset/input-joint/Injury 3.jpg\n",
      "dataset/input-joint/Bar 1.jpg\n",
      "dataset/input-joint/Injury 4.jpg\n",
      "dataset/input-joint/Intensity 1.jpg\n",
      "dataset/input-joint/Jail 1.jpg\n",
      "dataset/input-joint/Jail 2.jpg\n",
      "dataset/input-joint/Jail 3.jpg\n",
      "dataset/input-joint/Jail 4.jpg\n",
      "dataset/input-joint/Jail 5.jpg\n",
      "dataset/input-joint/Keyboard 1.jpg\n",
      "dataset/input-joint/Keyboard 2.jpg\n",
      "dataset/input-joint/Keyboard 3.jpg\n",
      "dataset/input-joint/Bar 2.jpg\n",
      "dataset/input-joint/Keys 1.jpg\n",
      "dataset/input-joint/KKK rally 1.jpg\n",
      "dataset/input-joint/Knife 1.jpg\n",
      "dataset/input-joint/Knife 2.jpg\n",
      "dataset/input-joint/Lake 1.jpg\n",
      "dataset/input-joint/Lake 2.jpg\n",
      "dataset/input-joint/Lake 3.jpg\n",
      "dataset/input-joint/Lake 4.jpg\n",
      "dataset/input-joint/Lake 5.jpg\n",
      "dataset/input-joint/Bar 3.jpg\n",
      "dataset/input-joint/Lake 6.jpg\n",
      "dataset/input-joint/Lake 7.jpg\n",
      "dataset/input-joint/Lake 8.jpg\n",
      "dataset/input-joint/Lake 9.jpg\n",
      "dataset/input-joint/Lake 10.jpg\n",
      "dataset/input-joint/Lake 11.jpg\n",
      "dataset/input-joint/Lake 12.jpg\n",
      "dataset/input-joint/Lake 13.jpg\n",
      "dataset/input-joint/Lake 14.jpg\n",
      "dataset/input-joint/Lake 15.jpg\n",
      "dataset/input-joint/Barbeque 1.jpg\n",
      "dataset/input-joint/Lake 16.jpg\n",
      "dataset/input-joint/Lake 17.jpg\n",
      "dataset/input-joint/Lamb 1.jpg\n",
      "dataset/input-joint/Lava 1.jpg\n",
      "dataset/input-joint/Lightning 1.jpg\n",
      "dataset/input-joint/Lightning 3.jpg\n",
      "dataset/input-joint/Lightning 4.jpg\n",
      "dataset/input-joint/Lightning 5.jpg\n",
      "dataset/input-joint/Lightning 6.jpg\n",
      "dataset/input-joint/Barbeque 2.jpg\n",
      "dataset/input-joint/Lightning 7.jpg\n",
      "dataset/input-joint/Lion 1.jpg\n",
      "dataset/input-joint/Lion 2.jpg\n",
      "dataset/input-joint/Lion 3.jpg\n",
      "dataset/input-joint/Lion 4.jpg\n",
      "dataset/input-joint/Lion 5.jpg\n",
      "dataset/input-joint/Massage 1.jpg\n",
      "dataset/input-joint/Massage 2.jpg\n",
      "dataset/input-joint/Memorial 1.jpg\n",
      "dataset/input-joint/Bark 1.jpg\n",
      "dataset/input-joint/Memorial 2.jpg\n",
      "dataset/input-joint/Miserable face 1.jpg\n",
      "dataset/input-joint/Miserable face 2.jpg\n",
      "dataset/input-joint/Miserable pose 1.jpg\n",
      "dataset/input-joint/Miserable pose 2.jpg\n",
      "dataset/input-joint/Miserable pose 3.jpg\n",
      "dataset/input-joint/Miserable pose 4.jpg\n",
      "dataset/input-joint/Money 1.jpg\n",
      "dataset/input-joint/Alcohol 2.jpg\n",
      "dataset/input-joint/Bark 2.jpg\n",
      "dataset/input-joint/Monkey 2.jpg\n",
      "dataset/input-joint/Monkey 3.jpg\n",
      "dataset/input-joint/Monkey 4.jpg\n",
      "dataset/input-joint/Moon 1.jpg\n",
      "dataset/input-joint/Mother 1.jpg\n",
      "dataset/input-joint/Mother 2.jpg\n",
      "dataset/input-joint/Mother 4.jpg\n",
      "dataset/input-joint/Mother 5.jpg\n",
      "dataset/input-joint/Bark 3.jpg\n",
      "dataset/input-joint/Mother 7.jpg\n",
      "dataset/input-joint/Mother 8.jpg\n",
      "dataset/input-joint/Mother 9.jpg\n",
      "dataset/input-joint/Motocross 1.jpg\n",
      "dataset/input-joint/Musician 1.jpg\n",
      "dataset/input-joint/Nature 1.jpg\n",
      "dataset/input-joint/Nature 2.jpg\n",
      "dataset/input-joint/Neonazi 1.jpg\n",
      "dataset/input-joint/Neutral face 1.jpg\n",
      "dataset/input-joint/Bark 4.jpg\n",
      "dataset/input-joint/Neutral face 2.jpg\n",
      "dataset/input-joint/Neutral face 3.jpg\n",
      "dataset/input-joint/Neutral face 4.jpg\n",
      "dataset/input-joint/Neutral face 5.jpg\n",
      "dataset/input-joint/Neutral pose 1.jpg\n",
      "dataset/input-joint/Neutral pose 2.jpg\n",
      "dataset/input-joint/Neutral pose 3.jpg\n",
      "dataset/input-joint/Nude couple 1.jpg\n",
      "dataset/input-joint/Nude couple 2.jpg\n",
      "dataset/input-joint/Nude couple 3.jpg\n",
      "dataset/input-joint/Bark 5.jpg\n",
      "dataset/input-joint/Nude couple 4.jpg\n",
      "dataset/input-joint/Nude couple 5.jpg\n",
      "dataset/input-joint/Nude couple 6.jpg\n",
      "dataset/input-joint/Nude couple 7.jpg\n",
      "dataset/input-joint/Nude couple 8.jpg\n",
      "dataset/input-joint/Nude couple 9.jpg\n",
      "dataset/input-joint/Nude couple 10.jpg\n",
      "dataset/input-joint/Nude couple 11.jpg\n",
      "dataset/input-joint/Nude couple 13.jpg\n",
      "dataset/input-joint/Bark 6.jpg\n",
      "dataset/input-joint/Nude couple 14.jpg\n",
      "dataset/input-joint/Nude man 1.jpg\n",
      "dataset/input-joint/Nude man 2.jpg\n",
      "dataset/input-joint/Nude man 4.jpg\n",
      "dataset/input-joint/Nude man 5.jpg\n",
      "dataset/input-joint/Nude man 6.jpg\n",
      "dataset/input-joint/Nude man 7.jpg\n",
      "dataset/input-joint/Nude man 9.jpg\n",
      "dataset/input-joint/Nude man 10.jpg\n",
      "dataset/input-joint/Barrels 1.jpg\n",
      "dataset/input-joint/Nude man 11.jpg\n",
      "dataset/input-joint/Nude man 12.jpg\n",
      "dataset/input-joint/Nude man 13.jpg\n",
      "dataset/input-joint/Nude man 14.jpg\n",
      "dataset/input-joint/Nude man 15.jpg\n",
      "dataset/input-joint/Nude man 16.jpg\n",
      "dataset/input-joint/Nude man 17.jpg\n",
      "dataset/input-joint/Nude man 18.jpg\n",
      "dataset/input-joint/Nude man 19.jpg\n",
      "dataset/input-joint/Nude man 20.jpg\n",
      "dataset/input-joint/BDSM 1.jpg\n",
      "dataset/input-joint/Nude man 3.jpg\n",
      "dataset/input-joint/Nude man 21.jpg\n",
      "dataset/input-joint/Nude man 22.jpg\n",
      "dataset/input-joint/Nude man 23.jpg\n",
      "dataset/input-joint/Nude woman 1.jpg\n",
      "dataset/input-joint/Nude woman 2.jpg\n",
      "dataset/input-joint/Nude woman 3.jpg\n",
      "dataset/input-joint/Nude woman 4.jpg\n",
      "dataset/input-joint/Nude woman 6.jpg\n",
      "dataset/input-joint/BDSM 2.jpg\n",
      "dataset/input-joint/Nude woman 7.jpg\n",
      "dataset/input-joint/Nude woman 8.jpg\n",
      "dataset/input-joint/Nude woman 9.jpg\n",
      "dataset/input-joint/Nude woman 10.jpg\n",
      "dataset/input-joint/Nude woman 11.jpg\n",
      "dataset/input-joint/Nude woman 12.jpg\n",
      "dataset/input-joint/Nude woman 13.jpg\n",
      "dataset/input-joint/Nude woman 15.jpg\n",
      "dataset/input-joint/Nude woman 16.jpg\n",
      "dataset/input-joint/Nude woman 17.jpg\n",
      "dataset/input-joint/Nude woman 18.jpg\n",
      "dataset/input-joint/Nude woman 20.jpg\n",
      "dataset/input-joint/Nude woman 21.jpg\n",
      "dataset/input-joint/Nude woman 22.jpg\n",
      "dataset/input-joint/Office supplies 1.jpg\n",
      "dataset/input-joint/Office supplies 2.jpg\n",
      "dataset/input-joint/Office supplies 3.jpg\n",
      "dataset/input-joint/Office supplies 4.jpg\n",
      "dataset/input-joint/Beach 1.jpg\n",
      "dataset/input-joint/Office supplies 5.jpg\n",
      "dataset/input-joint/Opossum 1.jpg\n",
      "dataset/input-joint/Orangutan 1.jpg\n",
      "dataset/input-joint/Ornament 1.jpg\n",
      "dataset/input-joint/Paintbrush 1.jpg\n",
      "dataset/input-joint/Paper 1.jpg\n",
      "dataset/input-joint/Paper 2.jpg\n",
      "dataset/input-joint/Paper 3.jpg\n",
      "dataset/input-joint/Paper 4.jpg\n",
      "dataset/input-joint/Paper 5.jpg\n",
      "dataset/input-joint/Alcohol 3.jpg\n",
      "dataset/input-joint/Beach 2.jpg\n",
      "dataset/input-joint/Paperclips 1.jpg\n",
      "dataset/input-joint/Paperclips 2.jpg\n",
      "dataset/input-joint/Parachuting 1.jpg\n",
      "dataset/input-joint/Parachuting 2.jpg\n",
      "dataset/input-joint/Parachuting 3.jpg\n",
      "dataset/input-joint/Parachuting 4.jpg\n",
      "dataset/input-joint/Parade 1.jpg\n",
      "dataset/input-joint/Parasailing 1.jpg\n",
      "dataset/input-joint/Beach 3.jpg\n",
      "dataset/input-joint/Parasailing 2.jpg\n",
      "dataset/input-joint/Parasailing 3.jpg\n",
      "dataset/input-joint/Parasailing 4.jpg\n",
      "dataset/input-joint/Party 1.jpg\n",
      "dataset/input-joint/Path 1.jpg\n",
      "dataset/input-joint/Penguins 1.jpg\n",
      "dataset/input-joint/Performance 1.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/input-joint/Performance 2.jpg\n",
      "dataset/input-joint/Phone 1.jpg\n",
      "dataset/input-joint/Beach 4.jpg\n",
      "dataset/input-joint/Picnic 2.jpg\n",
      "dataset/input-joint/Picnic 3.jpg\n",
      "dataset/input-joint/Picnic 4.jpg\n",
      "dataset/input-joint/Pig 1.jpg\n",
      "dataset/input-joint/Pig 2.jpg\n",
      "dataset/input-joint/Pigeon 1.jpg\n",
      "dataset/input-joint/Pigeon 3.jpg\n",
      "dataset/input-joint/Pigeon 4.jpg\n",
      "dataset/input-joint/Beach 5.jpg\n",
      "dataset/input-joint/Pigeon 5.jpg\n",
      "dataset/input-joint/Pigeon 6.jpg\n",
      "dataset/input-joint/Pinecone 1.jpg\n",
      "dataset/input-joint/Pinecone 2.jpg\n",
      "dataset/input-joint/Pinecone 3.jpg\n",
      "dataset/input-joint/Pinecone 4.jpg\n",
      "dataset/input-joint/Plane crash 1.jpg\n",
      "dataset/input-joint/Plane crash 2.jpg\n",
      "dataset/input-joint/Plane crash 3.jpg\n",
      "dataset/input-joint/Plane crash 4.jpg\n",
      "dataset/input-joint/Beach 6.jpg\n",
      "dataset/input-joint/Police 1.jpg\n",
      "dataset/input-joint/Police 2.jpg\n",
      "dataset/input-joint/Police 4.jpg\n",
      "dataset/input-joint/Police 5.jpg\n",
      "dataset/input-joint/Pollution 1.jpg\n",
      "dataset/input-joint/Power lines 1.jpg\n",
      "dataset/input-joint/Present 2.jpg\n",
      "dataset/input-joint/Prison 1.jpg\n",
      "dataset/input-joint/Beach 7.jpg\n",
      "dataset/input-joint/Prison 2.jpg\n",
      "dataset/input-joint/Pumpkin 1.jpg\n",
      "dataset/input-joint/Raccoon 1.jpg\n",
      "dataset/input-joint/Rafting 1.jpg\n",
      "dataset/input-joint/Rafting 3.jpg\n",
      "dataset/input-joint/Rafting 4.jpg\n",
      "dataset/input-joint/Rafting 5.jpg\n",
      "dataset/input-joint/Railroad 1.jpg\n",
      "dataset/input-joint/Beach 8.jpg\n",
      "dataset/input-joint/Rainbow 1.jpg\n",
      "dataset/input-joint/Rainbow 2.jpg\n",
      "dataset/input-joint/Research 1.jpg\n",
      "dataset/input-joint/Road 1.jpg\n",
      "dataset/input-joint/Rock climbing 1.jpg\n",
      "dataset/input-joint/Rock climbing 2.jpg\n",
      "dataset/input-joint/Rock climbing 3.jpg\n",
      "dataset/input-joint/Rock climbing 4.jpg\n",
      "dataset/input-joint/Rocks 1.jpg\n",
      "dataset/input-joint/Rocks 2.jpg\n",
      "dataset/input-joint/Bear 1.jpg\n",
      "dataset/input-joint/Rocks 3.jpg\n",
      "dataset/input-joint/Rocks 6.jpg\n",
      "dataset/input-joint/Rocks 7.jpg\n",
      "dataset/input-joint/Rollercoaster 1.jpg\n",
      "dataset/input-joint/Rollercoaster 2.jpg\n",
      "dataset/input-joint/Rollercoaster 3.jpg\n",
      "dataset/input-joint/Roofing 2.jpg\n",
      "dataset/input-joint/Bear 2.jpg\n",
      "dataset/input-joint/Roofing 3.jpg\n",
      "dataset/input-joint/Roofing 4.jpg\n",
      "dataset/input-joint/Roofing 5.jpg\n",
      "dataset/input-joint/Rooster 1.jpg\n",
      "dataset/input-joint/Rubber duck 1.jpg\n",
      "dataset/input-joint/Rugby 1.jpg\n",
      "dataset/input-joint/Rugby 2.jpg\n",
      "dataset/input-joint/Running away 1.jpg\n",
      "dataset/input-joint/Sad face 1.jpg\n",
      "dataset/input-joint/Sad face 2.jpg\n",
      "dataset/input-joint/Bear 3.jpg\n",
      "dataset/input-joint/Sad face 3.jpg\n",
      "dataset/input-joint/Sad face 4.jpg\n",
      "dataset/input-joint/Sad face 5.jpg\n",
      "dataset/input-joint/Sad face 6.jpg\n",
      "dataset/input-joint/Sad face 7.jpg\n",
      "dataset/input-joint/Sad face 8.jpg\n",
      "dataset/input-joint/Sad face 9.jpg\n",
      "dataset/input-joint/Sad pose 1.jpg\n",
      "dataset/input-joint/Sad pose 2.jpg\n",
      "dataset/input-joint/Alcohol 4.jpg\n",
      "dataset/input-joint/Bed 1.jpg\n",
      "dataset/input-joint/Sad pose 4.jpg\n",
      "dataset/input-joint/Sad pose 6.jpg\n",
      "dataset/input-joint/Sad pose 7.jpg\n",
      "dataset/input-joint/Sailing 1.jpg\n",
      "dataset/input-joint/Sailing 2.jpg\n",
      "dataset/input-joint/Sailing 3.jpg\n",
      "dataset/input-joint/Satellite 1.jpg\n",
      "dataset/input-joint/Scared face 1.jpg\n",
      "dataset/input-joint/Bee 1.jpg\n",
      "dataset/input-joint/Scared face 2.jpg\n",
      "dataset/input-joint/Scared face 3.jpg\n",
      "dataset/input-joint/Scared face 4.jpg\n",
      "dataset/input-joint/Scared face 5.jpg\n",
      "dataset/input-joint/Scary face 1.jpg\n",
      "dataset/input-joint/Scary face 2.jpg\n",
      "dataset/input-joint/School 1.jpg\n",
      "dataset/input-joint/School 2.jpg\n",
      "dataset/input-joint/School 3.jpg\n",
      "dataset/input-joint/School 4.jpg\n",
      "dataset/input-joint/Biking 1.jpg\n",
      "dataset/input-joint/School 6.jpg\n",
      "dataset/input-joint/School 7.jpg\n",
      "dataset/input-joint/School 8.jpg\n",
      "dataset/input-joint/Seal 1.jpg\n",
      "dataset/input-joint/Severed finger 1.jpg\n",
      "dataset/input-joint/Shark 1.jpg\n",
      "dataset/input-joint/Shark 2.jpg\n",
      "dataset/input-joint/Shark 3.jpg\n",
      "dataset/input-joint/Shark 4.jpg\n",
      "dataset/input-joint/Billiards 1.jpg\n",
      "dataset/input-joint/Shark 5.jpg\n",
      "dataset/input-joint/Shark 6.jpg\n",
      "dataset/input-joint/Shark 7.jpg\n",
      "dataset/input-joint/Shark 8.jpg\n",
      "dataset/input-joint/Shark 9.jpg\n",
      "dataset/input-joint/Shark 11.jpg\n",
      "dataset/input-joint/Shooting 1.jpg\n",
      "dataset/input-joint/Shot 1.jpg\n",
      "dataset/input-joint/Shot 2.jpg\n",
      "dataset/input-joint/Bird 1.jpg\n",
      "dataset/input-joint/Shot 3.jpg\n",
      "dataset/input-joint/Siblings 1.jpg\n",
      "dataset/input-joint/Sidewalk 1.jpg\n",
      "dataset/input-joint/Sidewalk 2.jpg\n",
      "dataset/input-joint/Sidewalk 3.jpg\n",
      "dataset/input-joint/Sidewalk 4.jpg\n",
      "dataset/input-joint/Sidewalk 5.jpg\n",
      "dataset/input-joint/Skier 1.jpg\n",
      "dataset/input-joint/Skijump 1.jpg\n",
      "dataset/input-joint/Skijump 2.jpg\n",
      "dataset/input-joint/Skinhead 1.jpg\n",
      "dataset/input-joint/Sky 1.jpg\n",
      "dataset/input-joint/Skydiving 1.jpg\n",
      "dataset/input-joint/Skydiving 2.jpg\n",
      "dataset/input-joint/Skydiving 3.jpg\n",
      "dataset/input-joint/Skydiving 4.jpg\n",
      "dataset/input-joint/Skydiving 5.jpg\n",
      "dataset/input-joint/Skyscraper 1.jpg\n",
      "dataset/input-joint/Skyscraper 2.jpg\n",
      "dataset/input-joint/Sleepy pose 1.jpg\n",
      "dataset/input-joint/Sleepy pose 2.jpg\n",
      "dataset/input-joint/Sleepy pose 3.jpg\n",
      "dataset/input-joint/Sleepy pose 4.jpg\n",
      "dataset/input-joint/Snake 1.jpg\n",
      "dataset/input-joint/Snake 2.jpg\n",
      "dataset/input-joint/Snake 3.jpg\n",
      "dataset/input-joint/Bird 4.jpg\n",
      "dataset/input-joint/Snake 4.jpg\n",
      "dataset/input-joint/Snake 5.jpg\n",
      "dataset/input-joint/Snake 6.jpg\n",
      "dataset/input-joint/Snow 1.jpg\n",
      "dataset/input-joint/Snow 2.jpg\n",
      "dataset/input-joint/Snow 3.jpg\n",
      "dataset/input-joint/Snow 4.jpg\n",
      "dataset/input-joint/Snow 5.jpg\n",
      "dataset/input-joint/Soccer 1.jpg\n",
      "dataset/input-joint/Soccer 2.jpg\n",
      "dataset/input-joint/Socks 1.jpg\n",
      "dataset/input-joint/Solar panel 1.jpg\n",
      "dataset/input-joint/Soldiers 1.jpg\n",
      "dataset/input-joint/Soldiers 3.jpg\n",
      "dataset/input-joint/Soldiers 4.jpg\n",
      "dataset/input-joint/Soldiers 5.jpg\n",
      "dataset/input-joint/Soldiers 6.jpg\n",
      "dataset/input-joint/Soldiers 8.jpg\n",
      "dataset/input-joint/Birthday 1.jpg\n",
      "dataset/input-joint/Soldiers 9.jpg\n",
      "dataset/input-joint/Soldiers 10.jpg\n",
      "dataset/input-joint/Soup 1.jpg\n",
      "dataset/input-joint/Spider 1.jpg\n",
      "dataset/input-joint/Spider 2.jpg\n",
      "dataset/input-joint/Statue 2.jpg\n",
      "dataset/input-joint/Stingray 2.jpg\n",
      "dataset/input-joint/Stingray 3.jpg\n",
      "dataset/input-joint/Alcohol 5.jpg\n",
      "dataset/input-joint/Birthday 2.jpg\n",
      "dataset/input-joint/Storage 1.jpg\n",
      "dataset/input-joint/Storage 3.jpg\n",
      "dataset/input-joint/Street 1.jpg\n",
      "dataset/input-joint/Street 2.jpg\n",
      "dataset/input-joint/Street 3.jpg\n",
      "dataset/input-joint/Street 4.jpg\n",
      "dataset/input-joint/Street 5.jpg\n",
      "dataset/input-joint/Sun 1.jpg\n",
      "dataset/input-joint/Sunflower 1.jpg\n",
      "dataset/input-joint/Birthday 3.jpg\n",
      "dataset/input-joint/Sunset 1.jpg\n",
      "dataset/input-joint/Sunset 2.jpg\n",
      "dataset/input-joint/Sunset 3.jpg\n",
      "dataset/input-joint/Sunset 4.jpg\n",
      "dataset/input-joint/Sunset 5.jpg\n",
      "dataset/input-joint/Sunset 6.jpg\n",
      "dataset/input-joint/Surgery 1.jpg\n",
      "dataset/input-joint/Surgery 2.jpg\n",
      "dataset/input-joint/Surgery 3.jpg\n",
      "dataset/input-joint/Bloody knife 1.jpg\n",
      "dataset/input-joint/Surgery 5.jpg\n",
      "dataset/input-joint/Surprise 1.jpg\n",
      "dataset/input-joint/Surprise 2.jpg\n",
      "dataset/input-joint/Swingset 1.jpg\n",
      "dataset/input-joint/Thunderstorm 1.jpg\n",
      "dataset/input-joint/Thunderstorm 2.jpg\n",
      "dataset/input-joint/Thunderstorm 3.jpg\n",
      "dataset/input-joint/Thunderstorm 4.jpg\n",
      "dataset/input-joint/Bloody knife 2.jpg\n",
      "dataset/input-joint/Thunderstorm 6.jpg\n",
      "dataset/input-joint/Thunderstorm 7.jpg\n",
      "dataset/input-joint/Thunderstorm 8.jpg\n",
      "dataset/input-joint/Thunderstorm 9.jpg\n",
      "dataset/input-joint/Thunderstorm 10.jpg\n",
      "dataset/input-joint/Thunderstorm 11.jpg\n",
      "dataset/input-joint/Tickling 1.jpg\n",
      "dataset/input-joint/Tiger 1.jpg\n",
      "dataset/input-joint/Tiger 2.jpg\n",
      "dataset/input-joint/Timber 1.jpg\n",
      "dataset/input-joint/Boat 1.jpg\n",
      "dataset/input-joint/Timber 2.jpg\n",
      "dataset/input-joint/Timber 3.jpg\n",
      "dataset/input-joint/Timber 4.jpg\n",
      "dataset/input-joint/Toast 1.jpg\n",
      "dataset/input-joint/Toilet 1.jpg\n",
      "dataset/input-joint/Toilet 2.jpg\n",
      "dataset/input-joint/Toilet 3.jpg\n",
      "dataset/input-joint/Toilet 4.jpg\n",
      "dataset/input-joint/Tornado 1.jpg\n",
      "dataset/input-joint/Tornado 2.jpg\n",
      "dataset/input-joint/Bored face 1.jpg\n",
      "dataset/input-joint/Tornado 4.jpg\n",
      "dataset/input-joint/Tornado 5.jpg\n",
      "dataset/input-joint/Torture chamber 1.jpg\n",
      "dataset/input-joint/Traffic 1.jpg\n",
      "dataset/input-joint/Tumor 1.jpg\n",
      "dataset/input-joint/Volcano 1.jpg\n",
      "dataset/input-joint/Volcano 2.jpg\n",
      "dataset/input-joint/Volcano 3.jpg\n",
      "dataset/input-joint/Wall 1.jpg\n",
      "dataset/input-joint/Bored pose 1.jpg\n",
      "dataset/input-joint/Wall 2.jpg\n",
      "dataset/input-joint/Wall 3.jpg\n",
      "dataset/input-joint/Wall 4.jpg\n",
      "dataset/input-joint/Wall 5.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/input-joint/War 1.jpg\n",
      "dataset/input-joint/War 2.jpg\n",
      "dataset/input-joint/War 4.jpg\n",
      "dataset/input-joint/War 5.jpg\n",
      "dataset/input-joint/War 6.jpg\n",
      "dataset/input-joint/Bored pose 2.jpg\n",
      "dataset/input-joint/War 7.jpg\n",
      "dataset/input-joint/War 8.jpg\n",
      "dataset/input-joint/Waterfall 1.jpg\n",
      "dataset/input-joint/Weapon 1.jpg\n",
      "dataset/input-joint/Wedding 1.jpg\n",
      "dataset/input-joint/Wedding 2.jpg\n",
      "dataset/input-joint/Wedding 3.jpg\n",
      "dataset/input-joint/Wedding 6.jpg\n",
      "dataset/input-joint/Bored pose 3.jpg\n",
      "dataset/input-joint/Wedding 7.jpg\n",
      "dataset/input-joint/Wedding 8.jpg\n",
      "dataset/input-joint/Wedding 9.jpg\n",
      "dataset/input-joint/Wedding 10.jpg\n",
      "dataset/input-joint/Wedding 11.jpg\n",
      "dataset/input-joint/Wedding ring 1.jpg\n",
      "dataset/input-joint/Windmill 1.jpg\n",
      "dataset/input-joint/Wolf 1.jpg\n",
      "dataset/input-joint/Wolf 2.jpg\n",
      "dataset/input-joint/Bored pose 4.jpg\n",
      "dataset/input-joint/Woods 1.jpg\n",
      "dataset/input-joint/Yarn 1.jpg\n",
      "dataset/input-joint/Yarn 2.jpg\n",
      "dataset/input-joint/Yarn 3.jpg\n",
      "dataset/input-joint/Yarn 4.jpg\n",
      "dataset/input-joint/Yoga 1.jpg\n",
      "dataset/input-joint/Yoga 2.jpg\n",
      "dataset/input-joint/Yoga 3.jpg\n",
      "dataset/input-joint/Yoga 4.jpg\n",
      "dataset/input-joint/Yoga 5.jpg\n",
      "dataset/input-joint/Alcohol 6.jpg\n",
      "dataset/input-joint/Bored pose 5.jpg\n",
      "dataset/input-joint/Zebra 1.jpg\n",
      "dataset/input-joint/Bored pose 6.jpg\n",
      "dataset/input-joint/Bottle 1.jpg\n",
      "dataset/input-joint/Boxing 1.jpg\n",
      "dataset/input-joint/Boxing 2.jpg\n",
      "dataset/input-joint/Bridge 1.jpg\n",
      "dataset/input-joint/Bubble 1.jpg\n",
      "dataset/input-joint/Bubble 2.jpg\n",
      "dataset/input-joint/Building 1.jpg\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "cnt = 0\n",
    "# https://github.com/fchollet/deep-learning-models\n",
    "for img_name in inputData['image_name']:\n",
    "    fpath = input_images_src + img_name\n",
    "    cnt += 1\n",
    "    print(fpath)\n",
    "    img = load_img(fpath, target_size=(224,224))\n",
    "    x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "    #x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    X_train.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filenames ['Acorns 1.jpg', 'Building 2.jpg', 'Bungee jumping 1.jpg', 'Bungee jumping 2.jpg', 'Camping 1.jpg', 'Camping 2.jpg', 'Camping 4.jpg', 'Camping 6.jpg', 'Camping 7.jpg', 'Alcohol 8.jpg', 'Camping 10.jpg', 'Candle 1.jpg', 'Car 1.jpg', 'Car 2.jpg', 'Car accident 2.jpg', 'Car accident 3.jpg', 'Car accident 4.jpg', 'Ambulance 1.jpg', 'Car crash 1.jpg', 'Car crash 2.jpg', 'Car crash 3.jpg', 'Car race 1.jpg', 'Car race 2.jpg', 'Car race 3.jpg', 'Car race 4.jpg', 'Cardboard 1.jpg', 'Cardboard 2.jpg', 'Cardboard 3.jpg', 'Ambulance 2.jpg', 'Cat 1.jpg', 'Cat 2.jpg', 'Cat 3.jpg', 'Cat 4.jpg', 'Cat 5.jpg', 'Cat 6.jpg', 'Cat 7.jpg', 'Cat 8.jpg', 'Cat 9.jpg', 'Cat 10.jpg', 'Ambulance 3.jpg', 'Cat 11.jpg', 'Cat 12.jpg', 'Cat 13.jpg', 'Cat 14.jpg', 'Celebration 1.jpg', 'Celebration 2.jpg', 'Cemetery 1.jpg', 'Cemetery 2.jpg', 'Cemetery 3.jpg', 'Cemetery 4.jpg', 'Angry face 1.jpg', 'Cemetery 5.jpg', 'Cheerleader 1.jpg', 'Cheerleader 2.jpg', 'Child labor 2.jpg', 'Child labor 3.jpg', 'Child labor 4.jpg', 'Children 1.jpg', 'Chipmunk 1.jpg', 'Chipmunk 2.jpg', 'Angry face 2.jpg', 'Chipmunk 3.jpg', 'City 1.jpg', 'Clean 1.jpg', 'Cliff diver 1.jpg', 'Cliff diver 2.jpg', 'Cliff diver 3.jpg', 'Cockroach 1.jpg', 'Cockroach 2.jpg', 'Cockroach 3.jpg', 'Cockroach 4.jpg', 'Angry face 3.jpg', 'Cold 1.jpg', 'Cold 2.jpg', 'Cold 3.jpg', 'Cold 4.jpg', 'Cold 5.jpg', 'Cold 6.jpg', 'Cold 8.jpg', 'Collaboration 1.jpg', 'Angry face 4.jpg', 'Cotton swabs 1.jpg', 'Cotton swabs 2.jpg', 'Cotton swabs 3.jpg', 'Couple 1.jpg', 'Couple 2.jpg', 'Couple 3.jpg', 'Couple 5.jpg', 'Couple 6.jpg', 'Couple 7.jpg', 'Angry face 5.jpg', 'Couple 9.jpg', 'Crow 1.jpg', 'Crow 2.jpg', 'Cups 2.jpg', 'Cups 3.jpg', 'Dancing 1.jpg', 'Acorns 2.jpg', 'Angry pose 1.jpg', 'Dancing 2.jpg', 'Dancing 3.jpg', 'Dancing 4.jpg', 'Dancing 5.jpg', 'Dancing 6.jpg', 'Dancing 8.jpg', 'Dancing 9.jpg', 'Dead bodies 1.jpg', 'Dead bodies 2.jpg', 'Angry pose 2.jpg', 'Depressed face 1.jpg', 'Depressed face 2.jpg', 'Depressed pose 1.jpg', 'Depressed pose 2.jpg', 'Depressed pose 4.jpg', 'Desert 1.jpg', 'Dessert 1.jpg', 'Dessert 2.jpg', 'Animal carcass 1.jpg', 'Dessert 4.jpg', 'Dessert 5.jpg', 'Dessert 6.jpg', 'Dessert 7.jpg', 'Dessert 8.jpg', 'Destruction 1.jpg', 'Destruction 4.jpg', 'Destruction 5.jpg', 'Destruction 6.jpg', 'Animal carcass 2.jpg', 'Destruction 7.jpg', 'Destruction 8.jpg', 'Destruction 9.jpg', 'Destruction 10.jpg', 'Dirt 1.jpg', 'Destruction 2.jpg', 'Destruction 3.jpg', 'Dirt 2.jpg', 'Dirt 3.jpg', 'Dirt 4.jpg', 'Animal carcass 3.jpg', 'Dirt 5.jpg', 'Dock 1.jpg', 'Doctor 1.jpg', 'Doctor 2.jpg', 'Doctor 4.jpg', 'Doctor 5.jpg', 'Doctor 6.jpg', 'Doctor 7.jpg', 'Doctor 8.jpg', 'Animal carcass 4.jpg', 'Doctor 9.jpg', 'Dog 1.jpg', 'Dog 2.jpg', 'Dog 4.jpg', 'Dog 5.jpg', 'Dog 7.jpg', 'Dog 8.jpg', 'Dog 9.jpg', 'Animal carcass 5.jpg', 'Dog 10.jpg', 'Dog 12.jpg', 'Dog 13.jpg', 'Dog 14.jpg', 'Dog 15.jpg', 'Dog 16.jpg', 'Dog 17.jpg', 'Dog 18.jpg', 'Animal carcass 6.jpg', 'Dog 21.jpg', 'Dog 22.jpg', 'Dog 23.jpg', 'Dog 24.jpg', 'Dog 25.jpg', 'Dog 26.jpg', 'Dog 27.jpg', 'Dog 28.jpg', 'Dog 29.jpg', 'Archery 1.jpg', 'Dog 30.jpg', 'Dog attack 1.jpg', 'Dog attack 2.jpg', 'Dog attack 3.jpg', 'Drink 1.jpg', 'Drink 2.jpg', 'Dummy 1.jpg', 'Eating 1.jpg', 'Eating 2.jpg', 'Archery 2.jpg', 'Eating 3.jpg', 'Elephant 1.jpg', 'Excited face 1.jpg', 'Excited face 2.jpg', 'Excited face 3.jpg', 'Excited face 4.jpg', 'Excited face 5.jpg', 'Excited face 6.jpg', 'Excited face 7.jpg', 'Exercise 1.jpg', 'Acorns 3.jpg', 'Astronaut 1.jpg', 'Exercise 2.jpg', 'Exercise 3.jpg', 'Explosion 1.jpg', 'Explosion 2.jpg', 'Explosion 3.jpg', 'Explosion 4.jpg', 'Explosion 5.jpg', 'Explosion 6.jpg', 'Father 1.jpg', 'Feces 1.jpg', 'Astronaut 2.jpg', 'Feces 2.jpg', 'Fence 1.jpg', 'Fence 2.jpg', 'Fence 3.jpg', 'Fence 4.jpg', 'Fence 5.jpg', 'Fence 6.jpg', 'Ferret 1.jpg', 'Fire 1.jpg', 'Fire 2.jpg', 'Baby 1.jpg', 'Fire 3.jpg', 'Fire 4.jpg', 'Fire 5.jpg', 'Fire 6.jpg', 'Fire 7.jpg', 'Fire 8.jpg', 'Fire 9.jpg', 'Fire 10.jpg', 'Fire 11.jpg', 'Baby 2.jpg', 'Fire hydrant 2.jpg', 'Fire hydrant 3.jpg', 'Fire hydrant 4.jpg', 'Fireman 1.jpg', 'Fireworks 1.jpg', 'Fireworks 2.jpg', 'Fireworks 3.jpg', 'Fireworks 4.jpg', 'Fireworks 5.jpg', 'Fireworks 6.jpg', 'Baby 3.jpg', 'Fireworks 7.jpg', 'Flood 1.jpg', 'Flood 2.jpg', 'Flood 3.jpg', 'Flowers 1.jpg', 'Flowers 2.jpg', 'Flowers 3.jpg', 'Flowers 4.jpg', 'Flowers 5.jpg', 'Flowers 6.jpg', 'Baby 4.jpg', 'Flowers 8.jpg', 'Flowers 9.jpg', 'Food 2.jpg', 'Food 3.jpg', 'Food 4.jpg', 'Food 6.jpg', 'Baby 5.jpg', 'Football player 1.jpg', 'Frisbee 1.jpg', 'Frustrated pose 3.jpg', 'Frustrated pose 4.jpg', 'Frustrated pose 5.jpg', 'Frustrated pose 6.jpg', 'Frustrated pose 7.jpg', 'Frustrated pose 8.jpg', 'Baby 6.jpg', 'Galaxy 1.jpg', 'Galaxy 2.jpg', 'Galaxy 3.jpg', 'Galaxy 4.jpg', 'Galaxy 5.jpg', 'Galaxy 6.jpg', 'Galaxy 7.jpg', 'Galaxy 8.jpg', 'Garbage dump 1.jpg', 'Baby 7.jpg', 'Garbage dump 2.jpg', 'Garbage dump 3.jpg', 'Garbage dump 4.jpg', 'Garbage dump 5.jpg', 'Garbage dump 6.jpg', 'Garbage dump 7.jpg', 'Garbage dump 8.jpg', 'Gargoyle 1.jpg', 'Gargoyle 2.jpg', 'Gazing 1.jpg', 'Baby 8.jpg', 'Gazing 2.jpg', 'Gazing 3.jpg', 'Gazing 4.jpg', 'Gazing 5.jpg', 'Gazing 7.jpg', 'Goat 1.jpg', 'Goat 2.jpg', 'Gorrila 1.jpg', 'Grass 1.jpg', 'Alcohol 1.jpg', 'Baby 9.jpg', 'Grass 2.jpg', 'Grass 3.jpg', 'Grass 4.jpg', 'Grass 5.jpg', 'Grass 6.jpg', 'Grass 7.jpg', 'Graveyard 2.jpg', 'Graveyard 3.jpg', 'Graveyard 4.jpg', 'Baby 10.jpg', 'Guitar 1.jpg', 'Gun 1.jpg', 'Gun 2.jpg', 'Gun 3.jpg', 'Gun 4.jpg', 'Gun 5.jpg', 'Gun 6.jpg', 'Gun 7.jpg', 'Gun 8.jpg', 'Band 1.jpg', 'Gun 10.jpg', 'Hallway 1.jpg', 'Hang gliding 1.jpg', 'Hang gliding 2.jpg', 'Hang gliding 3.jpg', 'Happy face 1.jpg', 'Happy face 2.jpg', 'Happy pose 1.jpg', 'Happy pose 2.jpg', 'Band 2.jpg', 'Happy pose 3.jpg', 'Heart 1.jpg', 'Heart 2.jpg', 'Heart 3.jpg', 'Horse 1.jpg', 'Horse racing 1.jpg', 'Injury 1.jpg', 'Injury 2.jpg', 'Injury 3.jpg', 'Bar 1.jpg', 'Injury 4.jpg', 'Intensity 1.jpg', 'Jail 1.jpg', 'Jail 2.jpg', 'Jail 3.jpg', 'Jail 4.jpg', 'Jail 5.jpg', 'Keyboard 1.jpg', 'Keyboard 2.jpg', 'Keyboard 3.jpg', 'Bar 2.jpg', 'Keys 1.jpg', 'KKK rally 1.jpg', 'Knife 1.jpg', 'Knife 2.jpg', 'Lake 1.jpg', 'Lake 2.jpg', 'Lake 3.jpg', 'Lake 4.jpg', 'Lake 5.jpg', 'Bar 3.jpg', 'Lake 6.jpg', 'Lake 7.jpg', 'Lake 8.jpg', 'Lake 9.jpg', 'Lake 10.jpg', 'Lake 11.jpg', 'Lake 12.jpg', 'Lake 13.jpg', 'Lake 14.jpg', 'Lake 15.jpg', 'Barbeque 1.jpg', 'Lake 16.jpg', 'Lake 17.jpg', 'Lamb 1.jpg', 'Lava 1.jpg', 'Lightning 1.jpg', 'Lightning 3.jpg', 'Lightning 4.jpg', 'Lightning 5.jpg', 'Lightning 6.jpg', 'Barbeque 2.jpg', 'Lightning 7.jpg', 'Lion 1.jpg', 'Lion 2.jpg', 'Lion 3.jpg', 'Lion 4.jpg', 'Lion 5.jpg', 'Massage 1.jpg', 'Massage 2.jpg', 'Memorial 1.jpg', 'Bark 1.jpg', 'Memorial 2.jpg', 'Miserable face 1.jpg', 'Miserable face 2.jpg', 'Miserable pose 1.jpg', 'Miserable pose 2.jpg', 'Miserable pose 3.jpg', 'Miserable pose 4.jpg', 'Money 1.jpg', 'Alcohol 2.jpg', 'Bark 2.jpg', 'Monkey 2.jpg', 'Monkey 3.jpg', 'Monkey 4.jpg', 'Moon 1.jpg', 'Mother 1.jpg', 'Mother 2.jpg', 'Mother 4.jpg', 'Mother 5.jpg', 'Bark 3.jpg', 'Mother 7.jpg', 'Mother 8.jpg', 'Mother 9.jpg', 'Motocross 1.jpg', 'Musician 1.jpg', 'Nature 1.jpg', 'Nature 2.jpg', 'Neonazi 1.jpg', 'Neutral face 1.jpg', 'Bark 4.jpg', 'Neutral face 2.jpg', 'Neutral face 3.jpg', 'Neutral face 4.jpg', 'Neutral face 5.jpg', 'Neutral pose 1.jpg', 'Neutral pose 2.jpg', 'Neutral pose 3.jpg', 'Nude couple 1.jpg', 'Nude couple 2.jpg', 'Nude couple 3.jpg', 'Bark 5.jpg', 'Nude couple 4.jpg', 'Nude couple 5.jpg', 'Nude couple 6.jpg', 'Nude couple 7.jpg', 'Nude couple 8.jpg', 'Nude couple 9.jpg', 'Nude couple 10.jpg', 'Nude couple 11.jpg', 'Nude couple 13.jpg', 'Bark 6.jpg', 'Nude couple 14.jpg', 'Nude man 1.jpg', 'Nude man 2.jpg', 'Nude man 4.jpg', 'Nude man 5.jpg', 'Nude man 6.jpg', 'Nude man 7.jpg', 'Nude man 9.jpg', 'Nude man 10.jpg', 'Barrels 1.jpg', 'Nude man 11.jpg', 'Nude man 12.jpg', 'Nude man 13.jpg', 'Nude man 14.jpg', 'Nude man 15.jpg', 'Nude man 16.jpg', 'Nude man 17.jpg', 'Nude man 18.jpg', 'Nude man 19.jpg', 'Nude man 20.jpg', 'BDSM 1.jpg', 'Nude man 3.jpg', 'Nude man 21.jpg', 'Nude man 22.jpg', 'Nude man 23.jpg', 'Nude woman 1.jpg', 'Nude woman 2.jpg', 'Nude woman 3.jpg', 'Nude woman 4.jpg', 'Nude woman 6.jpg', 'BDSM 2.jpg', 'Nude woman 7.jpg', 'Nude woman 8.jpg', 'Nude woman 9.jpg', 'Nude woman 10.jpg', 'Nude woman 11.jpg', 'Nude woman 12.jpg', 'Nude woman 13.jpg', 'Nude woman 15.jpg', 'Nude woman 16.jpg', 'Nude woman 17.jpg', 'Nude woman 18.jpg', 'Nude woman 20.jpg', 'Nude woman 21.jpg', 'Nude woman 22.jpg', 'Office supplies 1.jpg', 'Office supplies 2.jpg', 'Office supplies 3.jpg', 'Office supplies 4.jpg', 'Beach 1.jpg', 'Office supplies 5.jpg', 'Opossum 1.jpg', 'Orangutan 1.jpg', 'Ornament 1.jpg', 'Paintbrush 1.jpg', 'Paper 1.jpg', 'Paper 2.jpg', 'Paper 3.jpg', 'Paper 4.jpg', 'Paper 5.jpg', 'Alcohol 3.jpg', 'Beach 2.jpg', 'Paperclips 1.jpg', 'Paperclips 2.jpg', 'Parachuting 1.jpg', 'Parachuting 2.jpg', 'Parachuting 3.jpg', 'Parachuting 4.jpg', 'Parade 1.jpg', 'Parasailing 1.jpg', 'Beach 3.jpg', 'Parasailing 2.jpg', 'Parasailing 3.jpg', 'Parasailing 4.jpg', 'Party 1.jpg', 'Path 1.jpg', 'Penguins 1.jpg', 'Performance 1.jpg', 'Performance 2.jpg', 'Phone 1.jpg', 'Beach 4.jpg', 'Picnic 2.jpg', 'Picnic 3.jpg', 'Picnic 4.jpg', 'Pig 1.jpg', 'Pig 2.jpg', 'Pigeon 1.jpg', 'Pigeon 3.jpg', 'Pigeon 4.jpg', 'Beach 5.jpg', 'Pigeon 5.jpg', 'Pigeon 6.jpg', 'Pinecone 1.jpg', 'Pinecone 2.jpg', 'Pinecone 3.jpg', 'Pinecone 4.jpg', 'Plane crash 1.jpg', 'Plane crash 2.jpg', 'Plane crash 3.jpg', 'Plane crash 4.jpg', 'Beach 6.jpg', 'Police 1.jpg', 'Police 2.jpg', 'Police 4.jpg', 'Police 5.jpg', 'Pollution 1.jpg', 'Power lines 1.jpg', 'Present 2.jpg', 'Prison 1.jpg', 'Beach 7.jpg', 'Prison 2.jpg', 'Pumpkin 1.jpg', 'Raccoon 1.jpg', 'Rafting 1.jpg', 'Rafting 3.jpg', 'Rafting 4.jpg', 'Rafting 5.jpg', 'Railroad 1.jpg', 'Beach 8.jpg', 'Rainbow 1.jpg', 'Rainbow 2.jpg', 'Research 1.jpg', 'Road 1.jpg', 'Rock climbing 1.jpg', 'Rock climbing 2.jpg', 'Rock climbing 3.jpg', 'Rock climbing 4.jpg', 'Rocks 1.jpg', 'Rocks 2.jpg', 'Bear 1.jpg', 'Rocks 3.jpg', 'Rocks 6.jpg', 'Rocks 7.jpg', 'Rollercoaster 1.jpg', 'Rollercoaster 2.jpg', 'Rollercoaster 3.jpg', 'Roofing 2.jpg', 'Bear 2.jpg', 'Roofing 3.jpg', 'Roofing 4.jpg', 'Roofing 5.jpg', 'Rooster 1.jpg', 'Rubber duck 1.jpg', 'Rugby 1.jpg', 'Rugby 2.jpg', 'Running away 1.jpg', 'Sad face 1.jpg', 'Sad face 2.jpg', 'Bear 3.jpg', 'Sad face 3.jpg', 'Sad face 4.jpg', 'Sad face 5.jpg', 'Sad face 6.jpg', 'Sad face 7.jpg', 'Sad face 8.jpg', 'Sad face 9.jpg', 'Sad pose 1.jpg', 'Sad pose 2.jpg', 'Alcohol 4.jpg', 'Bed 1.jpg', 'Sad pose 4.jpg', 'Sad pose 6.jpg', 'Sad pose 7.jpg', 'Sailing 1.jpg', 'Sailing 2.jpg', 'Sailing 3.jpg', 'Satellite 1.jpg', 'Scared face 1.jpg', 'Bee 1.jpg', 'Scared face 2.jpg', 'Scared face 3.jpg', 'Scared face 4.jpg', 'Scared face 5.jpg', 'Scary face 1.jpg', 'Scary face 2.jpg', 'School 1.jpg', 'School 2.jpg', 'School 3.jpg', 'School 4.jpg', 'Biking 1.jpg', 'School 6.jpg', 'School 7.jpg', 'School 8.jpg', 'Seal 1.jpg', 'Severed finger 1.jpg', 'Shark 1.jpg', 'Shark 2.jpg', 'Shark 3.jpg', 'Shark 4.jpg', 'Billiards 1.jpg', 'Shark 5.jpg', 'Shark 6.jpg', 'Shark 7.jpg', 'Shark 8.jpg', 'Shark 9.jpg', 'Shark 11.jpg', 'Shooting 1.jpg', 'Shot 1.jpg', 'Shot 2.jpg', 'Bird 1.jpg', 'Shot 3.jpg', 'Siblings 1.jpg', 'Sidewalk 1.jpg', 'Sidewalk 2.jpg', 'Sidewalk 3.jpg', 'Sidewalk 4.jpg', 'Sidewalk 5.jpg', 'Skier 1.jpg', 'Skijump 1.jpg', 'Skijump 2.jpg', 'Skinhead 1.jpg', 'Sky 1.jpg', 'Skydiving 1.jpg', 'Skydiving 2.jpg', 'Skydiving 3.jpg', 'Skydiving 4.jpg', 'Skydiving 5.jpg', 'Skyscraper 1.jpg', 'Skyscraper 2.jpg', 'Sleepy pose 1.jpg', 'Sleepy pose 2.jpg', 'Sleepy pose 3.jpg', 'Sleepy pose 4.jpg', 'Snake 1.jpg', 'Snake 2.jpg', 'Snake 3.jpg', 'Bird 4.jpg', 'Snake 4.jpg', 'Snake 5.jpg', 'Snake 6.jpg', 'Snow 1.jpg', 'Snow 2.jpg', 'Snow 3.jpg', 'Snow 4.jpg', 'Snow 5.jpg', 'Soccer 1.jpg', 'Soccer 2.jpg', 'Socks 1.jpg', 'Solar panel 1.jpg', 'Soldiers 1.jpg', 'Soldiers 3.jpg', 'Soldiers 4.jpg', 'Soldiers 5.jpg', 'Soldiers 6.jpg', 'Soldiers 8.jpg', 'Birthday 1.jpg', 'Soldiers 9.jpg', 'Soldiers 10.jpg', 'Soup 1.jpg', 'Spider 1.jpg', 'Spider 2.jpg', 'Statue 2.jpg', 'Stingray 2.jpg', 'Stingray 3.jpg', 'Alcohol 5.jpg', 'Birthday 2.jpg', 'Storage 1.jpg', 'Storage 3.jpg', 'Street 1.jpg', 'Street 2.jpg', 'Street 3.jpg', 'Street 4.jpg', 'Street 5.jpg', 'Sun 1.jpg', 'Sunflower 1.jpg', 'Birthday 3.jpg', 'Sunset 1.jpg', 'Sunset 2.jpg', 'Sunset 3.jpg', 'Sunset 4.jpg', 'Sunset 5.jpg', 'Sunset 6.jpg', 'Surgery 1.jpg', 'Surgery 2.jpg', 'Surgery 3.jpg', 'Bloody knife 1.jpg', 'Surgery 5.jpg', 'Surprise 1.jpg', 'Surprise 2.jpg', 'Swingset 1.jpg', 'Thunderstorm 1.jpg', 'Thunderstorm 2.jpg', 'Thunderstorm 3.jpg', 'Thunderstorm 4.jpg', 'Bloody knife 2.jpg', 'Thunderstorm 6.jpg', 'Thunderstorm 7.jpg', 'Thunderstorm 8.jpg', 'Thunderstorm 9.jpg', 'Thunderstorm 10.jpg', 'Thunderstorm 11.jpg', 'Tickling 1.jpg', 'Tiger 1.jpg', 'Tiger 2.jpg', 'Timber 1.jpg', 'Boat 1.jpg', 'Timber 2.jpg', 'Timber 3.jpg', 'Timber 4.jpg', 'Toast 1.jpg', 'Toilet 1.jpg', 'Toilet 2.jpg', 'Toilet 3.jpg', 'Toilet 4.jpg', 'Tornado 1.jpg', 'Tornado 2.jpg', 'Bored face 1.jpg', 'Tornado 4.jpg', 'Tornado 5.jpg', 'Torture chamber 1.jpg', 'Traffic 1.jpg', 'Tumor 1.jpg', 'Volcano 1.jpg', 'Volcano 2.jpg', 'Volcano 3.jpg', 'Wall 1.jpg', 'Bored pose 1.jpg', 'Wall 2.jpg', 'Wall 3.jpg', 'Wall 4.jpg', 'Wall 5.jpg', 'War 1.jpg', 'War 2.jpg', 'War 4.jpg', 'War 5.jpg', 'War 6.jpg', 'Bored pose 2.jpg', 'War 7.jpg', 'War 8.jpg', 'Waterfall 1.jpg', 'Weapon 1.jpg', 'Wedding 1.jpg', 'Wedding 2.jpg', 'Wedding 3.jpg', 'Wedding 6.jpg', 'Bored pose 3.jpg', 'Wedding 7.jpg', 'Wedding 8.jpg', 'Wedding 9.jpg', 'Wedding 10.jpg', 'Wedding 11.jpg', 'Wedding ring 1.jpg', 'Windmill 1.jpg', 'Wolf 1.jpg', 'Wolf 2.jpg', 'Bored pose 4.jpg', 'Woods 1.jpg', 'Yarn 1.jpg', 'Yarn 2.jpg', 'Yarn 3.jpg', 'Yarn 4.jpg', 'Yoga 1.jpg', 'Yoga 2.jpg', 'Yoga 3.jpg', 'Yoga 4.jpg', 'Yoga 5.jpg', 'Alcohol 6.jpg', 'Bored pose 5.jpg', 'Zebra 1.jpg', 'Bored pose 6.jpg', 'Bottle 1.jpg', 'Boxing 1.jpg', 'Boxing 2.jpg', 'Bridge 1.jpg', 'Bubble 1.jpg', 'Bubble 2.jpg', 'Building 1.jpg']\n"
     ]
    }
   ],
   "source": [
    "X = inputData[\"caption\"]\n",
    "y = inputData[\"label\"]\n",
    "\n",
    "max_seq_len = int(inputData['caption'].map(lambda x: caput.get_non_stop_word_count(x.split())).max())\n",
    "\n",
    "\n",
    "dfTrain = pd.concat([X, y], axis=1)\n",
    "dfTrain.columns = ['caption', 'label']\n",
    "\n",
    "dfTrain = inputData\n",
    "\n",
    "class_to_index = {}\n",
    "index_to_class = {}\n",
    "\n",
    "X_train_text, y_train_index, num_of_classes, class_to_index, index_to_class, filenames = \\\n",
    "            caput.load_dataset_StratifiedKFold(\n",
    "                            dfTrain,\n",
    "                            wordToVec, \n",
    "                            max_seq_len, \n",
    "                            class_to_index, \n",
    "                            index_to_class,\n",
    "                            get_config())\n",
    "y_train = caput.convert_index_to_one_hot(y_train_index, num_of_classes) \n",
    "print(\"filenames\",filenames)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "<class 'numpy.ndarray'>\n",
      "batch_size 32\n",
      "Train on 729 samples, validate on 81 samples\n",
      "Epoch 1/100\n",
      "729/729 [==============================] - 4s 5ms/step - loss: 8.5786 - acc: 0.4678 - val_loss: 8.7555 - val_acc: 0.4568\n",
      "Epoch 2/100\n",
      "729/729 [==============================] - 4s 5ms/step - loss: 8.5786 - acc: 0.4678 - val_loss: 8.7555 - val_acc: 0.4568\n",
      "Epoch 3/100\n",
      "729/729 [==============================] - 4s 5ms/step - loss: 8.5786 - acc: 0.4678 - val_loss: 8.7555 - val_acc: 0.4568\n",
      "Epoch 4/100\n",
      "729/729 [==============================] - 4s 5ms/step - loss: 8.5786 - acc: 0.4678 - val_loss: 8.7555 - val_acc: 0.4568\n",
      "Epoch 5/100\n",
      "729/729 [==============================] - 4s 5ms/step - loss: 8.5786 - acc: 0.4678 - val_loss: 8.7555 - val_acc: 0.4568\n",
      "Epoch 6/100\n",
      "729/729 [==============================] - 4s 5ms/step - loss: 8.5786 - acc: 0.4678 - val_loss: 8.7555 - val_acc: 0.4568\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 7/100\n",
      "729/729 [==============================] - 4s 5ms/step - loss: 8.5786 - acc: 0.4678 - val_loss: 8.7555 - val_acc: 0.4568\n",
      "Epoch 8/100\n",
      "729/729 [==============================] - 4s 5ms/step - loss: 8.5786 - acc: 0.4678 - val_loss: 8.7555 - val_acc: 0.4568\n",
      "Epoch 9/100\n",
      "729/729 [==============================] - 4s 5ms/step - loss: 8.5786 - acc: 0.4678 - val_loss: 8.7555 - val_acc: 0.4568\n",
      "Epoch 10/100\n",
      "729/729 [==============================] - 4s 5ms/step - loss: 8.5786 - acc: 0.4678 - val_loss: 8.7555 - val_acc: 0.4568\n",
      "Epoch 11/100\n",
      "729/729 [==============================] - 4s 5ms/step - loss: 8.5786 - acc: 0.4678 - val_loss: 8.7555 - val_acc: 0.4568\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "best_train_acc 0.46776406060193954\n",
      "best_val_acc 0.456790127871949\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 2\n",
    "print(y_train[:3])\n",
    "y_train = np.array(y_train)\n",
    "print(y_train[:2])\n",
    "print(type(y_train))\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                  factor=0.7, \n",
    "                                  patience=5,\n",
    "                                  min_delta=0.0001,\n",
    "                                  cooldown=1,\n",
    "                                  min_lr=1e-7,\n",
    "                                  verbose=verbose)\n",
    "tfBoard = TensorBoard(log_dir='logs',histogram_freq=1) # ,embeddings_freq=1\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience)    \n",
    "callbacks_list = [early_stopping, reduce_lr, tfBoard] \n",
    "\n",
    "printCnt = 10\n",
    "X_train, X_train_text, y_train= np.array(X_train), np.array(X_train_text), np.array(y_train)\n",
    "X_train, X_train_text, y_train = shuffle(X_train, X_train_text, y_train)\n",
    "batch_size = 32 \n",
    "print(\"batch_size\", batch_size)\n",
    "history = full_model.fit([X_train, X_train_text], y_train,\n",
    "                                   batch_size=batch_size,\n",
    "                                   epochs=100,\n",
    "                                   #shuffle=True,\n",
    "                                   validation_split=0.1,\n",
    "                                   callbacks=callbacks_list,\n",
    "                                   #class_weight=class_weights,\n",
    "                                   verbose=1) \n",
    "\n",
    "# LAYERS_TO_UNFREEZE = 20\n",
    "# setup_to_finetune(full_model, False)\n",
    "# history = full_model.fit([X_train, X_train_text], y_train,\n",
    "#                                    batch_size=batch_size,\n",
    "#                                    epochs=100,\n",
    "#                                    shuffle=True,\n",
    "#                                    validation_split=0.1,\n",
    "#                                    callbacks=callbacks_list,\n",
    "#                                    #class_weight=class_weights,\n",
    "#                                    verbose=1) \n",
    "\n",
    "useF1Score = False\n",
    "pt.plot_model_accuracy(history, model_results_root_dir, useF1Score)\n",
    "#,  validation_split=0.2,epochs=epochs,\n",
    "#  steps_per_epoch=  2000 // get_config()['batch_size'],"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
