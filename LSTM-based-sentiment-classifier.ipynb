{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building LSTM-based recurrent neural network for classifying sentiment of the image captions\n",
    "\n",
    "https://www.oreilly.com/learning/perform-sentiment-analysis-with-lstms-using-tensorflow\n",
    "\n",
    "GloVe word2vec word vectors will be used :\n",
    "\n",
    "https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "- Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 50d, 100d, 200d, & 300d vectors, 822 MB download): glove.6B.zip\n",
    "- Common Crawl (42B tokens, 1.9M vocab, uncased, 300d vectors, 1.75 GB download): glove.42B.300d.zip\n",
    "- Common Crawl (840B tokens, 2.2M vocab, cased, 300d vectors, 2.03 GB download): glove.840B.300d.zip\n",
    "- Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 25d, 50d, 100d, & 200d vectors, 1.42 GB download): glove.twitter.27B.zip\n",
    "\n",
    "https://github.com/adeshpande3/LSTM-Sentiment-Analysis \n",
    "\n",
    "https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM\n",
    "\n",
    "Paper: Minimal Gated Unit for Recurrent Neural Networks https://arxiv.org/pdf/1603.09420v1.pdf \n",
    "\n",
    "https://www.quora.com/How-do-we-use-LSTM-to-do-sentiment-analysis \n",
    "\n",
    "It’s actually quite simple! Encode the document using the one-hot encoding, then train the LSTM to read the document character by character and optimize the hidden state after the last letter to contain the sentiment of the sentence.\n",
    "\n",
    "Here you have an example, how to use the hidden state of LSTM to recognize picture. Use the same technique, just use sentiment labels (eg. positive, negative, neutral) instead of image labels : https://arxiv.org/pdf/1603.09420...\n",
    "\n",
    "Note: one-hot encoding - each character is represented by a vector with size equal the alphabet size filled with 0s on most positions, and 1 at the position of the specified letter.\n",
    "\n",
    "- **KERAS example**\n",
    "https://www.kaggle.com/ngyptr/lstm-sentiment-analysis-keras/data \n",
    "\n",
    " - **TODO: Add Python NLTK sentiment analysis **\n",
    "\n",
    " - **TODO: Positive/Negative word clouds **\n",
    "https://www.kaggle.com/ngyptr/python-nltk-sentiment-analysis/code\n",
    "\n",
    "- **Pytorch examples: Natural Language Inference (SNLI) with GloVe vectors, LSTMs, and torchtext ** https://github.com/pytorch/examples/tree/master/snli\n",
    "- ** Deep Learning for NLP with Pytorch **  https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "\n",
    "\n",
    "SNLI : https://nlp.stanford.edu/projects/snli/ \n",
    "https://nlp.stanford.edu/pubs/snli_paper.pdf \n",
    "\n",
    "The SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE). We aim for it to serve both as a benchmark for evaluating representational systems for text, especially including those induced by representation learning methods, as well as a resource for developing NLP models of any kind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(width=41, compact=True)\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Pretrained Vectors\n",
    "\n",
    "- http://dl4nlp.info/en/latest/ NOT GOOD\n",
    " - http://pytorch-nlp-tutorial-ny2018.readthedocs.io/en/latest/\n",
    " - http://pytorch-nlp-tutorial-ny2018.readthedocs.io/en/latest/recipes/load_pretrained_vectors.html\n",
    " - git clone https://github.com/joosthub/pytorch-nlp-tutorial-ny2018.git\n",
    " - data: https://drive.google.com/file/d/0B2hg7DTHpfLsdHhEUVhHWU5hUXc/view\n",
    "\n",
    "\n",
    "It can be extremely useful to make a model which had as advantageous starting point.\n",
    "\n",
    "To do this, we can set the values of the embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we give an example of this function in the day 1, word vector notebook\n",
    "word_to_index, word_vectors, word_vector_size = load_word_vectors()\n",
    "\n",
    "\n",
    "# now, we want to iterate over our vocabulary items\n",
    "for word, emb_index in vectorizer.word_vocab.items():\n",
    "    # if the word is in the loaded glove vectors\n",
    "    if word.lower() in word_to_index:\n",
    "         # get the index into the glove vectors\n",
    "         glove_index = word_to_index[word.lower()]\n",
    "         # get the glove vector itself and convert to pytorch structure\n",
    "         glove_vec = torch.FloatTensor(word_vectors[glove_index])\n",
    "\n",
    "         # this only matters if using cuda :)\n",
    "         if settings.CUDA:\n",
    "             glove_vec = glove_vec.cuda()\n",
    "\n",
    "         # finally, if net is our network, and emb is the embedding layer:\n",
    "         net.emb.weight.data[emb_index, :].set_(glove_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formal Start\n",
    "\n",
    "## Twitter Sentiment Analysis [1] dataset\n",
    "\n",
    "Description: http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/\n",
    "\n",
    "Download: http://thinknook.com/wp-content/uploads/2012/09/Sentiment-Analysis-Dataset.zip \n",
    "\n",
    "## Inspired by : https://github.com/hpanwar08/sentiment-analysis-torchtext\n",
    "\n",
    "## TODO\n",
    "1. Add Python NLTK sentiment analysis -\n",
    "\n",
    "2. [DONE] Positive/Negative word clouds https://www.kaggle.com/ngyptr/python-nltk-sentiment-analysis/code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing GloVe vectors\n",
    "\n",
    "https://github.com/spro/practical-pytorch/blob/master/glove-word-vectors/glove-word-vectors.ipynb \n",
    "\n",
    "Installing torchtext: https://github.com/pytorch/text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:27, 5.85MB/s]                              \n",
      "100%|██████████| 400000/400000 [00:12<00:00, 31935.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 words\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading word vectors\n",
    "\n",
    "import torch\n",
    "import torchtext.vocab as vocab\n",
    "\n",
    "# sentiment = data.TabularDataset(\n",
    "#     path='data/sentiment/train.json', format='json',\n",
    "#     fields={'sentence_tokenized': ('text', data.Field(sequential=True)),\n",
    "#             'sentiment_gold': ('labels', data.Field(sequential=False))})\n",
    "\n",
    "glove = vocab.GloVe(name='6B', dim=100)\n",
    "\n",
    "print('Loaded {} words'.format(len(glove.itos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(word):\n",
    "    return glove.vectors[glove.stoi[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source : https://medium.com/@sonicboom8/sentiment-analysis-torchtext-55fb57b1fab8\n",
    "from torchtext import data\n",
    "\n",
    "# tokenizer function using spacy\n",
    "nlp = spacy.load('en',disable=['parser', 'tagger', 'ner'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
